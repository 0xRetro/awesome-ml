# Table of Contents

<details>
  <summary>Show Table of Contents</summary>
  
- [:speech_balloon: Large Language Models](#large-language-models)
  - [:open_file_folder: Open models](#open-models)
  - [:brain: Other SOTA Open Source Models](#other-sota-open-source-models)
  - [:floppy_disk: Data sets](#data-sets)
  - [:test_tube: Research](#research)
  - [:desktop_computer: LLM GUIs](#llm-guis)
    - [:rocket: OpenAI](#openai)
    - [:computer: Other GUIs](#other-guis)
  - [:package: LLM Wrappers](#llm-wrappers)
  - [:clapper: Showcases](#showcases)
  - [:wrench: Fine Tuning](#fine-tuning)
  - [:link: Other awesome lists](#other-awesome-lists)
- [:camera: Image Generation](#image-generation)
  - [:paintbrush: Models](#models)
  - [:computer_mouse: Wrappers & GUIs](#wrappers--guis)
  - [:wrench: Fine Tuning](#fine-tuning-1)
- [:stopwatch: Benchmarking](#benchmarking)
- [:movie_camera: Video](#video)
  - [:memo: Text to video generation](#text-to-video-generation)
  - [:film_strip: Frame Interpolation (Temporal Interpolation)](#frame-interpolation-temporal-interpolation)
  - [:mag_right: Super Resolution (Spacial Interpolation)](#super-resolution-spacial-interpolation)
  - [:clapper: Spacio Temporal Interpolation](#spacio-temporal-interpolation)
- [:musical_note: Audio](#audio)
  - [:clamp: Compression](#compression)
  - [:headphones: Multiple Tasks](#multiple-tasks)
  - [:microphone: Speech Recognition](#speech-recognition)
  - [:notes: TextToSpeech](#texttospeech)
  - [:loud_sound: Voice Conversion](#voice-conversion)
- [:computer: AI DevOps](#ai-devops)
- [:chart_with_upwards_trend: Optimization](#optimization)
  - [:bar_chart: Inference](#inference)
  - [:running: Training](#training)
  - [:wrench: Other Optimization](#other-optimization)

</details>

ü§ùüë• Contributions welcome. Accepting Pull Requests.

# Large Language Models

## Open models

üóé Open the [Model Google Sheet](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit?usp=sharing)
or:

<details>
  <summary>Show Table with models</summary>

| Model                                                                                                                                    | Author                       | Foundation  | Size       | Quantization                       | Fine Tuning Dataset                                                                                                                                                                                                                                                                                                                                                                          | Format                             | LoRa | model date |
|------------------------------------------------------------------------------------------------------------------------------------------|------------------------------|-------------|------------|------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------|------|------------|
| [Wizard-Vicuna-13b-Uncensored](https://huggingface.co/ehartford/Wizard-Vicuna-13b-Uncensored)                                            | ehartford                    | vicuna      | 13b        | none                               | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered)                                                                                                                                                                                                                 | native .bin                        |      | tbd        |
| [dromedary-65B-lora-GPTQ](https://huggingface.co/TheBloke/dromedary-65B-lora-GPTQ)                                                       | TheBloke                     | llama       | 65b        | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | safetensors                        |      | 2023-05-12 |
| [ggml-gpt4-x-vicuna-13b](https://huggingface.co/eachadea/ggml-gpt4-x-vicuna-13b)                                                         | eachadea                     | vicuna-v1.1 | 13b        | q4_0, q5_0, q5_1                   | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct                                                                                                                                                                                                                                                                                                                | ggml .bin                          |      | 2023-05-12 |
| [gpt4-x-vicuna-13B-GGML](https://huggingface.co/TheBloke/gpt4-x-vicuna-13B-GGML)                                                         | TheBloke                     | vicuna-v1.1 | 13b        | q4_0, q5_0, q5_1                   | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct                                                                                                                                                                                                                                                                                                                | ggml .bin                          |      | 2023-05-12 |
| [GPT4All-13B-snoozy-GGML](https://huggingface.co/TheBloke/GPT4All-13B-snoozy-GGML)                                                       | TheBloke                     | llama       | 13b        | q4_0, q5_0, q5_1                   | [gpt4all-j-prompt-generations](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations)                                                                                                                                                                                                                                                                                        | ggml .bin                          |      | 2023-05-12 |
| [open-llama-0.3T-7B-open-instruct-v1.1](https://huggingface.co/VMware/open-llama-0.3T-7B-open-instruct-v1.1)                             | VMware                       | open-llama  | 7b         | none                               | oasst, dolly, hhrlhf                                                                                                                                                                                                                                                                                                                                                                         | native .bin                        |      | 2023-05-12 |
| [OpenAssistant-SFT-7-Llama-30B-GGML](https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-GGML)                                 | TheBloke                     | llama       | 30b        | q4_0, q5_0, q5_1                   | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                               |      | 2023-05-12 |
| [stable-vicuna-13B-GGML](https://huggingface.co/TheBloke/stable-vicuna-13B-GGML)                                                         | TheBloke                     | vicuna      | 13b        | q4_0, q5_0, q5_1, q8_0             | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP)                                                                                | ggml .bin                          |      | 2023-05-12 |
| [WizardLM-7B-uncensored-GGML](https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGML)                                               | TheBloke                     | llama       | 7b         | q4_0, q5_0, q5_1                   | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered)                                                                                                                                                                                                                 | ggml .bin                          |      | 2023-05-12 |
| [dromedary-65B-lora-GGML](https://huggingface.co/TheBloke/dromedary-65B-lora-GGML)                                                       | TheBloke                     | llama       | 65b        | q4_0, q4_2, q5_0, q5_1             |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-05-11 |
| [dromedary-65b-lora-HF](https://huggingface.co/TheBloke/dromedary-65b-lora-HF)                                                           | TheBloke                     | llama       | 65b        | none                               |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        |      | 2023-05-11 |
| [h2ogpt-oasst1-512-30B-GPTQ](https://huggingface.co/TheBloke/h2ogpt-oasst1-512-30B-GPTQ)                                                 | TheBloke                     | llama       | 30b        | 4bit GPTQ                          | [h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2)                                                                                                                                                                                                                                                                   | safetensors                        |      | 2023-05-11 |
| [mpt-7b-wizardlm](https://huggingface.co/openaccess-ai-collective/mpt-7b-wizardlm)                                                       | openaccess-ai-collective     | llama       | 7b         | none                               | base WizardLM finetuned on MPT datasets: [bigcode/the-stack](https://huggingface.co/datasets/bigcode/the-stack), [mc4](https://huggingface.co/datasets/mc4), [c4](https://huggingface.co/datasets/c4)                                                                                                                                                                                        | native .bin                        |      | 2023-05-11 |
| [open-llama-0.3T-7B-instruct-dolly-hhrlhf](https://huggingface.co/VMware/open-llama-0.3T-7B-instruct-dolly-hhrlhf)                       | VMware                       | open-llama  | 7b         | none                               | [mosaicml/dolly_hhrlhf](https://huggingface.co/datasets/mosaicml/dolly_hhrlhf)                                                                                                                                                                                                                                                                                                               | native .bin                        |      | 2023-05-10 |
| [Vicuna-LoRA-EvolInstruct-StarCoder](https://huggingface.co/LLMs/Vicuna-LoRA-EvolInstruct-StarCoder)                                     | LLMs                         | vicuna      | ?          | none                               | EvolInstruct, [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack)                                                                                                                                                                                                                                                                                                            | native .bin                        | yes  | 2023-05-09 |
| [WizardLM-13B-Uncensored](https://huggingface.co/ehartford/WizardLM-13B-Uncensored)                                                      | ehartford                    | llama       | 13b        | none                               | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered)                                                                                                                                                                                                                 | native .bin                        |      | 2023-05-09 |
| [h2ogpt-research-oig-oasst1-512-30b](https://huggingface.co/h2oai/h2ogpt-research-oig-oasst1-512-30b)                                    | h2oai                        | llama       | 30b        | none                               | [h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2)                                                                                                                                                                                                                                                                   | native .bin                        |      | 2023-05-07 |
| [GPT4-x-Vicuna-13b-4bit](https://huggingface.co/NousResearch/GPT4-x-Vicuna-13b-4bit)                                                     | NousResearch                 | vicuna-v1.1 | 13b        | 4bit GPTQ                          | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct                                                                                                                                                                                                                                                                                                                | triton .pt                         |      | 2023-05-06 |
| [gpt4-x-vicuna-13B-GPTQ](https://huggingface.co/TheBloke/gpt4-x-vicuna-13B-GPTQ)                                                         | TheBloke                     | vicuna-v1.1 | 13b        | 4bit GPTQ                          | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct                                                                                                                                                                                                                                                                                                                | safetensors                        |      | 2023-05-05 |
| [gpt4-x-vicuna-13B-HF](https://huggingface.co/TheBloke/gpt4-x-vicuna-13B-HF)                                                             | TheBloke                     | vicuna-v1.1 | 13b        | 16bit                              | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct                                                                                                                                                                                                                                                                                                                | hf .bin                            |      | 2023-05-05 |
| [gpt4-x-vicuna-13b](https://huggingface.co/NousResearch/gpt4-x-vicuna-13b)                                                               | NousResearch                 | vicuna-v1.1 | 13b        | none                               | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct                                                                                                                                                                                                                                                                                                                | native .bin                        |      | 2023-05-05 |
| [mpt-7b-chat](https://huggingface.co/mosaicml/mpt-7b-chat)                                                                               | mosaicml                     | mpt         | 7b         | none                               | [ShareGPT-Vicuna](https://huggingface.co/datasets/jeffwan/sharegpt_vicuna), [HC3](https://huggingface.co/datasets/Hello-SimpleAI/HC3), [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca), [HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [EvolInstruct](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                 | native .bin                        |      | 2023-05-05 |
| [mpt-7b-instruct](https://huggingface.co/mosaicml/mpt-7b-instruct)                                                                       | mosaicml                     | mpt         | 7b         | none                               | [mosaicml/dolly-hhrlhf](https://huggingface.co/datasets/sam-mosaic/dolly_hhrlhf)                                                                                                                                                                                                                                                                                                             | native .bin                        |      | 2023-05-05 |
| [mpt-7b-storywriter](https://huggingface.co/mosaicml/mpt-7b-storywriter)                                                                 | mosaicml                     | mpt         | 7b         | none                               | [books3](https://huggingface.co/datasets/the_pile_books3)                                                                                                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-05-05 |
| [mpt-7b](https://huggingface.co/mosaicml/mpt-7b)                                                                                         | mosaicml                     | mpt         | 7b         | none                               | [bigcode/the-stack](https://huggingface.co/datasets/bigcode/the-stack), [mc4](https://huggingface.co/datasets/mc4), [c4](https://huggingface.co/datasets/c4)                                                                                                                                                                                                                                 | native .bin                        |      | 2023-05-05 |
| [RedPajama-INCITE-Chat-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1)                                       | togethercomputer             | redpajama   | 3b         | none                               | oasst1, dolly2                                                                                                                                                                                                                                                                                                                                                                               | native .bin                        |      | 2023-05-05 |
| [RedPajama-INCITE-Instruct-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1)                               | togethercomputer             | redpajama   | 3b         | none                               | base: [RedPajama-Data-T1](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T), instruct: dataset of [GPT-JT](https://huggingface.co/togethercomputer/GPT-JT-6B-v1) for few-shot                                                                                                                                                                                              | native .bin                        |      | 2023-05-05 |
| [starcoder-gpteacher-code-instruct](https://huggingface.co/GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct)               | GeorgiaTechResearchInstitute | starcoder   | 15.5b      | none                               | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack), [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                      | native .bin                        |      | 2023-05-05 |
| [WizardLM-7B-uncensored-GPTQ](https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GPTQ)                                               | TheBloke                     | llama       | 7b         | 4bit GPTQ                          | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered)                                                                                                                                                                                                                 | safetensors                        |      | 2023-05-05 |
| [open_llama_7b_preview_300bt](https://huggingface.co/openlm-research/open_llama_7b_preview_300bt)                                        | openlm-research              | open-llama  | 7b         | none                               | [RedPajama](https://www.together.xyz/blog/redpajama)                                                                                                                                                                                                                                                                                                                                         | native .bin                        |      | 2023-05-04 |
| [RedPajama-INCITE-Base-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1)                                       | togethercomputer             | redpajama   | 3b         | none                               | [RedPajama-Data-T1](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T)                                                                                                                                                                                                                                                                                                      | native .bin                        |      | 2023-05-04 |
| [starcoder](https://huggingface.co/bigcode/starcoder)                                                                                    | bigcode                      | starcoder   | 15.5b      | none                               | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack)                                                                                                                                                                                                                                                                                                                          | native .bin                        |      | 2023-05-04 |
| [starcoderbase](https://huggingface.co/bigcode/starcoderbase)                                                                            | bigcode                      | starcoder   | 15.5b      | none                               | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack)                                                                                                                                                                                                                                                                                                                          | native .bin                        |      | 2023-05-04 |
| [wizard-vicuna-13b-ggml](https://huggingface.co/amesianx/wizard-vicuna-13b-ggml)                                                         | amesianx                     | llama       | 13b        | q4_0, q4_1, q4_2, q5_0, q5_1, q8_0 | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k)                                                                                                                                                                                                                                                                                                  | ggml .bin                          |      | 2023-05-04 |
| [wizard-vicuna-13B-GGML](https://huggingface.co/TheBloke/wizard-vicuna-13B-GGML)                                                         | TheBloke                     | llama       | 13b        | q4_0, q4_2, q5_0, q5_1             | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k)                                                                                                                                                                                                                                                                                                  | ggml .bin                          |      | 2023-05-04 |
| [WizardLM-7B-Uncensored](https://huggingface.co/ehartford/WizardLM-7B-Uncensored)                                                        | ehartford                    | llama       | 7b         | none                               | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered)                                                                                                                                                                                                                 | native .bin                        |      | 2023-05-04 |
| [vicuna-13b-cocktail](https://huggingface.co/reeducator/vicuna-13b-cocktail)                                                             | reeducator                   | vicuna-1.1  | 13b        | q5_0, 4bit GPTQ                    | [GPTeacher-Vicuna](https://huggingface.co/datasets/gozfarb/GPTeacher-Vicuna), [gozfarb/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/gozfarb/ShareGPT_Vicuna_unfiltered), [anon8231489123/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                               | ggml .bin, safetensors cuda/triton |      | 2023-05-03 |
| [vicuna-13b-free](https://huggingface.co/reeducator/vicuna-13b-free)                                                                     | reeducator                   | vicuna-1.1  | 13b        | q5_0, 4bit GPTQ                    | [gozfarb/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/gozfarb/ShareGPT_Vicuna_unfiltered), [anon8231489123/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                             | ggml .bin, safetensors             |      | 2023-05-03 |
| [wizard-vicuna-13b](https://huggingface.co/junelee/wizard-vicuna-13b)                                                                    | junelee                      | llama       | 13b        | none                               | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k)                                                                                                                                                                                                                                                                                                  | native .bin                        |      | 2023-05-03 |
| [wizardLM-13b-ggml-4bit](https://huggingface.co/execveat/wizardLM-13b-ggml-4bit)                                                         | execveat                     | llama       | 13b        | q4_0, q4_1, q5_0, q5_1             | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k)                                                                                                                                                                                                                                                                                                  | ggml .bin                          |      | 2023-05-03 |
| [llama-adapter-13b](https://huggingface.co/winglian/llama-adapter-13b)                                                                   | winglian                     | llama       | 13b        | none                               | [alpaca_data_gpt4.json](https://github.com/tloen/alpaca-lora/blob/main/alpaca_data_gpt4.json)                                                                                                                                                                                                                                                                                                | native .bin                        |      | 2023-05-02 |
| [Metharme-7b-4bit-Q4_1-GGML](https://huggingface.co/TehVenom/Metharme-7b-4bit-Q4_1-GGML)                                                 | TehVenom                     | llama       | 7b         | q4_1                               | instruction, roleplay, fictional stories, conversations, synthetic instructions                                                                                                                                                                                                                                                                                                              |                                    |      | 2023-05-02 |
| [open_llama_7b_preview_200bt](https://huggingface.co/openlm-research/open_llama_7b_preview_200bt)                                        | openlm-research              | llama       | 7b         | none                               | [Redpajama](https://www.together.xyz/blog/redpajama)                                                                                                                                                                                                                                                                                                                                         | native .bin                        |      | 2023-05-02 |
| [wizardLM-LlaMA-LoRA-13](https://huggingface.co/winddude/wizardLM-LlaMA-LoRA-13)                                                         | winddude                     | llama       | 13b        | none                               | modified [evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                                                                                                                                                                                                                                                                    |                                    | yes  | 2023-05-02 |
| [pygmalion-7b](https://huggingface.co/PygmalionAI/pygmalion-7b)                                                                          | PygmalionAI                  | llama       | 7b         | none                               | subset of dataset used for Pygmalion-6B-v8-pt4                                                                                                                                                                                                                                                                                                                                               |                                    |      | 2023-05-01 |
| [stable-vicuna-13b](https://huggingface.co/unamedkr/stable-vicuna-13b)                                                                   | unamedkr                     | vicuna      | 13b        | none                               | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP)                                                                                | native .bin                        |      | 2023-05-01 |
| [metharme-7b](https://huggingface.co/Neko-Institute-of-Science/metharme-7b)                                                              | Neko-Institute-of-Science    | llama       | 7b         | none                               | instruction, roleplay, fictional stories, conversations, synthetic instructions                                                                                                                                                                                                                                                                                                              |                                    |      | 2023-04-30 |
| [pygmalion-7b](https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b)                                                            | Neko-Institute-of-Science    | llama       | 7b         | none                               | subset of dataset used for Pygmalion-6B-v8-pt4                                                                                                                                                                                                                                                                                                                                               |                                    |      | 2023-04-30 |
| [stable-vicuna-13B-4bit-128g-cuda](https://huggingface.co/tsumeone/stable-vicuna-13B-4bit-128g-cuda)                                     | tsumeone                     | vicuna      | 13b        | 4bit GPTQ                          | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP)                                                                                | safetensors                        |      | 2023-04-30 |
| [stable-vicuna-13B-GPTQ](https://huggingface.co/4bit/stable-vicuna-13B-GPTQ)                                                             | 4bit                         | vicuna      | 4b         | 4bit GPTQ                          | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP)                                                                                | safetensors                        |      | 2023-04-30 |
| [Alpaca-LoRA-65B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-65B-elina)                                                               | LLMs                         | alpaca      | 65b        | none                               | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored                                                                                                                                                                                                                                                                                                                | native .bin                        | yes  | 2023-04-29 |
| [GPT4-X-Alpasta-30b-4bit](https://huggingface.co/MetaIX/GPT4-X-Alpasta-30b-4bit)                                                         | MetaIX                       | alpaca      | 30b        | 4bit GPTQ / GGML                   | merge of [Chansung GPT4-Alpaca Lora](https://huggingface.co/chansung/gpt4-alpaca-lora-30b) and [oasst native fine-tune](https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor)                                                                                                                                                                                                      | safetensors, native .bin           |      | 2023-04-29 |
| [ChanSung_Elina_33b-4bit](https://huggingface.co/digitous/ChanSung_Elina_33b-4bit)                                                       | digitous                     | llama       | 33b        | 4bit GPTQ                          | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored                                                                                                                                                                                                                                                                                                                | safetensors                        |      | 2023-04-28 |
| [gpt4-alpaca-lora-13B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-GPTQ-4bit-128g)                               | TheBloke                     | alpaca      | 13b        | 4bit GPTQ                          | chansung/gpt4-alpaca-lora-13b dataset alpaca_data_gpt4.json                                                                                                                                                                                                                                                                                                                                  | safetensors                        |      | 2023-04-28 |
| [oasst-sft-7-llama-30b-xor](https://huggingface.co/OpenAssistant/oasst-sft-7-llama-30b-xor)                                              | OpenAssistant                | llama       | 30b        | none                               | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | native .bin                        |      | 2023-04-28 |
| [stable-vicuna-13b-delta](https://huggingface.co/CarperAI/stable-vicuna-13b-delta)                                                       | CarperAI                     | vicuna      | 13b        | none                               | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP)                                                                                | native .bin                        |      | 2023-04-28 |
| [stable-vicuna-13B-GPTQ](https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ)                                                         | TheBloke                     | vicuna      | 13b        | 4bit GPTQ                          | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP)                                                                                | safetensors                        |      | 2023-04-28 |
| [stable-vicuna-13B-HF](https://huggingface.co/TheBloke/stable-vicuna-13B-HF)                                                             | TheBloke                     | vicuna      | 13b        | none                               | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP)                                                                                | hf .bin                            |      | 2023-04-28 |
| [alpaca-7b-native-enhanced](https://huggingface.co/Pi3141/alpaca-7b-native-enhanced)                                                     | Pi3141                       | alpaca      | 7b         | q4_0, q4_1, q4_2, q4_3, q5_0, q5_1 | [larger dataset?](https://huggingface.co/Pi3141/alpaca-7b-native-enhanced/discussions/2)                                                                                                                                                                                                                                                                                                     | ggml .bin                          |      | 2023-04-27 |
| [GeoV-9b](https://huggingface.co/GeoV/GeoV-9b)                                                                                           | GeoV                         | GeoV        | 9b         | none                               |                                                                                                                                                                                                                                                                                                                                                                                              | native bin                         |      | 2023-04-27 |
| [ggml-LLaMa-65B-quantized](https://huggingface.co/CRD716/ggml-LLaMa-65B-quantized)                                                       | CRD716                       | llama       | 65b        | q4_0, q5_0, q5_1                   |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-27 |
| [Alpaca-LoRA-30B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-30B-elina)                                                               | LLMs                         | alpaca      | 30b        | none                               | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored                                                                                                                                                                                                                                                                                                                | native .bin                        |      | 2023-04-26 |
| [BigCodeAlpaca2048](https://huggingface.co/ArmelR/BigCodeAlpaca2048)                                                                     | ArmelR                       | alpaca?     | ?          | none                               | BigCode?                                                                                                                                                                                                                                                                                                                                                                                     | native .bin                        |      | 2023-04-26 |
| [codecapybara-4bit-128g-gptq](https://huggingface.co/catalpa/codecapybara-4bit-128g-gptq)                                                | catalpa                      | llama       | 7b         | 4bit GPTQ                          | [CodeCapybara](https://github.com/FSoft-AI4Code/CodeCapybara)                                                                                                                                                                                                                                                                                                                                | safetensors                        |      | 2023-04-26 |
| [CodeCapybara](https://huggingface.co/Fsoft-AIC/CodeCapybara)                                                                            | Fsoft-AIC                    | llama       | 7b         | none                               | [CodeCapybara](https://github.com/FSoft-AI4Code/CodeCapybara)                                                                                                                                                                                                                                                                                                                                | native .bin                        |      | 2023-04-26 |
| [codegen-6B-lora](https://huggingface.co/mhhmm/codegen-6B-lora)                                                                          | mhhmm                        | codegen     | 6b         | none                               | Peft/lora finetune with [Leetcode](https://huggingface.co/datasets/mhhmm/leetcode-solutions-python) and [Google Deepmind Code contests](https://huggingface.co/datasets/deepmind/code_contests)                                                                                                                                                                                              | native .bin                        | yes  | 2023-04-26 |
| [llama-65b-ggml-q4_2](https://huggingface.co/camelids/llama-65b-ggml-q4_2)                                                               | camelids                     | llama       | 65b        | q4_2                               |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-26 |
| [llama-natural-instructions-13b](https://huggingface.co/wordcab/llama-natural-instructions-13b)                                          | wordcab                      | llama       | 13b        | none                               | [LoRA of Natural Instructions by AllenAI](https://huggingface.co/datasets/Muennighoff/natural-instructions)                                                                                                                                                                                                                                                                                  |                                    |      | 2023-04-26 |
| [llama-natural-instructions-7b](https://huggingface.co/wordcab/llama-natural-instructions-7b)                                            | wordcab                      | llama       | 7b         | none                               | [LoRA of Natural Instructions by AllenAI](https://huggingface.co/datasets/Muennighoff/natural-instructions)                                                                                                                                                                                                                                                                                  |                                    |      | 2023-04-26 |
| [stablelm-7b-sft-v7-epoch-3-ggml-q4](https://huggingface.co/oeathus/stablelm-7b-sft-v7-epoch-3-ggml-q4)                                  | oeathus                      | stablelm    | 7b         | q4_0, q4_1, q4_2, q4_3             | oasst, vicuna, dolly15k, grade_school_math_instructions, code_alpaca                                                                                                                                                                                                                                                                                                                         | ggml                               |      | 2023-04-26 |
| [stablelm-base-alpha-7b-ggml-q4](https://huggingface.co/oeathus/stablelm-base-alpha-7b-ggml-q4)                                          | oeathus                      | stablelm    | 7b         | q4_0, q4_1, q4_2, q4_3             | [The New Pile](https://pile.eleuther.ai/)                                                                                                                                                                                                                                                                                                                                                    | ggml                               |      | 2023-04-26 |
| [stablelm-tuned-alpha-7b-ggml-q4](https://huggingface.co/oeathus/stablelm-tuned-alpha-7b-ggml-q4)                                        | oeathus                      | stablelm    | 7b         | q4_0, q4_1, q4_2, q4_3             | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    |                                    |      | 2023-04-26 |
| [wizardLM-7B-GGML](https://huggingface.co/TheBloke/wizardLM-7B-GGML)                                                                     | TheBloke                     | llama       | 7b         | q4_0, q4_2, q4_3, q5_0, q5_1       | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                                                                                                                                                                                                                                                                      | ggml                               |      | 2023-04-26 |
| [wizardLM-7B-GPTQ](https://huggingface.co/TheBloke/wizardLM-7B-GPTQ)                                                                     | TheBloke                     | llama       | 7b         | 4bit GPTQ                          | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                                                                                                                                                                                                                                                                      | safetensors                        |      | 2023-04-26 |
| [wizardLM-7B-HF](https://huggingface.co/TheBloke/wizardLM-7B-HF)                                                                         | TheBloke                     | llama       | 7b         | none                               | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                                                                                                                                                                                                                                                                      | hf .bin                            |      | 2023-04-26 |
| [wizardLM-LlaMA-LoRA-7B](https://huggingface.co/winddude/wizardLM-LlaMA-LoRA-7B)                                                         | winddude                     | llama       | 7b         | none                               | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                                                                                                                                                                                                                                                                      | native .bin                        | yes  | 2023-04-26 |
| [llama-30b-4bit-128g](https://huggingface.co/kajdun/llama-30b-4bit-128g)                                                                 | kajdun                       | llama       | 30b        | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | safetensors                        | yes  | 2023-04-25 |
| [WizardLM](https://huggingface.co/victor123/WizardLM)                                                                                    | victor123                    | llama       | 7b         | none                               | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                                                                                                                                                                                                                                                                      | native .bin                        |      | 2023-04-25 |
| [Alpaca-LoRA-13B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-13B-elina)                                                               | LLMs                         | alpaca      | 13b        | none                               | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored                                                                                                                                                                                                                                                                                                                | native .bin                        | yes  | 2023-04-24 |
| [ggml-oasst-sft-6-llama-30B-q4_0](https://huggingface.co/MildlyAggressiveGoose1/ggml-oasst-sft-6-llama-30B-q4_0)                         | MildlyAggressiveGoose1       | llama       | 30b        | q4_0                               | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                               |      | 2023-04-24 |
| [ggml-oasst-sft-6-llama-30B-q4_2](https://huggingface.co/MildlyAggressiveGoose1/ggml-oasst-sft-6-llama-30B-q4_2)                         | MildlyAggressiveGoose1       | llama       | 30b        | q4_2                               | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                               |      | 2023-04-24 |
| [gpt4all-13b-snoozy](https://huggingface.co/nomic-ai/gpt4all-13b-snoozy)                                                                 | nomic-ai                     | llama       | 13b        | none                               | [gpt4all-j-prompt-generations](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations)                                                                                                                                                                                                                                                                                        | native .bin                        |      | 2023-04-24 |
| [Alpaca-LoRA-7B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-7B-elina)                                                                 | LLMs                         | alpaca      | 7b         | none                               | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored                                                                                                                                                                                                                                                                                                                | native .bin                        | yes  | 2023-04-23 |
| [CodeGen-2B-multi-ggml-quant](https://huggingface.co/ravenscroftj/CodeGen-2B-multi-ggml-quant)                                           | ravenscroftj                 | codegen     | 2b         | 4bit ?                             | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml                               |      | 2023-04-23 |
| [CodeGen-6B-multi-ggml-quant](https://huggingface.co/ravenscroftj/CodeGen-6B-multi-ggml-quant)                                           | ravenscroftj                 | codegen     | 6b         | 4bit ?                             | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml                               |      | 2023-04-23 |
| [gpt4tools-vicuna-13b-lora](https://huggingface.co/stevengrove/gpt4tools-vicuna-13b-lora)                                                | stevengrove                  | vicuna      | 13b        | none                               | [gpt4tools_71k.json](https://github.com/StevenGrove/GPT4Tools#Dataset) which is a mix of [alpaca_gpt4_data](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data.json) and synthetic GPT3.5 instructions                                                                                                                                               |                                    | yes  | 2023-04-23 |
| [h2ogpt-oasst1-512-20b](https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b)                                                              | h2oai                        | gpt-neox    | 20b        | none                               | [openassistant_oasst1](https://huggingface.co/datasets/h2oai/openassistant_oasst1)                                                                                                                                                                                                                                                                                                           | native .bin                        |      | 2023-04-23 |
| [llama-13b-SuperCOT-4bit-TRITON](https://huggingface.co/TheYuriLover/llama-13b-SuperCOT-4bit-TRITON)                                     | TheYuriLover                 | llama       | 13b        | 4bit GPTQ                          | [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [neulab/conala](https://huggingface.co/datasets/neulab/conala), [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)                                                                                                                                                                                    | triton safetensors                 |      | 2023-04-23 |
| [MiniGPT4-7B](https://huggingface.co/camenduru/MiniGPT4-7B)                                                                              | camenduru                    | vicuna      | 7b         | none                               | minigpt-4                                                                                                                                                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-04-23 |
| [OpenAssistant-Llama-30b-4bit](https://huggingface.co/MetaIX/OpenAssistant-Llama-30b-4bit)                                               | MetaIX                       | llama       | 30b        | 4bit GPTQ                          | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | safetensors / ggml                 |      | 2023-04-23 |
| [stablelm-7b-sft-v7-epoch-3](https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3)                                            | OpenAssistant                | stablelm    | 7b         | none                               | oasst, vicuna, dolly15k, grade_school_math_instructions, code_alpaca                                                                                                                                                                                                                                                                                                                         | native .bin                        |      | 2023-04-23 |
| [alpaca-lora-65B-GGML](https://huggingface.co/TheBloke/alpaca-lora-65B-GGML)                                                             | TheBloke                     | alpaca      | 65b        | 4bit/2bit                          | Alpaca LoRa                                                                                                                                                                                                                                                                                                                                                                                  | ggml                               |      | 2023-04-22 |
| [dolly-v2-12b-sharded](https://huggingface.co/ethzanalytics/dolly-v2-12b-sharded)                                                        | ethzanalytics                | dolly       | 12b        | none                               | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | hf .bin                            |      | 2023-04-22 |
| [dolly-v2-7b-sharded](https://huggingface.co/ethzanalytics/dolly-v2-7b-sharded)                                                          | ethzanalytics                | dolly       | 7b         | none                               | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | hf .bin                            |      | 2023-04-22 |
| [ggml-vicuna-13b-1.1](https://huggingface.co/eachadea/ggml-vicuna-13b-1.1)                                                               | eachadea                     | vicuna-v1.1 | 13b        | q4_0, q4_1, q4_2, q4_3, q5_0, q5_1 | vicuna 1.1 censored, vicuna 1.0 uncensored                                                                                                                                                                                                                                                                                                                                                   | ggml .bin                          |      | 2023-04-22 |
| [GPT4-x-Alpaca13b-RolePlayLora-4bit-v2](https://huggingface.co/teknium/GPT4-x-Alpaca13b-RolePlayLora-4bit-v2)                            | teknium                      | llama       | 13b        | 4bit GPTQ                          | gpt4-x-alpaca finetune, [roleplay instruct](https://github.com/teknium1/GPTeacher/tree/main/Roleplay)                                                                                                                                                                                                                                                                                        | safetensors                        |      | 2023-04-22 |
| [h2ogpt-oig-oasst1-512-6.9b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-512-6.9b)                                                    | h2oai                        | pythia      | 6.9b       | none                               | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                        |      | 2023-04-22 |
| [llama_30b_corr](https://huggingface.co/prodm93/llama_30b_corr)                                                                          | prodm93                      | llama       | 30b        | none                               |                                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                            |      | 2023-04-22 |
| [llama-13b-hf](https://huggingface.co/luodian/llama-13b-hf)                                                                              | luodian                      | llama       | 13b        | none                               | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                            |      | 2023-04-22 |
| [llama-13b-supercot-4bit-128g](https://huggingface.co/ausboss/llama-13b-supercot-4bit-128g)                                              | ausboss                      | llama       | 13b        | 4bit GPTQ                          | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-13b)                                                                                                                                                                                                                                                                 | safetensors                        |      | 2023-04-22 |
| [llama-30b-hf-transformers-4.29](https://huggingface.co/elinas/llama-30b-hf-transformers-4.29)                                           | elinas                       | llama       | 30b        | none                               | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                            |      | 2023-04-22 |
| [llama-30b-supercot-4bit-128g-cuda](https://huggingface.co/tsumeone/llama-30b-supercot-4bit-128g-cuda)                                   | tsumeone                     | llama       | 30b        | 4bit GPTQ                          | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-30b)                                                                                                                                                                                                                                                                 | safetensors                        |      | 2023-04-22 |
| [llama-65b-hf-transformers-4.29](https://huggingface.co/elinas/llama-65b-hf-transformers-4.29)                                           | elinas                       | llama       | 65b        | none                               | llama                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                            |      | 2023-04-22 |
| [llama-7b-hf-transformers-4.29](https://huggingface.co/elinas/llama-7b-hf-transformers-4.29)                                             | elinas                       | llama       | 7b         | none                               | llama                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                            |      | 2023-04-22 |
| [llama-7b-hf](https://huggingface.co/fragro/llama-7b-hf)                                                                                 | fragro                       | llama       | 7b         | none                               | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                            |      | 2023-04-22 |
| [llama-7b-hf](https://huggingface.co/luodian/llama-7b-hf)                                                                                | luodian                      | llama       | 7b         | none                               | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                            |      | 2023-04-22 |
| [medalpaca-13B-GPTQ-4bit](https://huggingface.co/TheBloke/medalpaca-13B-GPTQ-4bit)                                                       | TheBloke                     | alpaca      | 13b        | 4bit GPTQ                          | [ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor), [Wikidoc](https://www.wikidoc.org/index.php/Main_Page), Stackexchange academia bio fitness health bioinformatics, Anki flashcards                                                                                                                                                                                                     | safetensors                        |      | 2023-04-22 |
| [MiniGPT-4-LLaMA-7B](https://huggingface.co/wangrongsheng/MiniGPT-4-LLaMA-7B)                                                            | wangrongsheng                | vicuna      | 7b         | none                               | minigpt-4                                                                                                                                                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-04-22 |
| [oasst-sft-6-llama-30b-xor](https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor)                                              | OpenAssistant                | llama       | 30b        | none                               | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | native .bin                        |      | 2023-04-22 |
| [stablelm-base-alpha-7b-sharded](https://huggingface.co/ethzanalytics/stablelm-base-alpha-7b-sharded)                                    | ethzanalytics                | stablelm    | 7b         | none                               | [The New Pile](https://pile.eleuther.ai/)                                                                                                                                                                                                                                                                                                                                                    | hf .bin                            |      | 2023-04-22 |
| [stablelm-tuned-alpha-3b-sharded](https://huggingface.co/ethzanalytics/stablelm-tuned-alpha-3b-sharded)                                  | ethzanalytics                | stablelm    | 3b         | none                               | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | hf .bin                            |      | 2023-04-22 |
| [stablelm-tuned-alpha-7b-sharded](https://huggingface.co/ethzanalytics/stablelm-tuned-alpha-7b-sharded)                                  | ethzanalytics                | stablelm    | 7b         | none                               | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | hf .bin                            |      | 2023-04-22 |
| [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA)                                                                         | kaiokendev                   | llama       | 7b/13b/30b | 4bit GPTQ                          | [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [neulab/conala](https://huggingface.co/datasets/neulab/conala), [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)                                                                                                                                                                                    | native .bin / ggml                 | yes  | 2023-04-22 |
| [llama-13b-supercot](https://huggingface.co/ausboss/llama-13b-supercot)                                                                  | ausboss                      | llama       | 13b        | none                               | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-13b)                                                                                                                                                                                                                                                                 | native .bin                        |      | 2023-04-21 |
| [llama-30b-supercot](https://huggingface.co/ausboss/llama-30b-supercot)                                                                  | ausboss                      | llama       | 30b        | none                               | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-30b)                                                                                                                                                                                                                                                                 | native .bin                        |      | 2023-04-21 |
| [llava-13b-v0-4bit-128g](https://huggingface.co/wojtab/llava-13b-v0-4bit-128g)                                                           | wojtab                       | llava       | 13b        | 4bit                               | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | safetensors                        |      | 2023-04-21 |
| [oasst-stablelm-7b-sft-v7-epoch-3-ggml-f16](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-f16)   | mongolian-basket-weaving     | stablelm    | 7b         | 16bit                              | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                               |      | 2023-04-21 |
| [oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_2](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_2) | mongolian-basket-weaving     | stablelm    | 7b         | 4bit                               | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                               |      | 2023-04-21 |
| [oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_3](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_3) | mongolian-basket-weaving     | stablelm    | 7b         | 4bit                               | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                               |      | 2023-04-21 |
| [rwkv-4-raven](https://huggingface.co/BlinkDL/rwkv-4-raven)                                                                              | BlinkDL                      | rwkv        | 3b/7b/14b  | none                               | The Pile, Alpaca, CodeAlpaca, Guanaco, GPT4All, ShareGPT                                                                                                                                                                                                                                                                                                                                     | .pth                               |      | 2023-04-21 |
| [alpaca-lora-65B-GGML](https://huggingface.co/TheBloke/alpaca-lora-65B-GGML)                                                             | TheBloke                     | alpaca      | 65b        | q2_0, q4_0, q4_2, q4_3             | GPT 3.5 Alpaca dataset?                                                                                                                                                                                                                                                                                                                                                                      | ggml .bin                          |      | 2023-04-20 |
| [alpaca-lora-65B-GPTQ-4bit](https://huggingface.co/TheBloke/alpaca-lora-65B-GPTQ-4bit)                                                   | TheBloke                     | alpaca      | 65b        | 4bit GPTQ                          | GPT 3.5 Alpaca dataset?                                                                                                                                                                                                                                                                                                                                                                      | safetensors                        |      | 2023-04-20 |
| [alpaca-lora-65B-GPTQ-4bit](https://huggingface.co/TheBloke/alpaca-lora-65B-GPTQ-4bit)                                                   | TheBloke                     | alpaca      | 65b        | 4bit GPTQ                          | Alpaca LoRa                                                                                                                                                                                                                                                                                                                                                                                  | ?                                  | ?    | 2023-04-20 |
| [llama_65b_corr](https://huggingface.co/prodm93/llama_65b_corr)                                                                          | prodm93                      | llama       | 65b        | none                               |                                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                            |      | 2023-04-20 |
| [llama_7b_corr](https://huggingface.co/prodm93/llama_7b_corr)                                                                            | prodm93                      | llama       | 7b         | none                               |                                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                            |      | 2023-04-20 |
| [llama-30b-oasst-4bit-128g](https://huggingface.co/Peeepy/llama-30b-oasst-4bit-128g)                                                     | Peeepy                       | llama       | 30b        | 4bit                               | oasst-lora                                                                                                                                                                                                                                                                                                                                                                                   | safetensors                        |      | 2023-04-20 |
| [llama-30b-oasst-4bit](https://huggingface.co/Peeepy/llama-30b-oasst-4bit)                                                               | Peeepy                       | llama       | 30b        | 4bit                               | oasst-lora                                                                                                                                                                                                                                                                                                                                                                                   | safetensors                        |      | 2023-04-20 |
| [llama-30b-oasst](https://huggingface.co/Peeepy/llama-30b-oasst)                                                                         | Peeepy                       | llama       | 30b        | none                               | oasst-lora                                                                                                                                                                                                                                                                                                                                                                                   | native .bin                        |      | 2023-04-20 |
| [llava-13b-fp16-safetensors](https://huggingface.co/mongolian-basket-weaving/llava-13b-fp16-safetensors)                                 | mongolian-basket-weaving     | llava       | 13b        | 16bit                              | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | safetensors                        |      | 2023-04-20 |
| [llava-13b-fp16](https://huggingface.co/mongolian-basket-weaving/llava-13b-fp16)                                                         | mongolian-basket-weaving     | llava       | 13b        | 16bit                              | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | native .bin                        |      | 2023-04-20 |
| [MiniGPT-4-LLaMA](https://huggingface.co/wangrongsheng/MiniGPT-4-LLaMA)                                                                  | wangrongsheng                | vicuna      | 13b        | none                               | minigpt-4                                                                                                                                                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-04-20 |
| [stablelm-tuned-alpha-3b-16bit](https://huggingface.co/vvsotnikov/stablelm-tuned-alpha-3b-16bit)                                         | vvsotnikov                   | stablelm    | 3b         | 16bit                              | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | safetensors / .bin                 |      | 2023-04-20 |
| [stablelm-tuned-alpha-7b-16bit](https://huggingface.co/vvsotnikov/stablelm-tuned-alpha-7b-16bit)                                         | vvsotnikov                   | stablelm    | 7b         | 16bit                              | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | safetensors / .bin                 |      | 2023-04-20 |
| [ggml-vicuna-7b-1.1](https://huggingface.co/eachadea/ggml-vicuna-7b-1.1)                                                                 | eachadea                     | vicuna-v1.1 | 7b         | 4bit                               | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-19 |
| [h2ogpt-oig-oasst1-256-20b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-20b)                                                      | h2oai                        | gpt-neox    | 20b        | none                               | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                        |      | 2023-04-19 |
| [MiniGPT-4](https://huggingface.co/Vision-CAIR/MiniGPT-4)                                                                                | Vision-CAIR                  | vicuna      | 7b         | none                               | minigpt-4                                                                                                                                                                                                                                                                                                                                                                                    | .pth                               |      | 2023-04-19 |
| [stablelm-tuned-alpha-3b/](https://huggingface.co/stabilityai/stablelm-tuned-alpha-3b/)                                                  | stabilityai                  | stablelm    | 3b         | none                               | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-04-19 |
| [stablelm-tuned-alpha-7b/](https://huggingface.co/stabilityai/stablelm-tuned-alpha-7b/)                                                  | stabilityai                  | stablelm    | 7b         | none                               | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-04-19 |
| [vicuna-13b-GPTQ-4bit-128g](https://huggingface.co/4bit/vicuna-13b-GPTQ-4bit-128g)                                                       | 4bit                         | vicuna      | 13b        | 4bit GPTQ                          | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                        |      | 2023-04-19 |
| [Alpacino-30b-ggml](https://huggingface.co/Melbourne/Alpacino-30b-ggml)                                                                  | Melbourne                    | alpaca      | 30b        | q4_0                               | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | ggml                               |      | 2023-04-17 |
| [h2ogpt-oasst1-512-12b](https://huggingface.co/h2oai/h2ogpt-oasst1-512-12b)                                                              | h2oai                        | pythia      | 12b        | none                               | [openassistant_oasst1](https://huggingface.co/datasets/h2oai/openassistant_oasst1)                                                                                                                                                                                                                                                                                                           | native .bin                        |      | 2023-04-17 |
| [h2ogpt-oig-oasst1-256-12b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-12b)                                                      | h2oai                        | gpt-neox    | 12b        | none                               | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                        |      | 2023-04-17 |
| [h2ogpt-oig-oasst1-256-12b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-12b)                                                      | h2oai                        | pythia      | 12b        | none                               | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                        |      | 2023-04-17 |
| [LLaVA-13b-delta-v0](https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0)                                                               | liuhaotian                   | llava       | 13b        | 16bit                              | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | native .bin                        |      | 2023-04-17 |
| [stablelm-base-alpha-3b/](https://huggingface.co/stabilityai/stablelm-base-alpha-3b/)                                                    | stabilityai                  | stablelm    | 3b         | none                               | [The New Pile](https://pile.eleuther.ai/)                                                                                                                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-04-17 |
| [alpacino-13b-4bit-128g](https://huggingface.co/gozfarb/alpacino-13b-4bit-128g)                                                          | gozfarb                      | alpaca      | 13b        | 4bit                               | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | safetensors                        |      | 2023-04-15 |
| [Alpacino-13b-ggml](https://huggingface.co/verymuchawful/Alpacino-13b-ggml)                                                              | verymuchawful                | alpaca      | 13b        | 16bit                              | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | ggml                               |      | 2023-04-15 |
| [GPT4-X-Alpaca-30B-4bit](https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-4bit)                                                           | MetaIX                       | alpaca      | 30b        | 4bit GPTQ                          | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           |                                    |      | 2023-04-15 |
| [vicuna-13b-1_1-hf](https://huggingface.co/winglian/vicuna-13b-1_1-hf)                                                                   | winglian                     | vicuna-v1.1 | 13b        | none                               | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                            |      | 2023-04-15 |
| [vicuna-13B-1.1-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g)                                           | TheBloke                     | vicuna-v1.1 | 13b        | 4bit GPTQ                          | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | triton pt / cuda safetensors       |      | 2023-04-15 |
| [vicuna-13B-1.1-HF](https://huggingface.co/TheBloke/vicuna-13B-1.1-HF)                                                                   | TheBloke                     | vicuna-v1.1 | 13b        | 16bit                              | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                            |      | 2023-04-15 |
| [vicuna-13b](https://huggingface.co/helloollel/vicuna-13b)                                                                               | helloollel                   | vicuna      | 13b        | 16bit                              | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | native .bin                        |      | 2023-04-15 |
| [Vicuna-7B-4bit-ggml](https://huggingface.co/Sosaka/Vicuna-7B-4bit-ggml)                                                                 | Sosaka                       | vicuna      | 7b         | q4_0                               | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ggml .bin                          |      | 2023-04-15 |
| [vicuna-7b](https://huggingface.co/helloollel/vicuna-7b)                                                                                 | helloollel                   | vicuna      | 7b         | 16bit                              | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       |                                    |      | 2023-04-15 |
| [Vicuna13B-v1.1-8bit-128g](https://huggingface.co/Thireus/Vicuna13B-v1.1-8bit-128g)                                                      | Thireus                      | vicuna-v1.1 | 13b        | 8bit GPTQ                          | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                        |      | 2023-04-15 |
| [Alpacino30b](https://huggingface.co/digitous/Alpacino30b)                                                                               | digitous                     | alpaca      | 30b        | 16bit                              | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | native .bin                        |      | 2023-04-14 |
| [Alpacino13b](https://huggingface.co/digitous/Alpacino13b)                                                                               | digitous                     | alpaca      | 13b        | 16bit                              | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | native .bin                        |      | 2023-04-13 |
| [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b)                                                                             | databricks                   | dolly       | 3b         | none                               | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | native .bin                        |      | 2023-04-13 |
| [dolly-v2-7b](https://huggingface.co/databricks/dolly-v2-7b)                                                                             | databricks                   | dolly       | 7b         | none                               | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | native .bin                        |      | 2023-04-13 |
| [ggml-vicuna-1.1-q4_0](https://huggingface.co/CRD716/ggml-vicuna-1.1-q4_0)                                                               | CRD716                       | vicuna-v1.1 | 13b        | q4_0, q5_0, f16                    | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-13 |
| [ggml-vicuna-1.1-q4_0](https://huggingface.co/CRD716/ggml-vicuna-1.1-q4_0)                                                               | CRD716                       | vicuna-v1.1 | 7b         | q4_0, f16                          | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-13 |
| [llama-adapter-7b](https://huggingface.co/winglian/llama-adapter-7b)                                                                     | winglian                     | llama       | 7b         | none                               | [alpaca_data_gpt4.json](https://github.com/tloen/alpaca-lora/blob/main/alpaca_data_gpt4.json)                                                                                                                                                                                                                                                                                                | native .bin                        | yes  | 2023-04-13 |
| [vicuna-13b-1.1](https://huggingface.co/eachadea/vicuna-13b-1.1)                                                                         | eachadea                     | vicuna      | 13b        | none                               | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) [llama](https://huggingface.co/datasets/viewv/LLaMA-13B) [shareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                         | native .bin                        |      | 2023-04-13 |
| [Base-GPT4-x-Alpaca-Roleplay-Lora](https://huggingface.co/teknium/Base-GPT4-x-Alpaca-Roleplay-Lora)                                      | teknium                      | llama       | 13b        | none                               | gpt4-x-alpaca finetune, [roleplay instruct](https://github.com/teknium1/GPTeacher/tree/main/Roleplay)                                                                                                                                                                                                                                                                                        |                                    |      | 2023-04-12 |
| [dolly-v2-12b-GPTQ-4bit-128g](https://huggingface.co/mzedp/dolly-v2-12b-GPTQ-4bit-128g)                                                  | mzedp                        | dolly       | 12b        | 4bit                               | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | safetensors                        |      | 2023-04-12 |
| [dolly-v2-12b](https://huggingface.co/databricks/dolly-v2-12b)                                                                           | databricks                   | dolly       | 12b        | none                               | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | native .bin                        |      | 2023-04-12 |
| [gpt4-x-alpaca-13b-native-4bit-128g](https://huggingface.co/Selyam/gpt4-x-alpaca-13b-native-4bit-128g)                                   | Selyam                       | alpaca      | 13b        | 4bit GPTQ                          | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | triton / cuda                      |      | 2023-04-12 |
| [vicuna-13B-1.1-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g-GGML)                                 | TheBloke                     | vicuna-v1.1 | 13b        | 4bit GPTQ                          | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-12 |
| [vicuna-7B-1.1-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/vicuna-7B-1.1-GPTQ-4bit-128g-GGML)                                   | TheBloke                     | vicuna-v1.1 | 7b         | 4bit GPTQ                          | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-12 |
| [vicuna-7B-1.1-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-7B-1.1-GPTQ-4bit-128g)                                             | TheBloke                     | vicuna-v1.1 | 7b         | 4bit GPTQ                          | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | triton pt / cuda safetensors       |      | 2023-04-12 |
| [vicuna-7B-1.1-HF](https://huggingface.co/TheBloke/vicuna-7B-1.1-HF)                                                                     | TheBloke                     | vicuna-v1.1 | 7b         | 16bit                              | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                            |      | 2023-04-12 |
| [gpt4all-j](https://huggingface.co/nomic-ai/gpt4all-j)                                                                                   | nomic-ai                     | gpt-j       | 6b         | 16bit                              | [gpt4all-j-prompt-generations](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations)                                                                                                                                                                                                                                                                                        | native .bin                        |      | 2023-04-11 |
| [llama-13b-pretrained-dropout-hf-int4-128g](https://huggingface.co/verymuchawful/llama-13b-pretrained-dropout-hf-int4-128g)              | verymuchawful                | llama       | 13b        | 4bit GPTQ                          | Open-Assistant?                                                                                                                                                                                                                                                                                                                                                                              | safetensors                        |      | 2023-04-11 |
| [stablelm-base-alpha-7b/](https://huggingface.co/stabilityai/stablelm-base-alpha-7b/)                                                    | stabilityai                  | stablelm    | 7b         | none                               | [The New Pile](https://pile.eleuther.ai/)                                                                                                                                                                                                                                                                                                                                                    | native .bin                        |      | 2023-04-11 |
| [vicuba-7b-int4-128g](https://huggingface.co/gozfarb/vicuba-7b-int4-128g)                                                                | gozfarb                      | vicuna      | 7b         | 4bit GPTQ                          | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                                                                                                                                             | safetensors                        |      | 2023-04-11 |
| [instruct-13b-4bit-128g](https://huggingface.co/gozfarb/instruct-13b-4bit-128g)                                                          | gozfarb                      | llama       | 13b        | 4bit GPTQ?                         | instruct-13b weights                                                                                                                                                                                                                                                                                                                                                                         | safetensors                        |      | 2023-04-10 |
| [instruct-13b-4bit-ggml](https://huggingface.co/llama-anon/instruct-13b-4bit-ggml)                                                       | llama-anon                   | llama       | 13b        | q4_0                               | instruct-13b weights                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                          |      | 2023-04-10 |
| [vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g)                       | TheBloke                     | vicuna      | 7b         | 4bit GPTQ                          | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                                                                                                                                             | safetensors                        |      | 2023-04-10 |
| [koala-13B-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g-GGML)                                           | TheBloke                     | llama       | 13b        | 4bit GPTQ                          | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | ggml                               |      | 2023-04-09 |
| [koala-13B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g)                                                     | TheBloke                     | llama       | 13b        | 4bit GPTQ                          | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | triton pt / cuda safetensors       |      | 2023-04-09 |
| [koala-7B-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g-GGML)                                             | TheBloke                     | llama       | 7b         | 4bit GPTQ                          | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | ggml                               |      | 2023-04-09 |
| [koala-7B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g)                                                       | TheBloke                     | llama       | 7b         | 4bit GPTQ                          | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | triton pt / cuda safetensors       |      | 2023-04-09 |
| [llama-13b-4bit-gr128](https://huggingface.co/4bit/llama-13b-4bit-gr128)                                                                 | 4bit                         | llama       | 13b        | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                             |      | 2023-04-09 |
| [pythia-6.9b-gpt4all-pretrain](https://huggingface.co/andreaskoepf/pythia-6.9b-gpt4all-pretrain)                                         | andreaskoepf                 | pythia      | 6.9b       | 16bit                              | Open-Assistant? gpt4all?                                                                                                                                                                                                                                                                                                                                                                     | native .bin                        |      | 2023-04-09 |
| [gpt4-x-alpaca-13b-native-4bit-128g-cuda](https://huggingface.co/tsumeone/gpt4-x-alpaca-13b-native-4bit-128g-cuda)                       | tsumeone                     | alpaca      | 13b        | 4bit                               | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | cuda safetensors                   |      | 2023-04-08 |
| [oasst-llama30b-ggml-q4](https://huggingface.co/Black-Engineer/oasst-llama30b-ggml-q4)                                                   | Black-Engineer               | llama       | 30b        | q4_0                               | Open-Assistant, Alpaca                                                                                                                                                                                                                                                                                                                                                                       | ggml                               |      | 2023-04-08 |
| [alpaca-native-7B-4bit-ggjt](https://huggingface.co/LLukas22/alpaca-native-7B-4bit-ggjt)                                                 | LLukas22                     | alpaca      | 7b         | 4bit GPTQ?                         |                                                                                                                                                                                                                                                                                                                                                                                              | ggjt                               |      | 2023-04-07 |
| [koala-13B-HF](https://huggingface.co/TheBloke/koala-13B-HF)                                                                             | TheBloke                     | llama       | 13b        | 16bit                              | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | native .bin                        |      | 2023-04-07 |
| [koala-7B-HF](https://huggingface.co/TheBloke/koala-7B-HF)                                                                               | TheBloke                     | llama       | 7b         | 16bit                              | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | native .bin                        |      | 2023-04-07 |
| [llama-13b-pretrained-sft-do2-ggml-q4](https://huggingface.co/Black-Engineer/llama-13b-pretrained-sft-do2-ggml-q4)                       | Black-Engineer               | llama       | 13b        | q4_0                               | ?                                                                                                                                                                                                                                                                                                                                                                                            | ggml                               |      | 2023-04-07 |
| [oasst-llama13b-ggml](https://huggingface.co/Black-Engineer/oasst-llama13b-ggml)                                                         | Black-Engineer               | llama       | 13b        | 16bit                              | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ? .bin                             |      | 2023-04-07 |
| [Alpaca-30B-Int4-128G-Safetensors](https://huggingface.co/MetaIX/Alpaca-30B-Int4-128G-Safetensors)                                       | MetaIX                       | alpaca      | 30b        | 4bit                               | Clean Alpaca dataset of 2023-04-06 using Chansung ALpaca Lora                                                                                                                                                                                                                                                                                                                                | safetensor                         |      | 2023-04-06 |
| [ggml-gpt4-x-alpaca-13b-native-4bit](https://huggingface.co/eachadea/ggml-gpt4-x-alpaca-13b-native-4bit)                                 | eachadea                     | alpaca      | 13b        | 4bit                               | Alpaca                                                                                                                                                                                                                                                                                                                                                                                       | ggml                               |      | 2023-04-06 |
| [gpt4all-alpaca-oa-codealpaca-lora-13b](https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b)                         | jordiclive                   | alpaca      | 13b        | ?                                  | Nebulous/gpt4all_pruned, sahil2801/CodeAlpaca-20k, yahma/alpaca-cleaned, part of OpenAssistant                                                                                                                                                                                                                                                                                               | native .bin                        | yes  | 2023-04-06 |
| [koala-7b-ggml-unquantized](https://huggingface.co/TheBloke/koala-7b-ggml-unquantized)                                                   | TheBloke                     | llama       | 7b         | 16bit                              | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | ggml                               |      | 2023-04-06 |
| [llama-13b-pretrained-sft-do2](https://huggingface.co/dvruette/llama-13b-pretrained-sft-do2)                                             | dvruette                     | llama       | 13b        | 16bit                              | ?                                                                                                                                                                                                                                                                                                                                                                                            | native .bin                        |      | 2023-04-06 |
| [oasst-llama13b-ggml-q4](https://huggingface.co/Black-Engineer/oasst-llama13b-ggml-q4)                                                   | Black-Engineer               | llama       | 13b        | q4_0                               | Open-Assistant, Alpaca                                                                                                                                                                                                                                                                                                                                                                       | ggml                               |      | 2023-04-06 |
| [vicuna-13b/tree/main](https://huggingface.co/jeffwan/vicuna-13b/tree/main)                                                              | jeffwan                      | vicuna      | 13b        | ?                                  | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ?                                  |      | 2023-04-06 |
| [alpaca-lora-13b](https://huggingface.co/chansung/alpaca-lora-13b)                                                                       | chansung                     | alpaca      | 13b        | 8bit                               | [cleaned-up aplaca dataset](https://github.com/gururise/AlpacaDataCleaned)                                                                                                                                                                                                                                                                                                                   | native .bin                        | yes  | 2023-04-05 |
| [ggml-vicuna-13b-4bit](https://huggingface.co/eachadea/ggml-vicuna-13b-4bit)                                                             | eachadea                     | vicuna      | 13b        | 4bit GPTQ?                         | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ggml .bin                          |      | 2023-04-05 |
| [ggml-vicuna-7b-4bit](https://huggingface.co/eachadea/ggml-vicuna-7b-4bit)                                                               | eachadea                     | vicuna      | 7b         | 4bit                               | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ggml                               |      | 2023-04-05 |
| [llama-13b-pretrained-dropout](https://huggingface.co/dvruette/llama-13b-pretrained-dropout)                                             | dvruette                     | llama       | 13b        | 16bit                              | Open-Assistant?                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        |      | 2023-04-05 |
| [llama30b-lora-cot](https://huggingface.co/magicgh/llama30b-lora-cot)                                                                    | magicgh                      | llama       | 30b        | ?                                  | Alpaca-CoT                                                                                                                                                                                                                                                                                                                                                                                   | .bin                               | yes  | 2023-04-05 |
| [Vicuna-13b](https://huggingface.co/titan087/Vicuna-13b)                                                                                 | titan087                     | vicuna      | 13b        | 16bit                              |                                                                                                                                                                                                                                                                                                                                                                                              | ?                                  |      | 2023-04-05 |
| [vicuna-7b](https://huggingface.co/AlekseyKorshuk/vicuna-7b)                                                                             | AlekseyKorshuk               | vicuna      | 7b         | none                               | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                                                                                                                                             | native .bin                        |      | 2023-04-05 |
| [gpt4all-alpaca-oa-codealpaca-lora-7b](https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-7b)                           | jordiclive                   | alpaca      | 7b         | ?                                  | [gpt4all_pruned](https://huggingface.co/datasets/Nebulous/gpt4all_pruned)<br />[CodeAlpaca-20k](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)<br />[alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)                                                                                                                                                        | ?                                  | yes  | 2023-04-04 |
| [vicuna-13b-4bit](https://huggingface.co/elinas/vicuna-13b-4bit)                                                                         | elinas                       | vicuna      | 13b        | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | safetensors                        |      | 2023-04-04 |
| [vicuna-13b-8bit](https://huggingface.co/samwit/vicuna-13b-8bit)                                                                         | samwit                       | vicuna      | 13b        | 8bit                               |                                                                                                                                                                                                                                                                                                                                                                                              | ?                                  |      | 2023-04-04 |
| [Vicuna-13B](https://huggingface.co/ShreyasBrill/Vicuna-13B)                                                                             | ShreyasBrill                 | vicuna      | 13b        | q4_0                               | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) [llama](https://huggingface.co/datasets/viewv/LLaMA-13B) [shareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                         | ggml .bin                          |      | 2023-04-04 |
| [alpaca-lora-65b](https://huggingface.co/chansung/alpaca-lora-65b)                                                                       | chansung                     | alpaca      | 65b        | 16bit                              | GPT 3.5 Alpaca dataset?                                                                                                                                                                                                                                                                                                                                                                      | native .bin                        | yes  | 2023-04-03 |
| [oasst-pythia-12b-pretrained](https://huggingface.co/dvruette/oasst-pythia-12b-pretrained)                                               | dvruette                     | pythia      | 12b        | 16bit                              | Open-Assistant?                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        |      | 2023-04-03 |
| [oasst-pythia-12b-reference](https://huggingface.co/dvruette/oasst-pythia-12b-reference)                                                 | dvruette                     | pythia      | 12b        | 16bit                              | ?                                                                                                                                                                                                                                                                                                                                                                                            | native .bin                        |      | 2023-04-03 |
| [pythia-12b-pre-2000](https://huggingface.co/andreaskoepf/pythia-12b-pre-2000)                                                           | andreaskoepf                 | pythia      | 12b        | 16bit                              | joke, webgpt, gpt4all, alpaca, code_alpaca, minimath, codegen, testgen, grade school math, recipes, cmu wiki, oa wiki, prosocial dialogue, explain prosocial                                                                                                                                                                                                                                 | native .bin                        |      | 2023-04-03 |
| [vicuna-13b-delta-v0](https://huggingface.co/lmsys/vicuna-13b-delta-v0)                                                                  | lmsys                        | vicuna      | 13b        | 16bit                              |                                                                                                                                                                                                                                                                                                                                                                                              | ?                                  |      | 2023-04-03 |
| [vicuna-13b-GPTQ-4bit-128g](https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g)                                             | anon8231489123               | vicuna      | 13b        | 4bit GPTQ                          | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                        |      | 2023-04-03 |
| [vicuna-13b](https://huggingface.co/eachadea/vicuna-13b)                                                                                 | eachadea                     | vicuna      | 13b        | 16bit                              | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ?                                  |      | 2023-04-03 |
| [alpaca-13B-ggml](https://huggingface.co/Pi3141/alpaca-13B-ggml)                                                                         | Pi3141                       | alpaca      | 13b        | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          | yes  | 2023-04-02 |
| [alpaca-30B-ggml](https://huggingface.co/Pi3141/alpaca-30B-ggml)                                                                         | Pi3141                       | alpaca      | 30b        | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-04-01 |
| [gpt4-x-alpaca-13b-native-4bit-128g](https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g)                           | anon8231489123               | alpaca      | 13b        | 4bit GPTQ                          | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | triton / cuda                      |      | 2023-04-01 |
| [pythia-12b-pre-3500](https://huggingface.co/andreaskoepf/pythia-12b-pre-3500)                                                           | andreaskoepf                 | pythia      | 12b        | 16bit                              | joke, webgpt, gpt4all, alpaca, code_alpaca, minimath, codegen, testgen, grade school math, recipes, cmu wiki, oa wiki, prosocial dialogue, explain prosocial                                                                                                                                                                                                                                 | native .bin                        |      | 2023-04-01 |
| [gpt4-x-alpaca](https://huggingface.co/chavinlo/gpt4-x-alpaca)                                                                           | chavinlo                     | alpaca      | 13b        | 16bit                              | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | native .bin                        |      | 2023-03-31 |
| [alpaca-30b-lora-int4](https://huggingface.co/elinas/alpaca-30b-lora-int4)                                                               | elinas                       | alpaca      | 30b        | 4bit GPTQ                          | Alpaca                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                        |      | 2023-03-30 |
| [alpaca-lora-7b/](https://huggingface.co/tloen/alpaca-lora-7b/)                                                                          | tloen                        | alpaca      | 7b         | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        | yes  | 2023-03-29 |
| [alpaca-7b-nativeEnhanced](https://huggingface.co/8bit-coder/alpaca-7b-nativeEnhanced)                                                   | 8bit-coder                   | alpaca      | 7b         | 16bit                              |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        |      | 2023-03-28 |
| [gpt4all-lora](https://huggingface.co/nomic-ai/gpt4all-lora)                                                                             | nomic-ai                     | llama       | 7b         | ?                                  | [gpt4all prompt generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations)                                                                                                                                                                                                                                                                                            | ?                                  | yes  | 2023-03-28 |
| [alpaca-13b-lora-int4](https://huggingface.co/elinas/alpaca-13b-lora-int4)                                                               | elinas                       | alpaca      | 7b         | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | safetensors                        | yes  | 2023-03-27 |
| [alpaca-7B-ggml](https://huggingface.co/Pi3141/alpaca-7B-ggml)                                                                           | Pi3141                       | alpaca      | 7b         | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          | yes  | 2023-03-25 |
| [Alpaca-native-4bit-ggml](https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml)                                                         | Sosaka                       | alpaca      | 7b         | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 2023-03-21 |
| [alpaca-native-4bit](https://huggingface.co/ozcur/alpaca-native-4bit)                                                                    | ozcur                        | alpaca      | 7b         | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | hf .pt                             |      | 2023-03-20 |
| [alpaca-30b](https://huggingface.co/baseten/alpaca-30b)                                                                                  | baseten                      | alpaca      | 30b        | 16bit                              |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        | yes  | 2023-03-19 |
| [alpaca-13b](https://huggingface.co/Dogge/alpaca-13b)                                                                                    | Dogge                        | alpaca      | 13b        | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        |      | 2023-03-18 |
| [alpaca-lora-13b](https://huggingface.co/baruga/alpaca-lora-13b)                                                                         | baruga                       | alpaca      | 13b        | 8bit                               |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        | yes  | 2023-03-18 |
| [alpaca-native](https://huggingface.co/chavinlo/alpaca-native)                                                                           | chavinlo                     | alpaca      | 7b         | 16bit                              |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        |      | 2023-03-18 |
| [llama-30b-int4](https://huggingface.co/TianXxx/llama-30b-int4)                                                                          | TianXxx                      | llama       | 13b        | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                             |      | 2023-03-18 |
| [llama-30b-4bit](https://huggingface.co/kuleshov/llama-30b-4bit)                                                                         | kuleshov                     | llama       | 13b        | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                             |      | 2023-03-17 |
| [llama-alpaca-stuff/tree/main/Alpaca-Loras](https://huggingface.co/Draff/llama-alpaca-stuff/tree/main/Alpaca-Loras)                      | Draff                        | alpaca      | 13b        | 8bit                               |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        | yes  | 2023-03-17 |
| [oasst-llama13b-4bit-128g](https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g)                                                      | gozfarb                      | llama       | 13b        | 4bit                               | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | safetensors                        |      | 2023-03-17 |
| [llama-30b-int4](https://huggingface.co/elinas/llama-30b-int4)                                                                           | elinas                       | llama       | 13b        | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                             |      | 2023-03-16 |
| [alpaca13B-lora](https://huggingface.co/samwit/alpaca13B-lora)                                                                           | samwit                       | alpaca      | 13b        | 8bit                               |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                        | yes  | 2023-03-15 |
| [llama-7b-hf](https://huggingface.co/decapoda-research/llama-7b-hf)                                                                      | decapoda-research            | llama       | 7b         | 16bit                              | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                             |      | 2023-03-08 |
| [vicuna-13b-fine-tuned-rlhf](https://huggingface.co/CarperAI/vicuna-13b-fine-tuned-rlhf)                                                 | CarperAI                     | vicuna      | 13b        | 16bit                              | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca), [gpt4all_prompt_generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human Preferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) | native .bin                        |      | 2023-03-01 |
| [llama-13B-ggml](https://huggingface.co/Pi3141/llama-13B-ggml)                                                                           | Pi3141                       | llama       | 13b        | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                          |      | 404        |
| [llama-30B-ggml](https://huggingface.co/Pi3141/llama-30B-ggml)                                                                           | Pi3141                       | llama       | 30b        | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                          |      | 404        |
| [llama-65B-ggml](https://huggingface.co/Pi3141/llama-65B-ggml)                                                                           | Pi3141                       | llama       | 65b        | 4bit GPTQ                          |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                          |      | 404        |
| [llama-7B-ggml](https://huggingface.co/Pi3141/llama-7B-ggml)                                                                             | Pi3141                       | llama       | 7b         | 4bit GPTQ                          | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                          |      | 404        |
| [llama13b-lora-gpt4all](https://huggingface.co/magicgh/llama13b-lora-gpt4all)                                                            | magicgh                      | llama       | 13b        | ?                                  | GPT4All, Alpaca-CoT                                                                                                                                                                                                                                                                                                                                                                          | .bin                               | yes  | 404        |


</details>
  
## Other SOTA Open Source models
- [Cerebras GPT-13b](https://huggingface.co/cerebras) ([release notes](https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/))
- [LAION OpenFlamingo | Multi Modal Model and training architecture](https://github.com/mlfoundations/open_flamingo)
- [TheBloke/galpaca-30b-gptq-4bit-128g](https://huggingface.co/TheBloke/galpaca-30B-GPTQ-4bit-128g), GALACTICA 30B fine tuned with Alpaca 
- [GeorgiaTechResearchInstitute/galpaca-6.7b](https://huggingface.co/GeorgiaTechResearchInstitute/galpaca-6.7b) GALACTICA 6.7B fine tuned with Alpaca
- [GeoV/GeoV-9b](https://huggingface.co/GeoV/GeoV-9b) - 9B parameter, in-progress training to 300B tokens (33:1)
- [RWKV: Parallelizable RNN with Transformer-level LLM Performance](https://github.com/BlinkDL/RWKV-LM)
- [CodeGeeX 13B | Multi Language Code Generation Model](https://huggingface.co/spaces/THUDM/CodeGeeX)
- [BigCode | Open Scientific collaboration to train a coding LLM](https://huggingface.co/bigcode)
- [MOSS by Fudan University](https://github.com/OpenLMLab/MOSS)
- [mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) Multimodal finetuned model for visual/language tasks
- [Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) multi-modal visual/language chatbot, using llama with custom LoRA weights and openflamingo-9B.
- [Visual-med-alpaca](https://github.com/cambridgeltl/visual-med-alpaca) fine-tuning llama-7b on self instruct for the biomedical domain. Models locked behind a request form.
- [replit-code-v1-3b](https://huggingface.co/replit/replit-code-v1-3b) focused on Code Completion. The model has been trained on a subset of the [Stack Dedup v1.2](https://arxiv.org/abs/2211.15533) dataset.
- [VPGTrans](https://vpgtrans.github.io/) Transfer Visual Prompt Generator across LLMs and the VL-Vicuna model is a novel VL-LLM. [Paper](https://arxiv.org/abs/2305.01278), [code](https://github.com/VPGTrans/VPGTrans)


## Data sets
- [Alpaca-lora instruction finetuned using Low Rank Adaption](https://github.com/tloen/alpaca-lora)
- [codealpaca Instruction training data set for code generation](https://github.com/sahil280114/codealpaca)
- [LAION AI / Open-Assistant Dataset](https://huggingface.co/datasets/OpenAssistant/oasst1) (https://github.com/LAION-AI/Open-Assistant / https://projects.laion.ai/Open-Assistant/ / https://open-assistant.io)
- [pre-cleaned, English only, "unfiltered," and 2048 token split version of the ShareGPT dataset ready for finetuning](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)
- [Vicuna ShareGPT pre-cleaned 90k conversation dataset](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/tree/main/HTML_cleaned_raw_dataset)
- [Vicuna ShareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)
- [GPTeacher](https://github.com/teknium1/GPTeacher)
- [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)
- [codealpaca 20k](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)
- [gpt3all pruned](https://huggingface.co/datasets/Nebulous/gpt4all_pruned)
- [gpt4all_prompt_generations_with_p3](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations_with_p3)
- [gpt4all_prompt_generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations)
- [alpaca-plus-gpt4all-without-p3](https://huggingface.co/datasets/magicgh/alpaca-plus-gpt4all-without-p3)
- [Alpaca dataset from Stanford, cleaned and curated](https://github.com/gururise/AlpacaDataCleaned) 
- [Alpaca Chain of Thought fine tuning dataset for EN and CN](https://github.com/PhoebusSi/Alpaca-CoT)
- [PRESTO | Multilingual dataset for parsing realistic task-oriented dialogues by Google & University of Rochester, California, Santa Barbara, Columbia](https://ai.googleblog.com/2023/03/presto-multilingual-dataset-for-parsing.html) [paper](https://arxiv.org/pdf/2303.08954.pdf)
- [RedPajama](https://www.together.xyz/blog/redpajama) Dataset and model similar to LLaMA but truly open source and ready for commercial use. [hf](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T)
- [BigCode The Stack](https://huggingface.co/datasets/bigcode/the-stack)
- [open-instruct-v1](https://huggingface.co/datasets/hakurei/open-instruct-v1)
- [list of instruction datasets by yadongC/awesome-instruction-dataset](https://github.com/yaodongC/awesome-instruction-dataset)
- [The Embedding Archives, Millions of Wikipedia Article Embeddings in multiple languages](https://txt.cohere.com/embedding-archives-wikipedia/)
- [Rereplit-finetuned-v1-3b & replit-code-v1-3b](https://twitter.com/Replit/status/1651344186715803648) outperforming all coding OSS models, gets released soon
- [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) an instruction-following dataset created using [Evol-Instruct](https://github.com/nlpxucan/evol-instruct), used to fine-tune [WizardLM](https://github.com/nlpxucan/WizardLM)
- [gpt4tools_71k.json](https://github.com/StevenGrove/GPT4Tools#Dataset) from GPT4Tools paper, having 71k instruction-following examples for sound/visual/text instructions
- [WizardVicuna 70k dataset](https://huggingface.co/datasets/junelee/wizard_vicuna_70k) used to fine tune [WizardVicuna](https://github.com/melodysdreamj/WizardVicunaLM)

## Research
- [LLM Model Cards](https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs)
- [GPTs are GPTs: An early look at the labor market impact potential of LLMs](https://arxiv.org/abs/2303.10130)
- [ViperGPT Visual Inference via Python Execution for reasoning](https://viper.cs.columbia.edu/)
- [Emergent Abilities of LLMs ](https://openreview.net/forum?id=yzkSU5zdwD), [blog post](https://www.jasonwei.net/blog/emergence)
- [visualchatgpt | Microsoft research proposes a multi-modal architecture to give chatgpt the ability to interpret and generate images based on open source foundation models](https://github.com/microsoft/visual-chatgpt)
- [facts checker reinforcement](https://arxiv.org/abs/2302.12813)
- [LLaVA: Large Language and Vision Assistant, combining LLaMA with a visual model. Delta-weights released](https://llava-vl.github.io/)
- [Mass Editing Memory in a Transformer](https://memit.baulab.info/)
- [MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models](https://minigpt-4.github.io/)
- [WizardLM | Fine tuned LLaMA 7B with evolving instructions, outperforming chatGPT and Vicuna 13B on complex test instructions](https://arxiv.org/abs/2304.12244) ([code](https://github.com/nlpxucan/WizardLM), [delta weights](https://huggingface.co/victor123/WizardLM))
- [Scaling Transformer to 1M tokens and beyond with RMT](https://arxiv.org/abs/2304.11062)
- [AudioGPT | Understanding and Generating Speech, Music, Sound, and Talking Head](https://arxiv.org/abs/2304.12995) ([github](https://github.com/AIGC-Audio/AudioGPT), [hf space](https://huggingface.co/spaces/AIGC-Audio/AudioGPT))
- [Chameleon-llm](https://github.com/lupantech/chameleon-llm), a [paper](https://arxiv.org/abs/2304.09842) about Plug-and-Play Compositional Reasoning with GPT-4
- [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) share data generated by GPT-4 for building an instruction-following LLMs with supervised learning and reinforcement learning. [paper](https://arxiv.org/abs/2304.03277)
- [GPT4Tools](https://gpt4tools.github.io/) Teaching LLM to Use Tools via Self-instruct. [code](https://github.com/StevenGrove/GPT4Tools)
- [CAMEL](https://github.com/lightaime/camel): Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. [preprint paper](https://ghli.org/camel.pdf), [website](https://www.camel-ai.org/)
- [Poisoning Language Models During Instruction Tuning](https://arxiv.org/abs/2305.00944)
- [SparseGPT](https://arxiv.org/abs/2301.00774): Massive Language Models Can Be Accurately Pruned in One-Shot
- [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention](https://arxiv.org/abs/2303.16199)
- [Dromedary](https://arxiv.org/abs/2305.03047): Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision, [code](https://github.com/IBM/Dromedary), [weights](https://huggingface.co/zhiqings/dromedary-65b-lora-delta-v0)
- [Unlimiformer](https://arxiv.org/abs/2305.01625): transformer-based model that can process unlimited length input by offloading attention computation to a k-nearest-neighbor index, extending the capabilities of existing models like BART and Longformer without additional weights or code modifications. [code](https://github.com/abertsch72/unlimiformer)




## LLM GUIs

### OpenAI

-   [chatgptui/desktop](https://github.com/chatgptui/desktop)
  -   [chatbox](https://github.com/Bin-Huang/chatbox) is a Windows, Mac & Linux native ChatGPT Client
  -   [BingGPT](https://github.com/dice2o/BingGPT) Desktop application of new Bing's AI-powered chat
-   [TypingMind](https://www.typingmind.com/)
-   [Chatwithme.chat](https://www.chatwithme.chat/)
-   [datafilik/GPT-Voice-Assistant](https://github.com/datafilik/GPT-Voice-Assistant)
-   [Abdallah-Ragab/VoiceGPT](https://github.com/Abdallah-Ragab/VoiceGPT)
-   [LlmKira/Openaibot](https://github.com/LlmKira/Openaibot)
-   [chathub-dev/chathub](https://github.com/chathub-dev/chathub)
-   [enricoros/nextjs-chatgpt-app](https://github.com/enricoros/nextjs-chatgpt-app)
-   [no8081/chatgpt-demo](https://github.com/ddiu8081/chatgpt-demo)
-   [Auto GPT](https://github.com/Torantulino/Auto-GPT)
    -   [AgentGPT](https://github.com/reworkd/AgentGPT) Deploy autonomous AI agents, using vectorDB memory, web browsing via LangChain, website interaction and more¬†
    -   [microGPT¬†](https://github.com/muellerberndt/micro-gpt) Autonomous GPT-3.5/4 agent, can analyze stocks, create art, order pizza, and perform network security tests
    -   [Auto GPT Plugins](https://github.com/Significant-Gravitas/Auto-GPT-Plugins)
    -   [AutoGPT-Next-Web](https://github.com/Dogtiti/AutoGPT-Next-Web) An AgentGPT fork as a Web GUI
    -   [AutoGPT Web](https://github.com/jina-ai/auto-gpt-web)
    -   [AutoGPT.js](https://github.com/zabirauf/AutoGPT.js)
    -   [LoopGPT](https://github.com/farizrahman4u/loopgpt) a re-implementation of AutoGPT as a proper python package, modular and extensible
    -   [Camel-AutoGPT](https://github.com/SamurAIGPT/Camel-AutoGPT) Communicaton between Agents like BabyAGI and AutoGPT
    -   [BabyAGIChatGPT](https://github.com/Doriandarko/BabyAGIChatGPT) is a fork of BabyAGI to work with OpenAI's GPT, pinecone and google search
    -   [GPT Assistant](https://github.com/BuilderIO/gpt-assistant) An autonomous agent that can access and control a chrome browser via Puppeteer¬†
    -   [gptchat](https://github.com/ian-kent/gptchat) a client which uses GPT-4, adding long term memory, can write its own plugins and can fulfill tasks
    -   [Chrome-GPT](https://github.com/richardyc/Chrome-GPT) experimental AutoGPT agent employing Langchain and Selenium to interact with and manipulate a Chrome browser session, enabling capabilities like Google search, webpage description, element interaction, and form input
-   [cheetah | Speech to text for remote coding interviews, giving you hints from GTP3/4](https://github.com/leetcode-mafia/cheetah)
-   [sqlchat | Use OpenAI GPT3/4 to chat with your database](https://github.com/sqlchat/sqlchat)
-   [chat-with-github-repo](https://github.com/peterw/Chat-with-Github-Repo) which uses streamlit, gpt3.5-turbo and deep lake to answer questions about a git repo
-   [BarkingGPT | Audio2Audio by using Whisper+chatGPT+Bark](https://github.com/BudEcosystem/BarkingGPT)
  -  [gpt_chatbot](https://github.com/1nnovat1on/gpt_chatbot) Windows / elevenlabs TTS + pinecone long term memory
  -  [gpt-voice-conversation-chatbot](https://github.com/Adri6336/gpt-voice-conversation-chatbot) using GPT3.5/4 API, elevenlab voices, google tts, session long term memory
  -  [JARVIS-ChatGPT](https://github.com/gia-guar/JARVIS-ChatGPT) conversational assistant that uses OpenAI Whisper, OpenAI ChatGPT, and IBM Watson to provide quasi-real-time tips and opinions.
-   [ALFRED | LangChain Voice Assistant, powered by GPT-3.5-turbo, whisper, Bark, pyttsx3 and more](https://github.com/masrad/ALFRED)
-   [IPython-gpt](https://github.com/santiagobasulto/ipython-gpt) use chatGPT directly inside jupyter notebooks
-   [Glarity](https://github.com/sparticleinc/chatgpt-google-summary-extension) open-source chrome extension to write summaries for various websites including custom ones and YouTube videos. Extensible
  -   [superpower-chatgpt](https://github.com/saeedezzati/superpower-chatgpt) chrome  extension / firefox addon to add missing features like Folders, Search, and Community Prompts to ChatGPT



### Other GUIs

-   [Text Generation Webui](https://github.com/oobabooga/text-generation-webui) An all purpose UI to run LLMs of all sorts with optimizations
    -   [running LLaMA on less than 10GB vram](https://github.com/oobabooga/text-generation-webui/issues/147#issuecomment-1456040134)
    -   [running LLaMA-7b on a 3080](https://github.com/TimDettmers/bitsandbytes/issues/30#issuecomment-1455993902)
-   [Alpaca-LoRa-Serve](https://github.com/deep-diver/Alpaca-LoRA-Serve)
-   [llama.cpp](https://github.com/ggerganov/llama.cpp)
    -   [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp)
    -   [koboldcpp](https://github.com/LostRuins/koboldcpp)
    -   [Serge](https://github.com/nsarrazin/serge) chat interface based on llama.cpp for running Alpaca models. Entirely self-hosted, no API keys needed
    -   [llama MPS](https://github.com/jankais3r/LLaMA_MPS) inference on Apple Silicon GPU using much lower power but is slightly slower than llama.cpp which uses CPU
-   [Dalai](https://github.com/cocktailpeanut/dalai)
-   [ChatLLaMA | LLaMA-based ChatGPT for single GPUs](https://github.com/juncongmoo/chatllama)
    -   [ChatLLaMA | another implementation](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama)
-   [Chatbot web app + HTTP and Websocket endpoints for BLOOM-176B inference with the Petals client](https://github.com/borzunov/chat.petals.ml)
    -   [bloomz.cpp](https://github.com/NouamaneTazi/bloomz.cpp) Inference of HuggingFace's BLOOM-like models in pure C/C++
-   [Vicuna FastChat](https://github.com/lm-sys/FastChat)
-   [Lit-llama](https://github.com/Lightning-AI/lit-llama)
-   [gpt4all](https://github.com/nomic-ai/gpt4all) terminal and gui version to run local gpt-j models, [compiled binaries for win/osx/linux](https://gpt4all.io/index.html)
    -   [gpt4all.zig](https://github.com/renerocksai/gpt4all.zig) terminal version of GPT4All
    -   [gpt4all-chat](https://github.com/nomic-ai/gpt4all-chat) Cross platform desktop GUI for GPT4All ¬†models (gpt-j)
-   [openplayground Try out almost any LLM in a gui](https://github.com/nat/openplayground)
-   [Alpaca-Turbo | Web UI to run alpaca model locally on Win/Mac/Linux](https://github.com/ViperX7/Alpaca-Turbo)
-   [FreedomGPT | Web app that executes the FreedomGPT LLM locally](https://github.com/ohmplatform/FreedomGPT)
-   [Auto Vicuna Butler](https://github.com/NiaSchim/auto-vicuna-butler) Baby-AGI fork / AutoGPT alternative to run with local LLMs
    -   [BabyAGI](https://github.com/yoheinakajima/babyagi) AI-Powered Task Management for OpenAI + Pinecone or Llama.cpp
    -   [Agent-LLM](https://github.com/Josh-XT/Agent-LLM) Webapp to control an agent-based Auto-GPT alternative, supporting GPT4, Kobold, llama.cpp, FastChat, Bard, Oobabooga textgen
    -   [auto-llama-cpp](https://github.com/rhohndorf/Auto-Llama-cpp) fork of Auto-GPT with added support for locally running llama models through llama.cpp
    -   [AgentOoba](https://github.com/flurb18/AgentOoba) autonomous AI agent extension for Oobabooga's web ui
-   [huggingGPT / JARVIS](https://github.com/microsoft/JARVIS) Connects LLMs with huggingface specialized models
-   [OpenAGI](https://github.com/agiresearch/openagi) AGI research platform, solves multi step tasks with RLTF and supports complex model chains
-   [bark TTS for oobabooga/text-generation-webui](https://github.com/wsippel/bark_tts) make your local LLM talk
    -   [bark TTS for oobabooga/text-generation-webui](https://github.com/minemo/text-generation-webui-barktts) another implementation
-   [HuggingChat](https://huggingface.co/chat) open source chat interface for transformer based LLMs by Huggingface
-   [mlc-llm](https://github.com/mlc-ai/mlc-llm), run any LLM on any hardware (iPhones, Android, Win, Linux, Mac, WebGPU, Metal. NVidia, AMD)
-   [faraday.dev](https://faraday.dev/) Run open-source LLMs on your Win/Mac. Completely offline. Zero configuration.
-   [PrivateGPT](https://github.com/imartinez/privateGPT) a standalone question-answering system using LangChain, GPT4All, LlamaCpp and embeddings models to enable offline querying of documents

## LLM Wrappers

-   [acheong08/ChatGPT Python](https://github.com/acheong08/ChatGPT)
-   [mpoon/gpt-repository-loader](https://github.com/mpoon/gpt-repository-loader)
-   [LangChain | framework for developing LLM applications](https://github.com/hwchase17/langchain) ([example](https://www.youtube.com/watch?v=iRJ4uab_NIg&t=588s), [paolorechia/learn-langchain with vicuna and GPQT 4 bit support](https://github.com/paolorechia/learn-langchain))
-   [LangFlow | GUI for Langchain](https://github.com/logspace-ai/langflow)
-   [pyllama | hacked version of LLaMA based on Meta's implementation, optimized for Single GPUs](https://github.com/juncongmoo/pyllama)
-   [Toolformer implementation | Allows LLMs to use Tools](https://github.com/lucidrains/toolformer-pytorch)
-   [FastLLaMA Python wrapper for llama.cpp](https://github.com/PotatoSpudowski/fastLLaMa)
-   [LlamaIndex](https://github.com/jerryjliu/llama_index) provides a central interface to connect your LLM's with external data
    -   [Llama-lab](https://github.com/run-llama/llama-lab) home of llama\_agi and auto\_llama using LlamaIndex
-   [supercharger | Write Software + unit tests for you, based on Baize-30B 8bit, using model parallelism](https://github.com/catid/supercharger)
-   [WebGPT Inference in pure javascript](https://github.com/0hq/WebGPT)
-   [WasmGPT ChatGPT-like chatbot in browser using ggml and emscripten](https://github.com/lxe/ggml/tree/wasm-demo)
-   [FauxPilot | open source Copilot alternative using Triton Inference Server](https://github.com/fauxpilot/fauxpilot)
    -   [Turbopilot | open source LLM code completion engine and Copilot alternative](https://github.com/ravenscroftj/turbopilot)
    -   [Tabby | Self hosted Github Copilot alternative](https://github.com/TabbyML/tabby)
-   [Sidekick | Information retrieval for LLMs](https://github.com/ai-sidekick/sidekick)
-   [gpt4free | Use reverse engineered GPT3.5/4 APIs of other website's APIs](https://github.com/xtekky/gpt4free)
-   [AutoGPTQ | easy-to-use model GPTQ quantization package with user-friendly CLI](https://github.com/PanQiWei/AutoGPTQ)
-   [RWKV.cpp](https://github.com/saharNooby/rwkv.cpp) CPU only port of BlinkDL/RWKV-LM to ggerganov/ggml. Supports FP32, FP16 and quantized INT4.
    -   [RWKV Cuda](https://github.com/harrisonvanderbyl/rwkv-cpp-cuda) a torchless, c++ rwkv implementation with 8bit quantization written in cuda
-   [gpt-llama.cpp](https://github.com/keldenl/gpt-llama.cpp) Replace OpenAi's GPT APIs with llama.cpp's supported models locally
-   [llama-node](https://github.com/Atome-FE/llama-node) JS client library for llama (or llama based) LLMs built on top of llama-rs and llama.cpp.
-   [megabots](https://github.com/momegas/megabots) to create LLM bots by providing Q&A, document retrieval, vector DBs, FastAPI, Gradio UI, GPTCache, guardrails, whisper, supports OpenAI API (local LLMs planned)
-   [GPTCache](https://github.com/zilliztech/GPTCache), serve cached results based on embeddings in a vector DB, before querying the OpenAI API.
-   [kitt](https://github.com/livekit-examples/kitt) TTS + GPT4 + STT to create a conference call audio bot
-   [Jsonformer](https://github.com/1rgs/jsonformer): Generate Structured JSON from Language Models by handling JSON synthax, and letting LLM just output the values
-   [Marvin](https://github.com/prefecthq/marvin) simplifies AI integration in software development with easy creation of AI functions and bots managed through a conversational interface
-   [chatgpt.js](https://github.com/chatgptjs/chatgpt.js) client-side JavaScript library for ChatGPT
-   [ChatGPT-Bridge](https://github.com/improveTheWorld/ChatGPT-Bridge) use chatGPT plus' GPT-4 as a local API


## Showcases
- [Opinionate.io AI Debating AI](https://opinionate.io/)
- [phind.com](phind.com) Developer Search Engine
- [Voice Q&A Assistant](https://github.com/hackingthemarkets/qa-assistant-eleven-labs-voice-cloning) using ChatGPT API, Embeddings, Gradio, Eleven Labs and Whisper
- [chatpdf](https://www.chatpdf.com/), Q&A for PDFs

## Fine Tuning
- [simple llama finetuner](https://github.com/lxe/simple-llama-finetuner)
- [LLaMA-LoRA Tuner](https://github.com/zetavg/LLaMA-LoRA-Tuner)
- [alpaca-lora](https://github.com/tloen/alpaca-lora)
- [StackLLaMA Fine-Tuning Guide by huggingface](https://huggingface.co/blog/stackllama)
- [xTuring | LLM finetuning pipeline supporting LoRa & 4bit](https://github.com/stochasticai/xturing)
- [Microsoft DeepSpeed Chat](https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/README.md)
- [How to train your LLMs](https://blog.replit.com/llm-training)
- [H2O LLM Studio | Framework and no-code GUI for fine tuning SOTA LLMs](https://github.com/h2oai/h2o-llmstudio)
- [Implementation of LLaMA-Adapter](https://github.com/ZrrSkywalker/LLaMA-Adapter), to fine tune instructions within hours

## Other awesome resources
- [LLM Worksheet](https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=741531996) by [randomfoo2](https://www.reddit.com/r/LocalAI/comments/12smsy9/list_of_public_foundational_models_fine_tunes/)
- [The full story of LLMs](https://www.assemblyai.com/blog/the-full-story-of-large-language-models-and-rlhf/)
- [Brief history of llama models](https://agi-sphere.com/llama-models/)
- [A timeline of transformer models](https://ai.v-gar.de/ml/transformer/timeline/)
- [Every front-end GUI client for ChatGPT API](https://github.com/billmei/every-chatgpt-gui)
- [LLM Logic Tests](https://docs.google.com/spreadsheets/d/1NgHDxbVWJFolq8bLvLkuPWKC7i_R6I6W/edit#gid=719051075) by [YearZero on reddit/localllama](https://www.reddit.com/r/LocalLLaMA/comments/13636h5/updated_riddlecleverness_comparison_of_popular/)
- [LLMSurvey](https://github.com/rucaibox/llmsurvey) a collection of papers and resources including an LLM timeline
- [rentry.org/lmg_models](https://rentry.org/lmg_models) a list of llama derrivates and models
- [Timeline of AI and language models](https://lifearchitect.ai/timeline/) and [Model Comparison Sheet](https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs/edit#gid=1158069878) by Dr. Alan D. Thompson

# Image Generation

## Models
- https://github.com/kakaobrain/karlo
- https://lukashoel.github.io/text-to-room/
- [facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything) image segmentation
  - [YOLOv8](https://github.com/ultralytics/ultralytics) SOTA object detection, segmentation, classification and tracking
  - [DINOv2](https://github.com/facebookresearch/dinov2) 1B-parameter ViT model to generate robust all-purpose visual features that outperform OpenCLIP benchmarks at image and pixel levels
- [DeepFloyd if by StabilityAI](https://huggingface.co/DeepFloyd/IF-I-XL-v1.0) open-source text-to-image model with photorealism and language understanding. [code](https://github.com/deep-floyd/IF)
- [OpenAI shap-E](https://github.com/openai/shap-e) a text/image to 3D model
- [Kandinsky](https://github.com/ai-forever/Kandinsky-2) multilingual text2image latent diffusion model

## Wrappers & GUIs
- [a Stable Diffusion UI](https://github.com/brycedrennan/imaginAIry/blob/master/README.md)
- [InvokeAI | Alternative, polished stable diffusion UI with less features than automatic1111](https://github.com/invoke-ai/InvokeAI)
- [Automatic1111/stable-diffusion-webui | The most famous UI for Stable Diffusion with the most features](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- [mlc-ai/web-stable-diffusion](https://github.com/mlc-ai/web-stable-diffusion)
- [vladmandic/automatic | Heavily opinionated custom fork AUTOMATIC1111's repo, as close as up-to-date with origin as time allows](https://github.com/vladmandic/automatic)
- [anapnoe/stable-diffusion-webui-ux | Redesigned from automatic1111's UI, adding mobile and desktop layouts and UX improvements](https://github.com/anapnoe/stable-diffusion-webui-ux)

## Fine Tuning
- https://github.com/JoePenna/Dreambooth-Stable-Diffusion
- https://github.com/TheLastBen/fast-stable-diffusion
- https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth
- https://github.com/cloneofsimo/lora
- [Kohya_ss | Windows-focused Gradio GUI for Kohya's Stable Diffusion trainers](https://github.com/bmaltais/kohya_ss)
- [StableTuner | Windows GUI for Finetuning / Dreambooth Stable Diffusion models](https://github.com/devilismyfriend/StableTuner)

## Research
 - [Speed Is All You Need](https://arxiv.org/abs/2304.11267) up to 50% speed increase for Latent Diffusion Models

# Video
## Text to video generation
- [ModelScope Text to video synthesis](https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis)
- [Nvidia VideoLDM: Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models](https://research.nvidia.com/labs/toronto-ai/VideoLDM/)

## Frame Interpolation (Temporal Interpolation)
- https://github.com/google-research/frame-interpolation
- https://github.com/ltkong218/ifrnet
- https://github.com/megvii-research/ECCV2022-RIFE

## Segmentation & Tracking
- [Segment and Track Anything](https://arxiv.org/abs/2305.06558v1), [code](https://github.com/z-x-yang/segment-and-track-anything). an innovative framework combining the Segment Anything Model (SAM) and DeAOT tracking model, enables precise, multimodal object tracking in video, demonstrating superior performance in benchmarks
- [Track Anything](https://arxiv.org/abs/2304.11968v2), [code](https://github.com/gaomingqi/track-anything). extends the Segment Anything Model (SAM) to achieve high-performance, interactive tracking and segmentation in videos with minimal human intervention, addressing SAM's limitations in consistent video segmentation

## Super Resolution (Spacial Interpolation)
- https://github.com/researchmm/FTVSR
- https://github.com/picsart-ai-research/videoinr-continuous-space-time-super-resolution
- 

## Spacio Temporal Interpolation
- https://github.com/llmpass/RSTT

# Audio
## Compression
- https://github.com/facebookresearch/encodec

## Multiple Tasks
- [Speechbrain](https://github.com/speechbrain/speechbrain) A PyTorch-based Speech Toolkit for TTS, STT, etc
- [Nvidia NeMo](https://github.com/NVIDIA/NeMo) TTS, LLM, Audio Synthesis framework
- [speech-rest-api](https://github.com/askrella/speech-rest-api) for Speech-To-Text and Text-To-Speech with Whisper and Speechbrain
- [LangHelper](https://github.com/NsLearning/LangHelper) language learning through Text-to-speech + chatGPT + speech-to-text to practise speaking assessments, memorizing words and listening tests
- [Silero-models](https://github.com/snakers4/silero-models) pre-trained speech-to-text, text-to-speech and text-enhancement for ONNX, PyTorch, TensorFlow, SSML
- [AI-Waifu-Vtuber](https://github.com/ardha27/AI-Waifu-Vtuber) AI Waifu Vtuber & is a virtual streamer. Supports multiple languages and uses VoiceVox, DeepL, Whisper, Seliro TTS, and VtubeStudio, and now also supports Twitch streaming.


## Speech Recognition
- https://github.com/openai/whisper
  - [Whisper JAX implementation](https://github.com/sanchit-gandhi/whisper-jax) runs around 70x faster on CPU, GPU and TPU
  - [whisper.cpp](https://github.com/ggerganov/whisper.cpp) C/C++ port for Intel and ARM based Mac OS, ANdroid, iOS, Linux, WebAssembly, Windows, Raspberry Pi
- [ermine-ai | Whisper in the browser using transformers.js](https://github.com/vishnumenon/ermine-ai)
- [wav2vec2 dimensional emotion model](https://github.com/audeering/w2v2-how-to)
- [MeetingSummarizer](https://github.com/rajpdus/MeetingSummarizer) using Whisper and GPT3.dd

## TextToSpeech
-   [tts-generation-webui](https://github.com/rsxdalv/tts-generation-webui) for all things TTS, currently supports Bark
-   [Bark](https://github.com/suno-ai/bark) transformer-based text-to-audio model by Suno. Can generate highly realistic, multilingual speech and other audio like music, background noise and simple effects
    -   [Bark-Voice-Clones](https://github.com/nikaskeba/Bark-Voice-Clones)
    -   [Bark WebUI colab notebooks](https://github.com/camenduru/bark-colab)
    -   [bark-with-voice-clone](https://github.com/serp-ai/bark-with-voice-clone)
    -   [Bark Infinity for longer audio](https://github.com/JonathanFly/bark)
    -   [Bark WebUI](https://github.com/makawy7/bark-webui))
-   [Coqui TTS | deep learning toolkit for Text-to-Speech](https://github.com/coqui-ai/TTS)
    -   [Tutorial](https://www.youtube.com/watch?v=dfmlyXHQOwE) for Coqui VITS and Whisper to automate voice cloning and [Colab notebook](https://colab.research.google.com/drive/1Swo0GH_PjjAMqYYV6He9uFaq5TQsJ7ZH?usp=sharing#scrollTo=nSrZbKCXxalg)
-   [StyleTTS implementation](https://github.com/yl4579/StyleTTS)
  -   [StyleTTS-VC](https://github.com/yl4579/StyleTTS-VC) One-Shot Voice Conversion by Knowledge Transfer from Style-Based TTS Models
-   [Vall-E and Vall-E X](https://valle-demo.github.io/), [paper](https://arxiv.org/abs/2301.02111), [code](https://github.com/enhuiz/vall-e). Zero Shot TTS preserving emotion, expression, similarity and allows language transfer
  -  [Vall-e PyTorch Implementation](https://github.com/enhuiz/vall-e) of Vall-E based on EnCodec tokenizer
  -  [Vall-E PyTorch implementation](https://github.com/lifeiteng/vall-e)
-   [NaturalSpeech implmenetation](https://github.com/heatz123/naturalspeech)
-   [IMS Toucan, TTS Toolkit from University of Stuttgart](https://github.com/digitalphonetics/ims-toucan)
-   [YourTTS | Zero Shot Multi Speaker TTS and Voice Conversion for everyone](https://github.com/Edresson/YourTTS)
-   [PaddleSpeech | Easy to use Speech Toolkit with Self Supervised learning, SOTA Streaming with punctuation, TTS, Translation etc](https://github.com/PaddlePaddle/PaddleSpeech)
-   [Tortoise TTS | Open source multi voice TTS system](https://github.com/neonbjb/tortoise-tts)
    -   [finetune guide using DLAS DL-Art-School](https://www.youtube.com/watch?v=lnIq4SFFXWs)
    -   [DL-Art-School](https://github.com/152334H/DL-Art-School) fine tuning tortoise with DLAS GUI
    -   [tortoise-tts-fast](https://github.com/152334H/tortoise-tts-fast) fast Tortoise TTS inference up to 5x. [Video tutorial](https://www.youtube.com/watch?v=8i4T5v1Fl_M)
    -   [Tortoise mrq fork for voice cloning](https://git.ecker.tech/mrq/ai-voice-cloning)
-   [piper](https://github.com/rhasspy/piper) A fast, local neural text to speech system that sounds great and is optimized for the Raspberry Pi 4. Using VITS and onnxruntime
-   [PITS](https://github.com/anonymous-pits/pits) PyTorch implementation of Variational Pitch Inference for End-to-end Pitch-controllable TTS. [hf demo](https://huggingface.co/spaces/anonymous-pits/pits), [samples](https://anonymous-pits.github.io/pits/)
-   [VoiceCloning](https://github.com/MartinMashalov/VoiceCloning) Implementing the [YourTTS paper](https://arxiv.org/abs/2112.02418) for Zero-Shot multi-speaker Attention-Based TTS using VITS approaches
  -   [VITS-Umamusume-voice-synthesizer](https://huggingface.co/spaces/1raliopunche/VITS-Umamusume-voice-synthesizer) (Multilingual Anime TTS) Including Japanese TTS, Chinese and English TTS, speakers are all anime characters.
-   [Parallel WaveGAN implementation in PyTorch](https://github.com/kan-bayashi/ParallelWaveGAN) for high quality text to speech synthesis [paper](https://github.com/kan-bayashi/ParallelWaveGAN)


## Voice Conversion

-   [voicepaw/so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) SoftVC VITS Singing Voice Conversion Fork with realtime support and greatly improved interface. Based on so-vits-svc 4.0 (v1)
    -   [Video tutorial by Nerdy Rodent](https://www.youtube.com/watch?v=tZn0lcGO5OQ)
    -   [nateraw/so-vits-svc-fork gradio app](https://github.com/nateraw/voice-cloning) for inference of so-vits-svc-fork voice models + ([training in colab](https://colab.research.google.com/github/nateraw/voice-cloning/blob/main/training_so_vits_svc_fork.ipynb) with yt downloader and audio splitter, [hf space demo](https://hf.co/spaces/nateraw/voice-cloning))
    -   [so-vits-svc-5.0](https://github.com/PlayVoice/so-vits-svc-5.0)
    -   [LoRa svc](https://github.com/PlayVoice/lora-svc)
    -   [RVC-Project](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI) simple and easy-to-use voice transformation (voice changer) web GUI based on VITS
        -   [rvc-webui](https://github.com/ddPn08/rvc-webui) Win/Mac/Linux installer and Guide for RVC-Project
    -   [w-okada/voice-changer](https://github.com/w-okada/voice-changer) supports various models: MMVC, so-vits-svc, RVC, DDSP-SVC, can work over LAN to offload processing
    -   [DDSP-SVC](https://github.com/yxlllc/DDSP-SVC) Real-time singing voice conversion based on DDSP, training and inference uses lower requirements than diff-svc and so-vits-svc
    -   [Leader board of SOTA models](https://github.com/Anjok07/ultimatevocalremovergui/issues/344) for stem separation using model ensembles in UVR
    -   [VITS GUI to load VITS text to speech models](https://github.com/CjangCjengh/MoeGoe_GUI)
    -   [Vits-fast-fine-tuning](https://github.com/Plachtaa/VITS-fast-fine-tuning) pipeline of VITS finetuning for fast speaker adaptation TTS, and many-to-many voice conversion
-   [w-okada/voice-changer | real time voice conversion using various models like MMVC, so-vits-svc, RVC, DDSP-SVC](https://github.com/w-okada/voice-changer/blob/master/README_en.md)
-   [Diff-svc](https://github.com/prophesier/diff-svc) Singing Voice Conversion via Diffusion model
  -   [FastDiff implementation| Fast Conditional Diffusion Model for High-Quality Speech Synthesis](https://github.com/Rongjiehuang/FastDiff)
  -   [Fish Diffusion](https://github.com/fishaudio/fish-diffusion) easy to understand TTS / SVS / SVC framework, can convert Diff models
-   [Auto-synced-translated-dubs](https://github.com/ThioJoe/Auto-Synced-Translated-Dubs) Youtube audio translation and dubbing pipeline using Whisper speech-to-text, Google/DeepL Translate, Azure/Google TTS
-   [Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning) abandoned project
    -   [Real-Time-Voice-Cloning v2](https://github.com/liuhaozhe6788/voice-cloning-collab) active fork of the original
-  [Raven with voice cloning 2.0](https://huggingface.co/spaces/Kevin676/Raven-with-Voice-Cloning-2.0/tree/main) by Kevin676


# AI DevOps
- https://www.steamship.com/
- [SynapseML](https://github.com/microsoft/SynapseML) (previously known as MMLSpark),an open-source library that simplifies the creation of massively scalable machine learning (ML) pipelines

# Optimization
## Inference
- https://github.com/bigscience-workshop/petals
- https://github.com/chavinlo/distributed-diffusion
- https://github.com/VoltaML/voltaML-fast-stable-diffusion
- https://github.com/FMInference/FlexGen
- https://github.com/alpa-projects/alpa
- https://github.com/kir-gadjello/zipslicer
- https://github.com/modular-ml/wrapyfi-examples_llama
- https://github.com/tloen/llama-int8
- [4 bits quantization of LLaMa using GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) ([discussion](https://github.com/oobabooga/text-generation-webui/issues/177))
- https://petals.ml/
- https://github.com/facebookincubator/AITemplate

## Training
- https://github.com/learning-at-home/hivemind

## Other Optimization
- https://github.com/HazyResearch/flash-attention
- https://github.com/stochasticai/x-stable-diffusion


# Benchmarking
- https://videoprocessing.ai/benchmarks/
- https://paperswithcode.com/
- [Pythia | interpretability analysis for autoregressive transformers during training](https://github.com/EleutherAI/pythia)
- [LMSys Chatbot Arena Leaderboard](https://chat.lmsys.org/?leaderboard), [blogpost](https://lmsys.org/blog/2023-05-03-arena/) is an anonymous benchmark platform for LLMs that features randomized battles in a crowdsourced manner
- [Current best choices](https://old.reddit.com/r/LocalLLaMA/wiki/models#wiki_current_best_choices) on LocalLLaMA reddit


# Star History

[![Star History Chart](https://api.star-history.com/svg?repos=underlines/awesome-marketing-datascience&type=Date)](https://star-history.com/#underlines/awesome-marketing-datascience&Date)
