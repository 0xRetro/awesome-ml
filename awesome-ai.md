# Table of Contents

- [Large Language Models](#large-language-models)
  - [Open models](#open-models)
  - [Other SOTA Open Source Models](#other-sota-open-source-models)
  - [Data sets](#data-sets)
  - [Research](#research)
  - [LLM GUIs](#llm-guis)
    - [OpenAI](#openai)
    - [Other GUIs](#other-guis)
  - [LLM Wrappers](#llm-wrappers)
  - [Showcases](#showcases)
  - [Fine Tuning](#fine-tuning)
  - [Other awesome lists](#other-awesome-lists)
- [Image Generation](#image-generation)
  - [Models](#models)
  - [Wrappers & GUIs](#wrappers--guis)
  - [Fine Tuning](#fine-tuning-1)
- [Benchmarking](#benchmarking)
- [Video](#video)
  - [Text to video generation](#text-to-video-generation)
  - [Frame Interpolation (Temporal Interpolation)](#frame-interpolation-temporal-interpolation)
  - [Super Resolution (Spacial Interpolation)](#super-resolution-spacial-interpolation)
  - [Spacio Temporal Interpolation](#spacio-temporal-interpolation)
- [Audio](#audio)
  - [Compression](#compression)
  - [Speech Recognition](#speech-recognition)
  - [Generative Audio](#generative-audio)
- [AI DevOps](#ai-devops)
- [Optimization](#optimization)
  - [Inference](#inference)
  - [Training](#training)
  - [Other Optimization](#other-optimization)

# Large Language Models



## Open models
| Model                                                                                                                                    | Author                   | Foundation  | Size       | Quantization | Fine Tuning Dataset                                                                                                                                                                                                                                                                                                                                                                          | Format                       | LoRa | model date |
|------------------------------------------------------------------------------------------------------------------------------------------|--------------------------|-------------|------------|--------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------|------|------------|
| [WizardLM](https://huggingface.co/victor123/WizardLM)                                                                              | victor123                | llama           | 7b         | none         | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k)                                                                                                                                                                                                                                                                                             | native .bin                  |      | 2023-04-25 |
| [MiniGPT4-7B](https://huggingface.co/camenduru/MiniGPT4-7B)                                                                              | camenduru                | ?           | 7b         | none         | minigpt-4                                                                                                                                                                                                                                                                                                                                                                                    | native .bin                  |      | 2023-04-23 |
| [CodeGen-6B-multi-ggml-quant](https://huggingface.co/ravenscroftj/CodeGen-6B-multi-ggml-quant)                                           | ravenscroftj             | codegen     | 6b         | 4bit ?       | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml                         |      | 2023-04-23 |
| [CodeGen-2B-multi-ggml-quant](https://huggingface.co/ravenscroftj/CodeGen-2B-multi-ggml-quant)                                           | ravenscroftj             | codegen     | 2b         | 4bit ?       | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml                         |      | 2023-04-23 |
| [h2ogpt-oasst1-512-20b](https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b)                                                              | h2oai                    | gpt-neox    | 20b        | none         | [openassistant_oasst1](https://huggingface.co/datasets/h2oai/openassistant_oasst1)                                                                                                                                                                                                                                                                                                           | native .bin                  |      | 2023-04-23 |
| [OpenAssistant-Llama-30b-4bit](https://huggingface.co/MetaIX/OpenAssistant-Llama-30b-4bit)                                               | MetaIX                   | llama       | 30b        | 4bit GPTQ    | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | safetensors / ggml           |      | 2023-04-23 |
| [llama-13b-SuperCOT-4bit-TRITON](https://huggingface.co/TheYuriLover/llama-13b-SuperCOT-4bit-TRITON)                                     | TheYuriLover             | llama       | 13b        | 4bit GPTQ    | [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [neulab/conala](https://huggingface.co/datasets/neulab/conala), [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)                                                                                                                                                                                    | triton safetensors           |      | 2023-04-23 |
| [stablelm-7b-sft-v7-epoch-3](https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3)                                            | OpenAssistant            | stablelm    | 7b         | none         | oasst, vicuna, dolly15k, grade_school_math_instructions, code_alpaca                                                                                                                                                                                                                                                                                                                         | native .bin                  |      | 2023-04-23 |
| [medalpaca-13B-GPTQ-4bit](https://huggingface.co/TheBloke/medalpaca-13B-GPTQ-4bit)                                                       | TheBloke                 | alpaca      | 13b        | 4bit GPTQ    | [ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor), [Wikidoc](https://www.wikidoc.org/index.php/Main_Page), Stackexchange academia bio fitness health bioinformatics, Anki flashcards                                                                                                                                                                                                     | safetensors                  |      | 2023-04-22 |
| [alpaca-lora-65B-GGML](https://huggingface.co/TheBloke/alpaca-lora-65B-GGML)                                                             | TheBloke                 | alpaca      | 65b        | 4bit/2bit    | Alpaca LoRa                                                                                                                                                                                                                                                                                                                                                                                  | new ggml                     |      | 2023-04-22 |
| [dolly-v2-12b-sharded](https://huggingface.co/ethzanalytics/dolly-v2-12b-sharded)                                                        | ethzanalytics            | dolly       | 12b        | none         | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | hf .bin                      |      | 2023-04-22 |
| [dolly-v2-7b-sharded](https://huggingface.co/ethzanalytics/dolly-v2-7b-sharded)                                                          | ethzanalytics            | dolly       | 7b         | none         | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | hf .bin                      |      | 2023-04-22 |
| [llama-13b-supercot-4bit-128g](https://huggingface.co/ausboss/llama-13b-supercot-4bit-128g)                                              | ausboss                  | llama       | 13b        | 4bit GPTQ    | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-13b)                                                                                                                                                                                                                                                                 | safetensors                  |      | 2023-04-22 |
| [llama-30b-hf-transformers-4.29](https://huggingface.co/elinas/llama-30b-hf-transformers-4.29)                                           | elinas                   | llama       | 30b        | none         | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                      |      | 2023-04-22 |
| [llama-7b-hf-transformers-4.29](https://huggingface.co/elinas/llama-7b-hf-transformers-4.29)                                             | elinas                   | llama       | 7b         | none         | llama                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                      |      | 2023-04-22 |
| [llama-65b-hf-transformers-4.29](https://huggingface.co/elinas/llama-65b-hf-transformers-4.29)                                           | elinas                   | llama       | 65b        | none         | llama                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                      |      | 2023-04-22 |
| [llama-7b-hf](https://huggingface.co/fragro/llama-7b-hf)                                                                                 | fragro                   | llama       | 7b         | none         | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                      |      | 2023-04-22 |
| [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA)                                                                         | kaiokendev               | llama       | 7b/13b/30b | 4bit GPTQ    | [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [neulab/conala](https://huggingface.co/datasets/neulab/conala), [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)                                                                                                                                                                                    |                              | yes  | 2023-04-22 |
| [llama-13b-hf](https://huggingface.co/luodian/llama-13b-hf)                                                                              | luodian                  | llama       | 13b        | none         | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                      |      | 2023-04-22 |
| [llama-7b-hf](https://huggingface.co/luodian/llama-7b-hf)                                                                                | luodian                  | llama       | 7b         | none         | LLaMA                                                                                                                                                                                                                                                                                                                                                                                        | hf .bin                      |      | 2023-04-22 |
| [oasst-sft-6-llama-30b-xor](https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor)                                              | OpenAssistant            | llama       | 30b        | none         | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | native .bin                  |      | 2023-04-22 |
| [llama_30b_corr](https://huggingface.co/prodm93/llama_30b_corr)                                                                          | prodm93                  | llama       | 30b        | none         |                                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                      |      | 2023-04-22 |
| [GPT4-x-Alpaca13b-RolePlayLora-4bit-v2](https://huggingface.co/teknium/GPT4-x-Alpaca13b-RolePlayLora-4bit-v2)                            | teknium                  | llama       | 13b        | 4bit GPTQ    | gpt4-x-alpaca finetune, [roleplay instruct](https://github.com/teknium1/GPTeacher/tree/main/Roleplay)                                                                                                                                                                                                                                                                                        |                              |      | 2023-04-22 |
| [llama-30b-supercot-4bit-128g-cuda](https://huggingface.co/tsumeone/llama-30b-supercot-4bit-128g-cuda)                                   | tsumeone                 | llama       | 30b        | 4bit GPTQ    | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-30b)                                                                                                                                                                                                                                                                 | safetensors                  |      | 2023-04-22 |
| [h2ogpt-oig-oasst1-512-6.9b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-512-6.9b)                                                    | h2oai                    | pythia      | 6.9b       | none         | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                  |      | 2023-04-22 |
| [stablelm-tuned-alpha-3b-sharded](https://huggingface.co/ethzanalytics/stablelm-tuned-alpha-3b-sharded)                                  | ethzanalytics            | stablelm    | 3b         | none         | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | hf .bin                      |      | 2023-04-22 |
| [stablelm-base-alpha-7b-sharded](https://huggingface.co/ethzanalytics/stablelm-base-alpha-7b-sharded)                                    | ethzanalytics            | stablelm    | 7b         | none         | [The New Pile](https://pile.eleuther.ai/)                                                                                                                                                                                                                                                                                                                                                    | hf .bin                      |      | 2023-04-22 |
| [stablelm-tuned-alpha-7b-sharded](https://huggingface.co/ethzanalytics/stablelm-tuned-alpha-7b-sharded)                                  | ethzanalytics            | stablelm    | 7b         | none         | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | hf .bin                      |      | 2023-04-22 |
| [ggml-vicuna-13b-1.1](https://huggingface.co/eachadea/ggml-vicuna-13b-1.1)                                                               | eachadea                 | vicuna-v1.1 | 13b        | 4bit         | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      | 2023-04-22 |
| [MiniGPT-4-LLaMA-7B](https://huggingface.co/wangrongsheng/MiniGPT-4-LLaMA-7B)                                                            | wangrongsheng            | vicuna?     | 7b         | none         | minigpt-4                                                                                                                                                                                                                                                                                                                                                                                    | native .bin                  |      | 2023-04-22 |
| [llama-13b-supercot](https://huggingface.co/ausboss/llama-13b-supercot)                                                                  | ausboss                  | llama       | 13b        | none         | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-13b)                                                                                                                                                                                                                                                                 | native .bin                  |      | 2023-04-21 |
| [llama-30b-supercot](https://huggingface.co/ausboss/llama-30b-supercot)                                                                  | ausboss                  | llama       | 30b        | none         | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-30b)                                                                                                                                                                                                                                                                 | native .bin                  |      | 2023-04-21 |
| [llava-13b-v0-4bit-128g](https://huggingface.co/wojtab/llava-13b-v0-4bit-128g)                                                           | wojtab                   | llava       | 13b        | 4bit         | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | safetensors                  |      | 2023-04-21 |
| [rwkv-4-raven](https://huggingface.co/BlinkDL/rwkv-4-raven)                                                                              | BlinkDL                  | rwkv        | 3b/7b/14b  | none         | The Pile, Alpaca, CodeAlpaca, Guanaco, GPT4All, ShareGPT                                                                                                                                                                                                                                                                                                                                     | .pth                         |      | 2023-04-21 |
| [oasst-stablelm-7b-sft-v7-epoch-3-ggml-f16](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-f16)   | mongolian-basket-weaving | stablelm    | 7b         | 16bit        | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                         |      | 2023-04-21 |
| [oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_2](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_2) | mongolian-basket-weaving | stablelm    | 7b         | 4bit         | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                         |      | 2023-04-21 |
| [oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_3](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_3) | mongolian-basket-weaving | stablelm    | 7b         | 4bit         | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ggml                         |      | 2023-04-21 |
| [alpaca-lora-65B-GPTQ-4bit](https://huggingface.co/TheBloke/alpaca-lora-65B-GPTQ-4bit)                                                   | TheBloke                 | alpaca      | 65b        | 4bit GPTQ    | GPT 3.5 Alpaca dataset?                                                                                                                                                                                                                                                                                                                                                                      | safetensors                  |      | 2023-04-20 |
| [alpaca-lora-65B-GGML](https://huggingface.co/TheBloke/alpaca-lora-65B-GGML)                                                             | TheBloke                 | alpaca      | 65b        | 4bit / 2bit  | GPT 3.5 Alpaca dataset?                                                                                                                                                                                                                                                                                                                                                                      | ggml .bin                    |      | 2023-04-20 |
| [alpaca-lora-65B-GPTQ-4bit](https://huggingface.co/TheBloke/alpaca-lora-65B-GPTQ-4bit)                                                   | TheBloke                 | alpaca      | 65b        | 4bit GPTQ    | Alpaca LoRa                                                                                                                                                                                                                                                                                                                                                                                  | ?                            | ?    | 2023-04-20 |
| [llama-30b-oasst-4bit-128g](https://huggingface.co/Peeepy/llama-30b-oasst-4bit-128g)                                                     | Peeepy                   | llama       | 30b        | 4bit         | oasst-lora                                                                                                                                                                                                                                                                                                                                                                                   | safetensors                  |      | 2023-04-20 |
| [llama-30b-oasst-4bit](https://huggingface.co/Peeepy/llama-30b-oasst-4bit)                                                               | Peeepy                   | llama       | 30b        | 4bit         | oasst-lora                                                                                                                                                                                                                                                                                                                                                                                   | safetensors                  |      | 2023-04-20 |
| [llama-30b-oasst](https://huggingface.co/Peeepy/llama-30b-oasst)                                                                         | Peeepy                   | llama       | 30b        | none         | oasst-lora                                                                                                                                                                                                                                                                                                                                                                                   | native .bin                  |      | 2023-04-20 |
| [llama_65b_corr](https://huggingface.co/prodm93/llama_65b_corr)                                                                          | prodm93                  | llama       | 65b        | none         |                                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                      |      | 2023-04-20 |
| [llama_7b_corr](https://huggingface.co/prodm93/llama_7b_corr)                                                                            | prodm93                  | llama       | 7b         | none         |                                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                      |      | 2023-04-20 |
| [MiniGPT-4-LLaMA](https://huggingface.co/wangrongsheng/MiniGPT-4-LLaMA)                                                                  | wangrongsheng            | llama       | 13b        | none         | minigpt-4                                                                                                                                                                                                                                                                                                                                                                                    | native .bin                  |      | 2023-04-20 |
| [llava-13b-fp16](https://huggingface.co/mongolian-basket-weaving/llava-13b-fp16)                                                         | mongolian-basket-weaving | llava       | 13b        | 16bit        | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | native .bin                  |      | 2023-04-20 |
| [llava-13b-fp16-safetensors](https://huggingface.co/mongolian-basket-weaving/llava-13b-fp16-safetensors)                                 | mongolian-basket-weaving | llava       | 13b        | 16bit        | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | safetensors                  |      | 2023-04-20 |
| [stablelm-tuned-alpha-3b-16bit](https://huggingface.co/vvsotnikov/stablelm-tuned-alpha-3b-16bit)                                         | vvsotnikov               | stablelm    | 3b         | 16bit        | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | safetensors / .bin           |      | 2023-04-20 |
| [stablelm-tuned-alpha-7b-16bit](https://huggingface.co/vvsotnikov/stablelm-tuned-alpha-7b-16bit)                                         | vvsotnikov               | stablelm    | 7b         | 16bit        | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | safetensors / .bin           |      | 2023-04-20 |
| [h2ogpt-oig-oasst1-256-20b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-20b)                                                      | h2oai                    | gpt-neox    | 20b        | none         | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                  |      | 2023-04-19 |
| [stablelm-tuned-alpha-3b/](https://huggingface.co/stabilityai/stablelm-tuned-alpha-3b/)                                                  | stabilityai              | stablelm    | 3b         | none         | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | native .bin                  |      | 2023-04-19 |
| [stablelm-tuned-alpha-7b/](https://huggingface.co/stabilityai/stablelm-tuned-alpha-7b/)                                                  | stabilityai              | stablelm    | 7b         | none         | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH                                                                                                                                                                                                                                                    | native .bin                  |      | 2023-04-19 |
| [vicuna-13b-GPTQ-4bit-128g](https://huggingface.co/4bit/vicuna-13b-GPTQ-4bit-128g)                                                       | 4bit                     | vicuna      | 13b        | 4bit GPTQ    | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                  |      | 2023-04-19 |
| [ggml-vicuna-7b-1.1](https://huggingface.co/eachadea/ggml-vicuna-7b-1.1)                                                                 | eachadea                 | vicuna-v1.1 | 7b         | 4bit         | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      | 2023-04-19 |
| [h2ogpt-oig-oasst1-256-12b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-12b)                                                      | h2oai                    | gpt-neox    | 12b        | none         | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                  |      | 2023-04-17 |
| [LLaVA-13b-delta-v0](https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0)                                                               | liuhaotian               | llava       | 13b        | 16bit        | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K)                                                                                                                                                                                                                                                                                                             | native .bin                  |      | 2023-04-17 |
| [h2ogpt-oasst1-512-12b](https://huggingface.co/h2oai/h2ogpt-oasst1-512-12b)                                                              | h2oai                    | pythia      | 12b        | none         | [openassistant_oasst1](https://huggingface.co/datasets/h2oai/openassistant_oasst1)                                                                                                                                                                                                                                                                                                           | native .bin                  |      | 2023-04-17 |
| [h2ogpt-oig-oasst1-256-12b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-12b)                                                      | h2oai                    | pythia      | 12b        | none         | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt)                                                                                                                                                                       | native .bin                  |      | 2023-04-17 |
| [stablelm-base-alpha-3b/](https://huggingface.co/stabilityai/stablelm-base-alpha-3b/)                                                    | stabilityai              | stablelm    | 3b         | none         | [The New Pile](https://pile.eleuther.ai/)                                                                                                                                                                                                                                                                                                                                                    | native .bin                  |      | 2023-04-17 |
| [GPT4-X-Alpaca-30B-4bit](https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-4bit)                                                           | MetaIX                   | alpaca      | 30b        | 4bit GPTQ    | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           |                              |      | 2023-04-15 |
| [vicuna-13B-1.1-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g)                                           | TheBloke                 | vicuna-v1.1 | 13b        | 4bit GPTQ    | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | triton pt / cuda safetensors |      | 2023-04-15 |
| [vicuna-13B-1.1-HF](https://huggingface.co/TheBloke/vicuna-13B-1.1-HF)                                                                   | TheBloke                 | vicuna-v1.1 | 13b        | 16bit        | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                      |      | 2023-04-15 |
| [Vicuna13B-v1.1-8bit-128g](https://huggingface.co/Thireus/Vicuna13B-v1.1-8bit-128g)                                                      | Thireus                  | vicuna-v1.1 | 13b        | 8bit GPTQ    | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                  |      | 2023-04-15 |
| [vicuna-13b-1_1-hf](https://huggingface.co/winglian/vicuna-13b-1_1-hf)                                                                   | winglian                 | vicuna-v1.1 | 13b        | none         | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                      |      | 2023-04-15 |
| [Alpacino30b](https://huggingface.co/digitous/Alpacino30b)                                                                               | digitous                 | alpaca      | 30b        | 16bit        | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | native .bin                  |      | 2023-04-14 |
| [Alpacino13b](https://huggingface.co/digitous/Alpacino13b)                                                                               | digitous                 | alpaca      | 13b        | 16bit        | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | native .bin                  |      | 2023-04-13 |
| [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b)                                                                             | databricks               | dolly       | 3b         | none         | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | native .bin                  |      | 2023-04-13 |
| [dolly-v2-7b](https://huggingface.co/databricks/dolly-v2-7b)                                                                             | databricks               | dolly       | 7b         | none         | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | native .bin                  |      | 2023-04-13 |
| [ggml-vicuna-1.1-q4_0](https://huggingface.co/CRD716/ggml-vicuna-1.1-q4_0)                                                               | CRD716                   | vicuna-v1.1 | 13b        | 4bit         | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      | 2023-04-13 |
| [ggml-vicuna-1.1-q4_0](https://huggingface.co/CRD716/ggml-vicuna-1.1-q4_0)                                                               | CRD716                   | vicuna-v1.1 | 7b         | 4bit         | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      | 2023-04-13 |
| [dolly-v2-12b](https://huggingface.co/databricks/dolly-v2-12b)                                                                           | databricks               | dolly       | 12b        | none         | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | native .bin                  |      | 2023-04-12 |
| [dolly-v2-12b-GPTQ-4bit-128g](https://huggingface.co/mzedp/dolly-v2-12b-GPTQ-4bit-128g)                                                  | mzedp                    | dolly       | 12b        | 4bit         | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data)                                                                                                                                                                                                                                                                                                             | safetensors                  |      | 2023-04-12 |
| [Base-GPT4-x-Alpaca-Roleplay-Lora](https://huggingface.co/teknium/Base-GPT4-x-Alpaca-Roleplay-Lora)                                      | teknium                  | llama       | 13b        | none         | gpt4-x-alpaca finetune, [roleplay instruct](https://github.com/teknium1/GPTeacher/tree/main/Roleplay)                                                                                                                                                                                                                                                                                        |                              |      | 2023-04-12 |
| [vicuna-13B-1.1-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g-GGML)                                 | TheBloke                 | vicuna-v1.1 | 13b        | 4bit GPTQ    | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      | 2023-04-12 |
| [vicuna-7B-1.1-HF](https://huggingface.co/TheBloke/vicuna-7B-1.1-HF)                                                                     | TheBloke                 | vicuna-v1.1 | 7b         | 16bit        | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | hf .bin                      |      | 2023-04-12 |
| [vicuna-7B-1.1-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-7B-1.1-GPTQ-4bit-128g)                                             | TheBloke                 | vicuna-v1.1 | 7b         | 4bit GPTQ    | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | triton pt / cuda safetensors |      | 2023-04-12 |
| [vicuna-7B-1.1-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/vicuna-7B-1.1-GPTQ-4bit-128g-GGML)                                   | TheBloke                 | vicuna-v1.1 | 7b         | 4bit GPTQ    | vicuna censored                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      | 2023-04-12 |
| [gpt4all-j](https://huggingface.co/nomic-ai/gpt4all-j)                                                                                   | nomic-ai                 | gpt-j       | 6b         | 16bit        | [gpt4all-j-prompt-generations](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations)                                                                                                                                                                                                                                                                                        | native .bin                  |      | 2023-04-11 |
| [llama-13b-pretrained-dropout-hf-int4-128g](https://huggingface.co/verymuchawful/llama-13b-pretrained-dropout-hf-int4-128g)              | verymuchawful            | llama       | 13b        | 4bit GPTQ    | Open-Assistant?                                                                                                                                                                                                                                                                                                                                                                              | safetensors                  |      | 2023-04-11 |
| [stablelm-base-alpha-7b/](https://huggingface.co/stabilityai/stablelm-base-alpha-7b/)                                                    | stabilityai              | stablelm    | 7b         | none         | [The New Pile](https://pile.eleuther.ai/)                                                                                                                                                                                                                                                                                                                                                    | native .bin                  |      | 2023-04-11 |
| [instruct-13b-4bit-ggml](https://huggingface.co/llama-anon/instruct-13b-4bit-ggml)                                                       | llama-anon               | llama       | 13b        | 4bit GPTQ?   | instruct-13b weights                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                    |      | 2023-04-10 |
| [Alpaca-30B-Int4-128G-Safetensors](https://huggingface.co/MetaIX/Alpaca-30B-Int4-128G-Safetensors)                                       | MetaIX                   | alpaca      | 30b        | 4bit         | Clean Alpaca dataset of 2023-04-06 using Chansung ALpaca Lora                                                                                                                                                                                                                                                                                                                                | safetensor                   |      | 2023-04-06 |
| [alpaca-lora-13b](https://huggingface.co/chansung/alpaca-lora-13b)                                                                       | chansung                 | alpaca      | 13b        | 8bit         | [cleaned-up aplaca dataset](https://github.com/gururise/AlpacaDataCleaned)                                                                                                                                                                                                                                                                                                                   | native .bin                  | yes  | 2023-04-05 |
| [alpaca-lora-65b](https://huggingface.co/chansung/alpaca-lora-65b)                                                                       | chansung                 | alpaca      | 65b        | 16bit        | GPT 3.5 Alpaca dataset?                                                                                                                                                                                                                                                                                                                                                                      | native .bin                  | yes  | 2023-04-03 |
| [gpt4-x-alpaca-13b-native-4bit-128g](https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g)                           | anon8231489123           | alpaca      | 13b        | 4bit GPTQ    | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | triton / cuda                |      | 2023-04-01 |
| [gpt4-x-alpaca](https://huggingface.co/chavinlo/gpt4-x-alpaca)                                                                           | chavinlo                 | alpaca      | 13b        | 16bit        | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | native .bin                  |      | 2023-03-31 |
| [alpaca-7b-nativeEnhanced](https://huggingface.co/8bit-coder/alpaca-7b-nativeEnhanced)                                                   | 8bit-coder               | alpaca      | 7b         | 16bit        |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  |      | 2023-03-28 |
| [alpaca-30b](https://huggingface.co/baseten/alpaca-30b)                                                                                  | baseten                  | alpaca      | 30b        | 16bit        |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  | yes  | 2023-03-19 |
| [alpaca-lora-13b](https://huggingface.co/baruga/alpaca-lora-13b)                                                                         | baruga                   | alpaca      | 13b        | 8bit         |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  | yes  | 2023-03-18 |
| [alpaca-native](https://huggingface.co/chavinlo/alpaca-native)                                                                           | chavinlo                 | alpaca      | 7b         | 16bit        |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  |      | 2023-03-18 |
| [alpaca-13b](https://huggingface.co/Dogge/alpaca-13b)                                                                                    | Dogge                    | alpaca      | 13b        | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  |      |            |
| [llama-alpaca-stuff/tree/main/Alpaca-Loras](https://huggingface.co/Draff/llama-alpaca-stuff/tree/main/Alpaca-Loras)                      | Draff                    | alpaca      | 13b        | 8bit         |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  | yes  |            |
| [ggml-gpt4-x-alpaca-13b-native-4bit](https://huggingface.co/eachadea/ggml-gpt4-x-alpaca-13b-native-4bit)                                 | eachadea                 | alpaca      | 13b        | 4bit         | Alpaca                                                                                                                                                                                                                                                                                                                                                                                       | ggml                         |      |            |
| [alpaca-30b-lora-int4](https://huggingface.co/elinas/alpaca-30b-lora-int4)                                                               | elinas                   | alpaca      | 30b        | 4bit GPTQ    | Alpaca                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                  |      |            |
| [alpaca-13b-lora-int4](https://huggingface.co/elinas/alpaca-13b-lora-int4)                                                               | elinas                   | alpaca      | 7b         | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | safetensors                  | yes  |            |
| [alpacino-13b-4bit-128g](https://huggingface.co/gozfarb/alpacino-13b-4bit-128g)                                                          | gozfarb                  | alpaca      | 13b        | 4bit         | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | safetensors                  |      |            |
| [gpt4all-alpaca-oa-codealpaca-lora-13b](https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b)                         | jordiclive               | alpaca      | 13b        | ?            | Nebulous/gpt4all_pruned, sahil2801/CodeAlpaca-20k, yahma/alpaca-cleaned, part of OpenAssistant                                                                                                                                                                                                                                                                                               | native .bin                  | yes  |            |
| [gpt4all-alpaca-oa-codealpaca-lora-7b](https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-7b)                           | jordiclive               | alpaca      | 7b         | ?            | [gpt4all_pruned](https://huggingface.co/datasets/Nebulous/gpt4all_pruned)<br />[CodeAlpaca-20k](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)<br />[alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)                                                                                                                                                        | ?                            | yes  |            |
| [alpaca-native-7B-4bit-ggjt](https://huggingface.co/LLukas22/alpaca-native-7B-4bit-ggjt)                                                 | LLukas22                 | alpaca      | 7b         | 4bit GPTQ?   |                                                                                                                                                                                                                                                                                                                                                                                              | ggjt                         |      |            |
| [Alpacino-30b-ggml](https://huggingface.co/Melbourne/Alpacino-30b-ggml)                                                                  | Melbourne                | alpaca      | 30b        | 16bit        | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | new ggml                     |      |            |
| [alpaca-native-4bit](https://huggingface.co/ozcur/alpaca-native-4bit)                                                                    | ozcur                    | alpaca      | 7b         | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | hf .pt                       |      |            |
| [alpaca-13B-ggml](https://huggingface.co/Pi3141/alpaca-13B-ggml)                                                                         | Pi3141                   | alpaca      | 13b        | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    | yes  |            |
| [alpaca-30B-ggml](https://huggingface.co/Pi3141/alpaca-30B-ggml)                                                                         | Pi3141                   | alpaca      | 30b        | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      |            |
| [alpaca-7B-ggml](https://huggingface.co/Pi3141/alpaca-7B-ggml)                                                                           | Pi3141                   | alpaca      | 7b         | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    | yes  |            |
| [alpaca13B-lora](https://huggingface.co/samwit/alpaca13B-lora)                                                                           | samwit                   | alpaca      | 13b        | 8bit         |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  | yes  |            |
| [gpt4-x-alpaca-13b-native-4bit-128g](https://huggingface.co/Selyam/gpt4-x-alpaca-13b-native-4bit-128g)                                   | Selyam                   | alpaca      | 13b        | 4bit GPTQ    | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | triton / cuda                |      |            |
| [Alpaca-native-4bit-ggml](https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml)                                                         | Sosaka                   | alpaca      | 7b         | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      |            |
| [alpaca-lora-7b/](https://huggingface.co/tloen/alpaca-lora-7b/)                                                                          | tloen                    | alpaca      | 7b         | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  | yes  |            |
| [gpt4-x-alpaca-13b-native-4bit-128g-cuda](https://huggingface.co/tsumeone/gpt4-x-alpaca-13b-native-4bit-128g-cuda)                       | tsumeone                 | alpaca      | 13b        | 4bit         | [GPTeacher](https://github.com/teknium1/GPTeacher)                                                                                                                                                                                                                                                                                                                                           | cuda safetensors             |      |            |
| [Alpacino-13b-ggml](https://huggingface.co/verymuchawful/Alpacino-13b-ggml)                                                              | verymuchawful            | alpaca      | 13b        | 16bit        | CoT + Storytelling                                                                                                                                                                                                                                                                                                                                                                           | new ggml                     |      |            |
| [llama-13b-4bit-gr128](https://huggingface.co/4bit/llama-13b-4bit-gr128)                                                                 | 4bit                     | llama       | 13b        | 4bit GPTQ    | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                       |      |            |
| [oasst-llama13b-ggml](https://huggingface.co/Black-Engineer/oasst-llama13b-ggml)                                                         | Black-Engineer           | llama       | 13b        | 16bit        | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | ? .bin                       |      |            |
| [llama-13b-pretrained-sft-do2-ggml-q4](https://huggingface.co/Black-Engineer/llama-13b-pretrained-sft-do2-ggml-q4)                       | Black-Engineer           | llama       | 13b        | 4bit         | ?                                                                                                                                                                                                                                                                                                                                                                                            | ggml                         |      |            |
| [oasst-llama13b-ggml-q4](https://huggingface.co/Black-Engineer/oasst-llama13b-ggml-q4)                                                   | Black-Engineer           | llama       | 13b        | 4bit         | Open-Assistant, Alpaca                                                                                                                                                                                                                                                                                                                                                                       | ggml                         |      |            |
| [oasst-llama30b-ggml-q4](https://huggingface.co/Black-Engineer/oasst-llama30b-ggml-q4)                                                   | Black-Engineer           | llama       | 30b        | 4bit         | Open-Assistant, Alpaca                                                                                                                                                                                                                                                                                                                                                                       | ggml                         |      |            |
| [llama-65b-ggml-q4_0](https://huggingface.co/camelids/llama-65b-ggml-q4_0)                                                               | camelids                 | llama       | 65b        | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      |            |
| [llama-7b-hf](https://huggingface.co/decapoda-research/llama-7b-hf)                                                                      | decapoda-research        | llama       | 7b         | 16bit        | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                       |      |            |
| [llama-13b-pretrained-sft-do2](https://huggingface.co/dvruette/llama-13b-pretrained-sft-do2)                                             | dvruette                 | llama       | 13b        | 16bit        | ?                                                                                                                                                                                                                                                                                                                                                                                            | native .bin                  |      |            |
| [llama-13b-pretrained-dropout](https://huggingface.co/dvruette/llama-13b-pretrained-dropout)                                             | dvruette                 | llama       | 13b        | 16bit        | Open-Assistant?                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  |      |            |
| [llama-30b-int4](https://huggingface.co/elinas/llama-30b-int4)                                                                           | elinas                   | llama       | 13b        | 4bit GPTQ    | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                       |      |            |
| [instruct-13b-4bit-128g](https://huggingface.co/gozfarb/instruct-13b-4bit-128g)                                                          | gozfarb                  | llama       | 13b        | 4bit GPTQ?   | instruct-13b weights                                                                                                                                                                                                                                                                                                                                                                         | safetensors                  |      |            |
| [oasst-llama13b-4bit-128g](https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g)                                                      | gozfarb                  | llama       | 13b        | 4bit         | Open-Assistant                                                                                                                                                                                                                                                                                                                                                                               | safetensors                  |      |            |
| [llama-30b-4bit](https://huggingface.co/kuleshov/llama-30b-4bit)                                                                         | kuleshov                 | llama       | 13b        | 4bit GPTQ    | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                       |      |            |
| [llama13b-lora-gpt4all](https://huggingface.co/magicgh/llama13b-lora-gpt4all)                                                            | magicgh                  | llama       | 13b        | ?            | GPT4All, Alpaca-CoT                                                                                                                                                                                                                                                                                                                                                                          | .bin                         | yes  |            |
| [llama30b-lora-cot](https://huggingface.co/magicgh/llama30b-lora-cot)                                                                    | magicgh                  | llama       | 30b        | ?            | Alpaca-CoT                                                                                                                                                                                                                                                                                                                                                                                   | .bin                         | yes  |            |
| [gpt4all-lora](https://huggingface.co/nomic-ai/gpt4all-lora)                                                                             | nomic-ai                 | llama       | 7b         | ?            | [gpt4all prompt generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations)                                                                                                                                                                                                                                                                                            | ?                            | yes  |            |
| [llama-13B-ggml](https://huggingface.co/Pi3141/llama-13B-ggml)                                                                           | Pi3141                   | llama       | 13b        | 4bit GPTQ    | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                    |      |            |
| [llama-30B-ggml](https://huggingface.co/Pi3141/llama-30B-ggml)                                                                           | Pi3141                   | llama       | 30b        | 4bit GPTQ    | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                    |      |            |
| [llama-65B-ggml](https://huggingface.co/Pi3141/llama-65B-ggml)                                                                           | Pi3141                   | llama       | 65b        | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | ggml .bin                    |      |            |
| [llama-7B-ggml](https://huggingface.co/Pi3141/llama-7B-ggml)                                                                             | Pi3141                   | llama       | 7b         | 4bit GPTQ    | none                                                                                                                                                                                                                                                                                                                                                                                         | ggml .bin                    |      |            |
| [koala-13B-HF](https://huggingface.co/TheBloke/koala-13B-HF)                                                                             | TheBloke                 | llama       | 13b        | 16bit        | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | native .bin                  |      |            |
| [koala-13B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g)                                                     | TheBloke                 | llama       | 13b        | 4bit GPTQ    | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | triton pt / cuda safetensors |      |            |
| [koala-13B-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g-GGML)                                           | TheBloke                 | llama       | 13b        | 4bit GPTQ    | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | ggml                         |      |            |
| [koala-7b-ggml-unquantized](https://huggingface.co/TheBloke/koala-7b-ggml-unquantized)                                                   | TheBloke                 | llama       | 7b         | 16bit        | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | ggml                         |      |            |
| [koala-7B-HF](https://huggingface.co/TheBloke/koala-7B-HF)                                                                               | TheBloke                 | llama       | 7b         | 16bit        | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | native .bin                  |      |            |
| [koala-7B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g)                                                       | TheBloke                 | llama       | 7b         | 4bit GPTQ    | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | triton pt / cuda safetensors |      |            |
| [koala-7B-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g-GGML)                                             | TheBloke                 | llama       | 7b         | 4bit GPTQ    | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization                                                                                                                                                                                                                                                                                                         | ggml                         |      |            |
| [llama-30b-int4](https://huggingface.co/TianXxx/llama-30b-int4)                                                                          | TianXxx                  | llama       | 13b        | 4bit GPTQ    | none                                                                                                                                                                                                                                                                                                                                                                                         | hf .pt                       |      |            |
| [pythia-12b-pre-2000](https://huggingface.co/andreaskoepf/pythia-12b-pre-2000)                                                           | andreaskoepf             | pythia      | 12b        | 16bit        | joke, webgpt, gpt4all, alpaca, code_alpaca, minimath, codegen, testgen, grade school math, recipes, cmu wiki, oa wiki, prosocial dialogue, explain prosocial                                                                                                                                                                                                                                 | native .bin                  |      |            |
| [pythia-12b-pre-3500](https://huggingface.co/andreaskoepf/pythia-12b-pre-3500)                                                           | andreaskoepf             | pythia      | 12b        | 16bit        | joke, webgpt, gpt4all, alpaca, code_alpaca, minimath, codegen, testgen, grade school math, recipes, cmu wiki, oa wiki, prosocial dialogue, explain prosocial                                                                                                                                                                                                                                 | native .bin                  |      |            |
| [pythia-6.9b-gpt4all-pretrain](https://huggingface.co/andreaskoepf/pythia-6.9b-gpt4all-pretrain)                                         | andreaskoepf             | pythia      | 6.9b       | 16bit        | Open-Assistant? gpt4all?                                                                                                                                                                                                                                                                                                                                                                     | native .bin                  |      |            |
| [oasst-pythia-12b-pretrained](https://huggingface.co/dvruette/oasst-pythia-12b-pretrained)                                               | dvruette                 | pythia      | 12b        | 16bit        | Open-Assistant?                                                                                                                                                                                                                                                                                                                                                                              | native .bin                  |      |            |
| [oasst-pythia-12b-reference](https://huggingface.co/dvruette/oasst-pythia-12b-reference)                                                 | dvruette                 | pythia      | 12b        | 16bit        | ?                                                                                                                                                                                                                                                                                                                                                                                            | native .bin                  |      |            |
| [vicuna-7b](https://huggingface.co/AlekseyKorshuk/vicuna-7b)                                                                             | AlekseyKorshuk           | vicuna      | 7b         | ?            | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                                                                                                                                             | native .bin                  |      |            |
| [vicuna-13b-GPTQ-4bit-128g](https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g)                                             | anon8231489123           | vicuna      | 13b        | 4bit GPTQ    | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | safetensors                  |      |            |
| [vicuna-13b-fine-tuned-rlhf](https://huggingface.co/CarperAI/vicuna-13b-fine-tuned-rlhf)                                                 | CarperAI                 | vicuna      | 13b        | 16bit        | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca), [gpt4all_prompt_generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human Preferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) | native .bin                  |      |            |
| [ggml-vicuna-13b-4bit](https://huggingface.co/eachadea/ggml-vicuna-13b-4bit)                                                             | eachadea                 | vicuna      | 13b        | 4bit GPTQ?   | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ggml .bin                    |      |            |
| [vicuna-13b](https://huggingface.co/eachadea/vicuna-13b)                                                                                 | eachadea                 | vicuna      | 13b        | 16bit        | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ?                            |      |            |
| [ggml-vicuna-7b-4bit](https://huggingface.co/eachadea/ggml-vicuna-7b-4bit)                                                               | eachadea                 | vicuna      | 7b         | 4bit         | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | new ggml                     |      |            |
| [vicuna-13b-4bit](https://huggingface.co/elinas/vicuna-13b-4bit)                                                                         | elinas                   | vicuna      | 13b        | 4bit GPTQ    |                                                                                                                                                                                                                                                                                                                                                                                              | safetensors                  |      |            |
| [vicuba-7b-int4-128g](https://huggingface.co/gozfarb/vicuba-7b-int4-128g)                                                                | gozfarb                  | vicuna      | 7b         | 4bit GPTQ    | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                                                                                                                                             | safetensors                  |      |            |
| [vicuna-13b](https://huggingface.co/helloollel/vicuna-13b)                                                                               | helloollel               | vicuna      | 13b        | 16bit        | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | native .bin                  |      |            |
| [vicuna-7b](https://huggingface.co/helloollel/vicuna-7b)                                                                                 | helloollel               | vicuna      | 7b         | 16bit        | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       |                              |      |            |
| [vicuna-13b/tree/main](https://huggingface.co/jeffwan/vicuna-13b/tree/main)                                                              | jeffwan                  | vicuna      | 13b        | ?            | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ?                            |      |            |
| [vicuna-13b-delta-v0](https://huggingface.co/lmsys/vicuna-13b-delta-v0)                                                                  | lmsys                    | vicuna      | 13b        | 16bit        |                                                                                                                                                                                                                                                                                                                                                                                              | ?                            |      |            |
| [vicuna-13b-8bit](https://huggingface.co/samwit/vicuna-13b-8bit)                                                                         | samwit                   | vicuna      | 13b        | 8bit         |                                                                                                                                                                                                                                                                                                                                                                                              | ?                            |      |            |
| [Vicuna-13B](https://huggingface.co/ShreyasBrill/Vicuna-13B)                                                                             | ShreyasBrill             | vicuna      | 13b        | 4bit (GPTQ?) | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) [llama](https://huggingface.co/datasets/viewv/LLaMA-13B) [shareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                         | ggml .bin / safetensors      |      |            |
| [Vicuna-7B-4bit-ggml](https://huggingface.co/Sosaka/Vicuna-7B-4bit-ggml)                                                                 | Sosaka                   | vicuna      | 7b         | 4bit GPTQ?   | Vicuna                                                                                                                                                                                                                                                                                                                                                                                       | ggml                         |      |            |
| [vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g)                       | TheBloke                 | vicuna      | 7b         | 4bit GPTQ    | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)                                                                                                                                                                                                                                                                                             | safetensors                  |      |            |
| [Vicuna-13b](https://huggingface.co/titan087/Vicuna-13b)                                                                                 | titan087                 | vicuna      | 13b        | 16bit        |                                                                                                                                                                                                                                                                                                                                                                                              | ?                            |


## Other SOTA Open Source models
- [Cerebras GPT-13b](https://huggingface.co/cerebras) ([release notes](https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/))
- [LAION OpenFlamingo | Multi Modal Model and training architecture](https://github.com/mlfoundations/open_flamingo)
- [TheBloke/galpaca-30b-gptq-4bit-128g](https://huggingface.co/TheBloke/galpaca-30B-GPTQ-4bit-128g), GALACTICA 30B fine tuned with Alpaca 
- [GeorgiaTechResearchInstitute/galpaca-6.7b](https://huggingface.co/GeorgiaTechResearchInstitute/galpaca-6.7b) GALACTICA 6.7B fine tuned with Alpaca
- [GeoV/GeoV-9b](https://huggingface.co/GeoV/GeoV-9b) - 9B parameter, in-progress training to 300B tokens (33:1)
- [RWKV: Parallelizable RNN with Transformer-level LLM Performance](https://github.com/BlinkDL/RWKV-LM)
- [CodeGeeX 13B | Multi Language Code Generation Model](https://huggingface.co/spaces/THUDM/CodeGeeX)
- [BigCode | Open Scientific collaboration to train a coding LLM](https://huggingface.co/bigcode)
- [MOSS by Fudan University](https://github.com/OpenLMLab/MOSS)


## Data sets
- [Alpaca-lora instruction finetuned using Low Rank Adaption](https://github.com/tloen/alpaca-lora)
- [codealpaca Instruction training data set for code generation](https://github.com/sahil280114/codealpaca)
- [LAION AI / Open-Assistant Dataset](https://huggingface.co/datasets/OpenAssistant/oasst1) (https://github.com/LAION-AI/Open-Assistant / https://projects.laion.ai/Open-Assistant/ / https://open-assistant.io)
- [pre-cleaned, English only, "unfiltered," and 2048 token split version of the ShareGPT dataset ready for finetuning](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)
- [Vicuna ShareGPT pre-cleaned 90k conversation dataset](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/tree/main/HTML_cleaned_raw_dataset)
- [Vicuna ShareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered)
- [GPTeacher](https://github.com/teknium1/GPTeacher)
- [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned)
- [codealpaca 20k](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)
- [gpt3all pruned](https://huggingface.co/datasets/Nebulous/gpt4all_pruned)
- [gpt4all_prompt_generations_with_p3](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations_with_p3)
- [gpt4all_prompt_generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations)
- [alpaca-plus-gpt4all-without-p3](https://huggingface.co/datasets/magicgh/alpaca-plus-gpt4all-without-p3)
- [Alpaca dataset from Stanford, cleaned and curated](https://github.com/gururise/AlpacaDataCleaned) 
- [Alpaca Chain of Thought fine tuning dataset for EN and CN](https://github.com/PhoebusSi/Alpaca-CoT)
- [PRESTO | Multilingual dataset for parsing realistic task-oriented dialogues by Google & University of Rochester, California, Santa Barbara, Columbia](https://ai.googleblog.com/2023/03/presto-multilingual-dataset-for-parsing.html) [paper](https://arxiv.org/pdf/2303.08954.pdf)
- [RedPajama | Dataset and model similar to LLaMA but truly open source and ready for commercial use](https://www.together.xyz/blog/redpajama)
- [BigCode The Stack](https://huggingface.co/datasets/bigcode/the-stack)
- [open-instruct-v1](https://huggingface.co/datasets/hakurei/open-instruct-v1)
- [list of instruction datasets by yadongC/awesome-instruction-dataset](https://github.com/yaodongC/awesome-instruction-dataset)
- [The Embedding Archives, Millions of Wikipedia Article Embeddings in multiple languages](https://txt.cohere.com/embedding-archives-wikipedia/)

## Research
- [LLM Model Cards](https://docs.google.com/spreadsheets/d/1O5KVQW1Hx5ZAkcg8AIRjbQLQzx2wVaLl0SqUu-ir9Fs)
- [GPTs are GPTs: An early look at the labor market impact potential of LLMs](https://arxiv.org/abs/2303.10130)
- [ViperGPT Visual Inference via Python Execution for reasoning](https://viper.cs.columbia.edu/)
- [Emergent Abilities of LLMs ](https://openreview.net/forum?id=yzkSU5zdwD), [blog post](https://www.jasonwei.net/blog/emergence)
- [visualchatgpt | Microsoft research proposes a multi-modal architecture to give chatgpt the ability to interpret and generate images based on open source foundation models](https://github.com/microsoft/visual-chatgpt)
- [facts checker reinforcement](https://arxiv.org/abs/2302.12813)
- [LLaVA: Large Language and Vision Assistant, combining LLaMA with a visual model. Delta-weights released](https://llava-vl.github.io/)
- [Mass Editing Memory in a Transformer](https://memit.baulab.info/)
- [MiniGPT-4: Enhancing Vision-language Understanding with Advanced Large Language Models](https://minigpt-4.github.io/)
- [WizardLM | Fine tuned LLaMA 7B with evolving instructions, outperforming chatGPT and Vicuna 13B on complex test instructions](https://arxiv.org/abs/2304.12244) ([code](https://github.com/nlpxucan/WizardLM), [delta weights](https://huggingface.co/victor123/WizardLM))
- [Scaling Transformer to 1M tokens and beyond with RMT](https://arxiv.org/abs/2304.11062)
- [AudioGPT | Understanding and Generating Speech, Music, Sound, and Talking Head](https://arxiv.org/abs/2304.12995) ([AIGC-Audio/AudioGPT](https://github.com/AIGC-Audio/AudioGPT), [hf space](https://huggingface.co/spaces/AIGC-Audio/AudioGPT))

## LLM GUIs
### OpenAI
- [chatgptui/desktop](https://github.com/chatgptui/desktop)
- [TypingMind](https://www.typingmind.com/)
- [Chatwithme.chat](https://www.chatwithme.chat/)
- [datafilik/GPT-Voice-Assistant](https://github.com/datafilik/GPT-Voice-Assistant)
- [Abdallah-Ragab/VoiceGPT](https://github.com/Abdallah-Ragab/VoiceGPT)
- [LlmKira/Openaibot](https://github.com/LlmKira/Openaibot)
- [chathub-dev/chathub](https://github.com/chathub-dev/chathub)
- [enricoros/nextjs-chatgpt-app](https://github.com/enricoros/nextjs-chatgpt-app)
- [no8081/chatgpt-demo](https://github.com/ddiu8081/chatgpt-demo)
- [Auto GPT](https://github.com/Torantulino/Auto-GPT)
- [cheetah | Speech to text for remote coding interviews, giving you hints from GTP3/4](https://github.com/leetcode-mafia/cheetah)
- [sqlchat | Use OpenAI GPT3/4 to chat with your database](https://github.com/sqlchat/sqlchat)
- [BarkingGPT | Audio2Audio by using Whisper+chatGPT+Bark](https://github.com/BudEcosystem/BarkingGPT)
- [ALFRED | LangChain Voice Assistant, powered by GPT-3.5-turbo, whisper, Bark, pyttsx3 and more](https://github.com/masrad/ALFRED)

### Other GUIs
- [Alpaca.cpp](https://github.com/antimatter15/alpaca.cpp)
- [Text Generation Webui | An all purpose UI to run LLMs of all sorts with optimizations](https://github.com/oobabooga/text-generation-webui) ([running LLaMA on less than 10GB vram](https://github.com/oobabooga/text-generation-webui/issues/147#issuecomment-1456040134), [running LLaMA-7b on a 3080](https://github.com/TimDettmers/bitsandbytes/issues/30#issuecomment-1455993902), [detailed guide](https://rentry.org/llama-tard-v2))
- [Alpaca-LoRa-Serve](https://github.com/deep-diver/Alpaca-LoRA-Serve)
- [ChatLLaMA | another implementation](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [Dalai](https://github.com/cocktailpeanut/dalai)
- [ChatLLaMA | LLaMA-based ChatGPT for single GPUs](https://github.com/juncongmoo/chatllama)
- [Chatbot web app + HTTP and Websocket endpoints for BLOOM-176B inference with the Petals client](https://github.com/borzunov/chat.petals.ml)
- [Vicuna FastChat](https://github.com/lm-sys/FastChat)
- [Lit-llama](https://github.com/Lightning-AI/lit-llama)
- [gpt4all](https://github.com/nomic-ai/gpt4all)
- [openplayground Try out almost any LLM in a gui](https://github.com/nat/openplayground)
- [Alpaca-Turbo | Web UI to run alpaca model locally on Win/Mac/Linux](https://github.com/ViperX7/Alpaca-Turbo)
- [FreedomGPT | Web app that executes the FreedomGPT LLM locally](https://github.com/ohmplatform/FreedomGPT)
- [Auto Vicuna Butler| Baby-AGI fork / AutoGPT alternative to run with local LLMs](https://github.com/NiaSchim/auto-vicuna-butler)
- [BabyAGI | AI-Powered Task Management for OpenAI + Pinecone or Llama.cpp](https://github.com/yoheinakajima/babyagi)
- [huggingGPT / JARVIS | Connects LLMs with huggingface specialized models](https://github.com/microsoft/JARVIS)
- [OpenAGI | AGI research platform, solves multi step tasks with RLTF and supports complex model chains](https://github.com/agiresearch/openagi)
- [Agent-LLM | AI Automation Platform. Various providers, adaptive memory, plugin system, web browsing](https://github.com/Josh-XT/Agent-LLM)
- [bark TTS for oobabooga/text-generation-webui, make your local LLM talk](https://github.com/wsippel/bark_tts)
- [bark TTS for oobabooga/text-generation-webui, another implementation](https://github.com/minemo/text-generation-webui-barktts)
- [HuggingChat](https://huggingface.co/chat) open source chat interface for transformer based LLMs by Huggingface

## LLM Wrappers
- [acheong08/ChatGPT Python](https://github.com/acheong08/ChatGPT)
- [mpoon/gpt-repository-loader](https://github.com/mpoon/gpt-repository-loader)
- [LangChain | framework for developing LLM applications](https://github.com/hwchase17/langchain) ([example](https://www.youtube.com/watch?v=iRJ4uab_NIg&t=588s), [paolorechia/learn-langchain with vicuna and GPQT 4 bit support](https://github.com/paolorechia/learn-langchain))
- [LangFlow | GUI for Langchain](https://github.com/logspace-ai/langflow)
- [pyllama | hacked version of LLaMA based on Meta's implementation, optimized for Single GPUs](https://github.com/juncongmoo/pyllama)
- [Toolformer implementation | Allows LLMs to use Tools](https://github.com/lucidrains/toolformer-pytorch)
- [FastLLaMA Python wrapper for llama.cpp](https://github.com/PotatoSpudowski/fastLLaMa)
- [LlamaIndex (GPT Index) connecting LLMs to external data](https://github.com/jerryjliu/llama_index)
- [supercharger | Write Software + unit tests for you, based on Baize-30B 8bit, using model parallelism](https://github.com/catid/supercharger)
- [WebGPT Inference in pure javascript](https://github.com/0hq/WebGPT)
- [WasmGPT ChatGPT-like chatbot in browser using ggml and emscripten](https://github.com/lxe/ggml/tree/wasm-demo)
- [Tabby | Self hosted Github Copilot alternative](https://github.com/TabbyML/tabby)
- [Turbopilot | open source LLM code completion engine and Copilot alternative](https://github.com/ravenscroftj/turbopilot)
- [FauxPilot | open source Copilot alternative using Triton Inference Server](https://github.com/fauxpilot/fauxpilot)
- [Sidekick | Information retrieval for LLMs](https://github.com/ai-sidekick/sidekick)
- [gpt4free | Use reverse engineered GPT3.5/4 APIs of other website's APIs](https://github.com/xtekky/gpt4free)
- [AutoGPTQ | easy-to-use model GPTQ quantization package with user-friendly CLI](https://github.com/PanQiWei/AutoGPTQ)


## Showcases
- [Opinionate.io AI Debating AI](https://opinionate.io/)
- [phind.com](phind.com) Developer Search Engine
- [Voice Q&A Assistant](https://github.com/hackingthemarkets/qa-assistant-eleven-labs-voice-cloning) using ChatGPT API, Embeddings, Gradio, Eleven Labs and Whisper

## Fine Tuning
- [simple llama finetuner](https://github.com/lxe/simple-llama-finetuner)
- [LLaMA-LoRA Tuner](https://github.com/zetavg/LLaMA-LoRA-Tuner)
- [alpaca-lora](https://github.com/tloen/alpaca-lora)
- [StackLLaMA Fine-Tuning Guide by huggingface](https://huggingface.co/blog/stackllama)
- [xTuring | LLM finetuning pipeline supporting LoRa & 4bit](https://github.com/stochasticai/xturing)
- [Microsoft DeepSpeed Chat](https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/README.md)
- [How to train your LLMs](https://blog.replit.com/llm-training)
- [H2O LLM Studio | Framework and no-code GUI for fine tuning SOTA LLMs](https://github.com/h2oai/h2o-llmstudio)

## Other awesome lists
- [LLM Worksheet](https://docs.google.com/spreadsheets/d/1kT4or6b0Fedd-W_jMwYpb63e1ZR3aePczz3zlbJW-Y4/edit#gid=741531996) by [randomfoo2](https://www.reddit.com/r/LocalAI/comments/12smsy9/list_of_public_foundational_models_fine_tunes/)
- 

# Image Generation

## Models
- https://github.com/kakaobrain/karlo
- https://lukashoel.github.io/text-to-room/
- [facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything)
- 

## Wrappers & GUIs
- [a Stable Diffusion UI](https://github.com/brycedrennan/imaginAIry/blob/master/README.md)
- [InvokeAI | Alternative, polished stable diffusion UI with less features than automatic1111](https://github.com/invoke-ai/InvokeAI)
- [Automatic1111/stable-diffusion-webui | The most famous UI for Stable Diffusion with the most features](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- [mlc-ai/web-stable-diffusion](https://github.com/mlc-ai/web-stable-diffusion)
- [vladmandic/automatic | Heavily opinionated custom fork AUTOMATIC1111's repo, as close as up-to-date with origin as time allows](https://github.com/vladmandic/automatic)
- [anapnoe/stable-diffusion-webui-ux | Redesigned from automatic1111's UI, adding mobile and desktop layouts and UX improvements](https://github.com/anapnoe/stable-diffusion-webui-ux)

## Fine Tuning
- https://github.com/JoePenna/Dreambooth-Stable-Diffusion
- https://github.com/TheLastBen/fast-stable-diffusion
- https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth
- https://github.com/cloneofsimo/lora
- [Kohya_ss | Windows-focused Gradio GUI for Kohya's Stable Diffusion trainers](https://github.com/bmaltais/kohya_ss)
- [StableTuner | Windows GUI for Finetuning / Dreambooth Stable Diffusion models](https://github.com/devilismyfriend/StableTuner)

# Video
## Text to video generation
- [ModelScope Text to video synthesis](https://huggingface.co/spaces/damo-vilab/modelscope-text-to-video-synthesis)
- [Nvidia VideoLDM: Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models](https://research.nvidia.com/labs/toronto-ai/VideoLDM/)

## Frame Interpolation (Temporal Interpolation)
- https://github.com/google-research/frame-interpolation
- https://github.com/ltkong218/ifrnet
- https://github.com/megvii-research/ECCV2022-RIFE
- 

## Super Resolution (Spacial Interpolation)
- https://github.com/researchmm/FTVSR
- https://github.com/picsart-ai-research/videoinr-continuous-space-time-super-resolution
- 

## Spacio Temporal Interpolation
- https://github.com/llmpass/RSTT

# Audio
## Compression
- https://github.com/facebookresearch/encodec

## Speech Recognition
- https://github.com/openai/whisper
- [ermine-ai | Whisper in the browser using transformers.js](https://github.com/vishnumenon/ermine-ai)
- [wav2vec2 dimensional emotion model](https://github.com/audeering/w2v2-how-to)

## Generative Audio
- [Bark](https://github.com/suno-ai/bark) transformer-based text-to-audio model created by Suno. Bark can generate highly realistic, multilingual speech as well as other audio - including music, background noise and simple sound effects
  - [Bark-Voice-Clones](https://github.com/nikaskeba/Bark-Voice-Clones
  - [Bark WebUI colab notebooks](https://github.com/camenduru/bark-colab)
  - [bark-with-voice-clone](https://github.com/serp-ai/bark-with-voice-clone)
  - [Bark Infinity for longer audio](https://github.com/JonathanFly/bark)
  - [Bark WebUI](https://github.com/makawy7/bark-webui))
- [Coqui TTS | deep learning toolkit for Text-to-Speech](https://github.com/coqui-ai/TTS)
  - [Tutorial](https://www.youtube.com/watch?v=dfmlyXHQOwE) for Coqui VITS and Whisper to automate voice cloning and [Colab notebook](https://colab.research.google.com/drive/1Swo0GH_PjjAMqYYV6He9uFaq5TQsJ7ZH?usp=sharing#scrollTo=nSrZbKCXxalg)
- [voicepaw/so-vits-svc-fork](https://github.com/voicepaw/so-vits-svc-fork) SoftVC VITS Singing Voice Conversion Fork with realtime support and greatly improved interface. Based on branch 4.0 (v1) and the models are compatible.
  - [Video tutorial by Nerdy Rodent](https://www.youtube.com/watch?v=tZn0lcGO5OQ)
  - [nateraw/so-vits-svc-fork gradio app](https://github.com/nateraw/voice-cloning) for inference of so-vits-svc-fork voice models + ([training in colab](https://colab.research.google.com/github/nateraw/voice-cloning/blob/main/training_so_vits_svc_fork.ipynb) and [hf space](https://hf.co/spaces/nateraw/voice-cloning))
  - [so-vits-svc-5.0](https://github.com/PlayVoice/so-vits-svc-5.0)
  - [LoRa svc](https://github.com/PlayVoice/lora-svc)
- [w-okada/voice-changer | real time voice conversion using various models like MMVC, so-vits-svc, RVC, DDSP-SVC](https://github.com/w-okada/voice-changer/blob/master/README_en.md)
- [VITS GUI to load VITS text to speech models](https://github.com/CjangCjengh/MoeGoe_GUI) 
- [StyleTTS implementation](https://github.com/yl4579/StyleTTS)
- [RVC-Project | Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/docs/README.en.md)
- [Vall-E and Vall-E X | SOTA Zero Shot TTS preserving emotion, expression, similarity and allows language transfer](https://valle-demo.github.io/)
  - [paper](https://arxiv.org/abs/2301.02111)
  - [code](https://github.com/enhuiz/vall-e)
- [FastDiff implementation| Fast Conditional Diffusion Model for High-Quality Speech Synthesis](https://github.com/Rongjiehuang/FastDiff)
- [NaturalSpeech implmenetation](https://github.com/heatz123/naturalspeech)
- [IMS Toucan, TTS Toolkit from University of Stuttgart](https://github.com/digitalphonetics/ims-toucan)
- [YourTTS | Zero Shot Multi Speaker TTS and Voice Conversion for everyone](https://github.com/Edresson/YourTTS)
- [PaddleSpeech | Easy to use Speech Toolkit with Self Supervised learning, SOTA Streaming with punctuation, TTS, Translation etc](https://github.com/PaddlePaddle/PaddleSpeech)
- [Nvidia NeMo | TTS, LLM, Audio Synthesis framework](https://github.com/NVIDIA/NeMo)
- [Tortoise TTS | Open source multi voice TTS system](https://github.com/neonbjb/tortoise-tts)
  - [finetune guide using DLAS DL-Art-School](https://www.youtube.com/watch?v=lnIq4SFFXWs)
  - [DL-Art-School](https://github.com/152334H/DL-Art-School) fine tuning tortoise with DLAS GUI
  - [tortoise-tts-fast](https://github.com/152334H/tortoise-tts-fast) fast Tortoise TTS inference up to 5x. [Video tutorial](https://www.youtube.com/watch?v=8i4T5v1Fl_M)
 


# AI DevOps
- https://www.steamship.com/

# Optimization
## Inference
- https://github.com/bigscience-workshop/petals
- https://github.com/chavinlo/distributed-diffusion
- https://github.com/VoltaML/voltaML-fast-stable-diffusion
- https://github.com/FMInference/FlexGen
- https://github.com/alpa-projects/alpa
- https://github.com/kir-gadjello/zipslicer
- https://github.com/modular-ml/wrapyfi-examples_llama
- https://github.com/tloen/llama-int8
- [4 bits quantization of LLaMa using GPTQ](https://github.com/qwopqwop200/GPTQ-for-LLaMa) ([discussion](https://github.com/oobabooga/text-generation-webui/issues/177))
- https://petals.ml/
- https://github.com/facebookincubator/AITemplate

## Training
- https://github.com/learning-at-home/hivemind

## Other Optimization
- https://github.com/HazyResearch/flash-attention
- https://github.com/stochasticai/x-stable-diffusion
- 

# Benchmarking
- https://videoprocessing.ai/benchmarks/
- https://paperswithcode.com/
- [Pythia | interpretability analysis for autoregressive transformers during training](https://github.com/EleutherAI/pythia)
