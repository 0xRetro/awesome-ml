## Open LLM Models List

Curated list of llama, alpaca, vicuna and similar open models and a few other architectures.

Available as a [üìÑ Google Sheet](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit?usp=sharing)

Want to know which one is "the best"? Have a look at the [üèÜ Leaderboards](llm-tools.md#benchmarking) in the Benchmarking section.

[üëá Scroll to the bottom](#other-sota-open-source-models) for other SOTA (State Of The Art) models

| Author | Model |  Foundation |  Size |  Quantization |  Fine Tuning Dataset |  Objective | Prompt Format |  LoRa |  Model Date |
|---|---|---|---|---|---|---|---|---|---|
| baichuan-inc | [baichuan-7B](https://huggingface.co/baichuan-inc/baichuan-7B) | baichuan | 7b | none | unknown | text completion | [none](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| openaccess-ai-collective | [minotaur-15b](https://huggingface.co/openaccess-ai-collective/minotaur-15b) | starcoder | 15b | none | WizardLM, subset of Alpaca-CoT for roleplay and CoT, GPTeacher-General-Instruct, ScienceQA, Summarize from feedback, camel-ai/math, camel-ai/physics, camel-ai/chemistry, camel-ai/biology, winglian/evals and [more](https://huggingface.co/openaccess-ai-collective/minotaur-13b) | instruct | [minotaur](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| TheBloke | [minotaur-15B-GGML](https://huggingface.co/TheBloke/minotaur-15B-GGML) | llama | 15b | q4_0, q4_1, q5_0, q5_1, q8_0 | WizardLM, subset of Alpaca-CoT for roleplay and CoT, GPTeacher-General-Instruct, ScienceQA, Summarize from feedback, camel-ai/math, camel-ai/physics, camel-ai/chemistry, camel-ai/biology, winglian/evals and [more](https://huggingface.co/openaccess-ai-collective/minotaur-13b) | instruct | [minotaur](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| TheBloke | [minotaur-15B-GPTQ](https://huggingface.co/TheBloke/minotaur-15B-GPTQ) | llama | 15b | 4bit GPTQ | WizardLM, subset of Alpaca-CoT for roleplay and CoT, GPTeacher-General-Instruct, ScienceQA, Summarize from feedback, camel-ai/math, camel-ai/physics, camel-ai/chemistry, camel-ai/biology, winglian/evals and [more](https://huggingface.co/openaccess-ai-collective/minotaur-13b) | instruct | [minotaur](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| lmsys | [vicuna-13b-v1.3](https://huggingface.co/lmsys/vicuna-13b-v1.3) | vicuna | 13b | none | 140k shareGPT.com conversations | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| TheBloke | [vicuna-13b-v1.3-GPTQ](https://huggingface.co/TheBloke/vicuna-13b-v1.3-GPTQ) | llama | 13b | 4bit GPTQ | 140k shareGPT.com conversations | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| lmsys | [vicuna-7b-v1.3](https://huggingface.co/lmsys/vicuna-7b-v1.3) | vicuna | 7b | none | 140k shareGPT.com conversations | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| TheBloke | [vicuna-7B-v1.3-GPTQ](https://huggingface.co/TheBloke/vicuna-7B-v1.3-GPTQ) | llama | 7b | 4bit GPTQ | 140k shareGPT.com conversations | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| ehartford | [WizardLM-7B-V1.0-Uncensored](https://huggingface.co/ehartford/WizardLM-7B-V1.0-Uncensored) | llama | 7b | none | [WizardLM_evol_instruct_V2_196k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split) | instruct | [WizardLM-V1.0-Uncensored](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| TheBloke | [WizardLM-7B-V1.0-Uncensored-GGML](https://huggingface.co/TheBloke/WizardLM-7B-V1.0-Uncensored-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | [WizardLM_evol_instruct_V2_196k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split) | instruct | [WizardLM-V1.0-Uncensored](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| TheBloke | [WizardLM-7B-V1.0-Uncensored-GPTQ](https://huggingface.co/TheBloke/WizardLM-7B-V1.0-Uncensored-GPTQ) | llama | 7b | 4bit GPTQ | [WizardLM_evol_instruct_V2_196k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_evol_instruct_V2_196k_unfiltered_merged_split) | instruct | [WizardLM-V1.0-Uncensored](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-18 |
| GeorgiaTechResearchInstitute | [galactica-30b-evol-instruct-70k](https://huggingface.co/GeorgiaTechResearchInstitute/galactica-30b-evol-instruct-70k) | galactica | 30b | none | [WizardLM_evol_instruct_70k](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_70k) | instruct | [galactica-evol-instruct](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-13B-v2-fp16](https://huggingface.co/TheBloke/robin-13B-v2-fp16) | llama | 13b | none | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-13B-v2-GGML](https://huggingface.co/TheBloke/robin-13B-v2-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-13B-v2-GPTQ](https://huggingface.co/TheBloke/robin-13B-v2-GPTQ) | llama | 13b | 4bit GPTQ | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-33B-v2-fp16](https://huggingface.co/TheBloke/robin-33B-v2-fp16) | llama | 33b | none | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-33B-v2-GGML](https://huggingface.co/TheBloke/robin-33B-v2-GGML) | llama | 33b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-33B-v2-GPTQ](https://huggingface.co/TheBloke/robin-33B-v2-GPTQ) | llama | 33b | 4bit GPTQ | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-65b-v2-fp16](https://huggingface.co/TheBloke/robin-65b-v2-fp16) | llama | 65b | none | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-65B-v2-GGML](https://huggingface.co/TheBloke/robin-65B-v2-GGML) | llama | 65b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K |  | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-65B-v2-GPTQ](https://huggingface.co/TheBloke/robin-65B-v2-GPTQ) | llama | 65b | 4bit GPTQ | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-7B-v2-fp16](https://huggingface.co/TheBloke/robin-7B-v2-fp16) | llama | 7b | none | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-7B-v2-GGML](https://huggingface.co/TheBloke/robin-7B-v2-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| TheBloke | [robin-7B-v2-GPTQ](https://huggingface.co/TheBloke/robin-7B-v2-GPTQ) | llama | 7b | 4bit GPTQ | unknown | chat + instruct | [robin](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-16 |
| openlm-research | [open_llama_13b](https://huggingface.co/openlm-research/open_llama_13b) | open-llama | 13b | none | [RedPajama](https://github.com/togethercomputer/RedPajama-Data) | text completion | [none](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-15 |
| TheBloke | [airoboros-13B-gpt4-1.2-GGML](https://huggingface.co/TheBloke/airoboros-13B-gpt4-1.2-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [airoboros-13B-gpt4-1.2-GPTQ](https://huggingface.co/TheBloke/airoboros-13B-gpt4-1.2-GPTQ) | llama | 13b | 4bit GPTQ | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [airoboros-33B-gpt4-1.2-GGML](https://huggingface.co/TheBloke/airoboros-33B-gpt4-1.2-GGML) | llama | 33b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [airoboros-33B-gpt4-1.2-GPTQ](https://huggingface.co/TheBloke/airoboros-33B-gpt4-1.2-GPTQ) | llama | 33b | 4bit GPTQ | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [airoboros-65B-gpt4-1.2-GGML](https://huggingface.co/TheBloke/airoboros-65B-gpt4-1.2-GGML) | llama | 65b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [airoboros-65B-gpt4-1.2-GPTQ](https://huggingface.co/TheBloke/airoboros-65B-gpt4-1.2-GPTQ) | llama | 65b | 4bit GPTQ | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [airoboros-7B-gpt4-1.2-GGML](https://huggingface.co/TheBloke/airoboros-7B-gpt4-1.2-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [airoboros-7B-gpt4-1.2-GPTQ](https://huggingface.co/TheBloke/airoboros-7B-gpt4-1.2-GPTQ) | llama | 7b | 4bit GPTQ | [airoboros-gpt4-1.2](https://huggingface.co/datasets/jondurbin/airoboros-gpt4-1.2) | instruct | [airoboros](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [WizardCoder-15B-1.0-GGML](https://huggingface.co/TheBloke/WizardCoder-15B-1.0-GGML) | starcoder | 15b | q4_0, q4_1, q5_0, q5_1, q8_0 | 78k evolved code instructions | instruct | [Wizard-Mega WizardLM](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| TheBloke | [WizardCoder-15B-1.0-GPTQ](https://huggingface.co/TheBloke/WizardCoder-15B-1.0-GPTQ) | starcoder | 15b | 4bit GPTQ | 78k evolved code instructions | instruct | [Wizard-Mega WizardLM](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| WizardLM | [WizardCoder-15B-V1.0](https://huggingface.co/WizardLM/WizardCoder-15B-V1.0) | starcoder | 15b | none | 78k evolved code instructions | instruct | [Wizard-Mega WizardLM](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-14 |
| alpindale | [landmark-33b](https://huggingface.co/alpindale/landmark-33b) | llama | 33b | none | [Landmark RedPajama-Data-1T-Sampe](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T-Sample) | text completion | [none](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) | yes | 2023-06-13 |
| Honkware | [Manticore-13b-Landmark](https://huggingface.co/Honkware/Manticore-13b-Landmark) | llama | 13b | none | Landmark QLoRA + Manticore-13b [ShareGPT](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered), [WizardLM](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered), [Wizard-Vicuna](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered), [Alpaca-CoT subset](https://huggingface.co/QingyiSi/Alpaca-CoT), [GPT4-LLM-Cleaned](https://huggingface.co/datasets/teknium/GPT4-LLM-Cleaned), [GPTeacher-General-Instruct](https://huggingface.co/datasets/teknium/GPTeacher-General-Instruct), ARC-Easy & ARC-Challenge, mmlu subset, [hellaswag subset](https://huggingface.co/datasets/hellaswag), [ScienceQA_text_only](https://huggingface.co/datasets/metaeval/ScienceQA_text_only), [summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback) | chat + instruct | [manticore-chat + manticore-instruct](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-13 |
| 64bits | [LexPodLM-13B](https://huggingface.co/64bits/LexPodLM-13B) | llama | 13b | none | [Lex_friedman_podcast_for_llm_vicuna](https://huggingface.co/datasets/64bits/lex_fridman_podcast_for_llm_vicuna) | chat | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-10 |
| eugenepentland | [Minotaur-13b-Landmark-QLoRA](https://huggingface.co/eugenepentland/Minotaur-13b-Landmark-QLoRA) | llama | 13b | none | WizardLM, subset of Alpaca-CoT for roleplay and CoT, GPTeacher-General-Instruct, ScienceQA, Summarize from feedback, camel-ai/math, camel-ai/physics, camel-ai/chemistry, camel-ai/biology, winglian/evals and [more](https://huggingface.co/openaccess-ai-collective/minotaur-13b) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) | yes | 2023-06-10 |
| TheBloke | [tulu-13B-GGML](https://huggingface.co/TheBloke/tulu-13B-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | oasst1, dolly-15k, CodeAlpaca-20k | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-10 |
| TheBloke | [tulu-13B-GPTQ](https://huggingface.co/TheBloke/tulu-13B-GPTQ) | llama | 13b | 4bit GPTQ | oasst1, dolly-15k, CodeAlpaca-20k | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-10 |
| TheBloke | [tulu-30B-GGML](https://huggingface.co/TheBloke/tulu-30B-GGML) | llama | 30b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | oasst1, dolly-15k, CodeAlpaca-20k | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-10 |
| TheBloke | [tulu-30B-GPTQ](https://huggingface.co/TheBloke/tulu-30B-GPTQ) | llama | 30b | 4bit GPTQ | oasst1, dolly-15k, CodeAlpaca-20k | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-10 |
| TheBloke | [tulu-7B-GGML](https://huggingface.co/TheBloke/tulu-7B-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | oasst1, dolly-15k, CodeAlpaca-20k | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-10 |
| TheBloke | [tulu-7B-GPTQ](https://huggingface.co/TheBloke/tulu-7B-GPTQ) | llama | 7b | 4bit GPTQ | oasst1, dolly-15k, CodeAlpaca-20k | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-10 |
| h2oai | [h2ogpt-gm-oasst1-en-2048-open-llama-7b](https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-open-llama-7b) | open-llama | 7b | none | open_llama_7b_700bt_preview + oasst1 | instruct | [open assistant](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-09 |
| TheBloke | [open-llama-7b-open-instruct-GGML](https://huggingface.co/TheBloke/open-llama-7b-open-instruct-GGML) | open-llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | [Open-Instruct-v1](https://huggingface.co/datasets/VMware/open-instruct-v1-oasst-dolly-hhrlhf) | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-09 |
| TheBloke | [open-llama-7b-open-instruct-GPTQ](https://huggingface.co/TheBloke/open-llama-7b-open-instruct-GPTQ) | open-llama | 7b | 4bit GPTQ | [Open-Instruct-v1](https://huggingface.co/datasets/VMware/open-instruct-v1-oasst-dolly-hhrlhf) | instruct | [alpaca](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-09 |
| openaccess-ai-collective | [minotaur-13b](https://huggingface.co/openaccess-ai-collective/minotaur-13b) | llama | 13b | none | WizardLM, subset of Alpaca-CoT for roleplay and CoT, GPTeacher-General-Instruct, ScienceQA, Summarize from feedback, camel-ai/math, camel-ai/physics, camel-ai/chemistry, camel-ai/biology, winglian/evals and [more](https://huggingface.co/openaccess-ai-collective/minotaur-13b) | instruct | [minotaur](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-08 |
| VMware | [open-llama-7b-open-instruct](https://huggingface.co/VMware/open-llama-7b-open-instruct) | open-llama | 7b | none | [Open-Instruct-v1](https://huggingface.co/datasets/VMware/open-instruct-v1-oasst-dolly-hhrlhf) | instruct |  |  | 2023-06-08 |
| TheBloke | [starchat-beta-GGML](https://huggingface.co/TheBloke/starchat-beta-GGML) | starcoder | 16b | q4_0, q4_1, q5_0, q5_1, q8_0 | [dolly](https://huggingface.co/datasets/databricks/databricks-dolly-15k), [oasst](https://huggingface.co/datasets/OpenAssistant/oasst1) | instruct | [starchat](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-08 |
| TheBloke | [starchat-beta-GPTQ](https://huggingface.co/TheBloke/starchat-beta-GPTQ) | starcoder | 16b | 4bit GPTQ | [dolly](https://huggingface.co/datasets/databricks/databricks-dolly-15k), [oasst](https://huggingface.co/datasets/OpenAssistant/oasst1) | instruct | [starchat](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-08 |
| TheBloke | [starcoderplus-GGML](https://huggingface.co/TheBloke/starcoderplus-GGML) | starcoder | 15.5b | q4_0, q4_1, q5_0, q5_1, q8_0 | StarCoderBase + [RedefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), [StarCoderData](https://huggingface.co/datasets/bigcode/starcoderdata) (The Stack (v1.2)), a Wikipedia dataset | fill in the middle |  |  | 2023-06-08 |
| TheBloke | [starcoderplus-GPTQ](https://huggingface.co/TheBloke/starcoderplus-GPTQ) | starcoder | 15.5b | 4bit gptq | StarCoderBase + [RedefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), [StarCoderData](https://huggingface.co/datasets/bigcode/starcoderdata) (The Stack (v1.2)), a Wikipedia dataset | fill in the middle |  |  | 2023-06-08 |
| openlm-research | [open_llama_13b_600bt](https://huggingface.co/openlm-research/open_llama_13b_600bt) | llama | 13b | none | [RedPajama](https://github.com/togethercomputer/RedPajama-Data) |  |  |  | 2023-06-07 |
| BlinkDL | [rwkv-4-world](https://huggingface.co/BlinkDL/rwkv-4-world) | rwkv | 1.5b/3b/7b | none | rwkv + 100+ world languages (70% English, 15% multilang, 15% code) |  |  |  | 2023-06-07 |
| HuggingFaceH4 | [starchat-beta](https://huggingface.co/HuggingFaceH4/starchat-beta) | starcoder | 16b | none | [dolly](https://huggingface.co/datasets/databricks/databricks-dolly-15k), [oasst](https://huggingface.co/datasets/OpenAssistant/oasst1) | instruct | [starchat](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-07 |
| localmodels | [WizardLM-30B-1.0-gptq](https://huggingface.co/localmodels/WizardLM-30B-1.0-gptq) | llama | 30b | 4bit GPTQ | 250k evolved instructions (ShareGPT) |  |  |  | 2023-06-07 |
| h2oai | [h2ogpt-gm-oasst1-en-2048-falcon-40b-v1](https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v1) | falcon | 40b | none | falcon-40b + oasst1 |  |  |  | 2023-06-06 |
| TheBloke | [Nous-Hermes-13B-GGML](https://huggingface.co/TheBloke/Nous-Hermes-13B-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | GPTeacher, the general, roleplay v1&2, code instruct datasets, Nous Instruct & PDACTL, CodeAlpaca, Evol_Instruct Uncensored, GPT4-LLM, Unnatural Instructions |  |  |  | 2023-06-06 |
| togethercomputer | [RedPajama-INCITE-7B-Base](https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Base) | redpajama | 7b | none | [base](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T) |  |  |  | 2023-06-06 |
| TheBloke | [WizardLM-30B-fp16](https://huggingface.co/TheBloke/WizardLM-30B-fp16) | llama | 30b | none | 250k evolved instructions (ShareGPT) |  |  |  | 2023-06-06 |
| TheBloke | [WizardLM-30B-GGML](https://huggingface.co/TheBloke/WizardLM-30B-GGML) | llama | 30b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | 250k evolved instructions (ShareGPT) |  |  |  | 2023-06-06 |
| TheBloke | [WizardLM-30B-GPTQ](https://huggingface.co/TheBloke/WizardLM-30B-GPTQ) | llama | 30b | safetensors | 250k evolved instructions (ShareGPT) |  |  |  | 2023-06-06 |
| TheBloke | [landmark-attention-llama7b-fp16](https://huggingface.co/TheBloke/landmark-attention-llama7b-fp16) | llama | 7b | none | [RedPajama](https://github.com/togethercomputer/RedPajama-Data) trained with [landmark attention](https://github.com/epfml/landmark-attention) 32k context size |  |  |  | 2023-06-05 |
| TheBloke | [llama-deus-7b-v3-GGML](https://huggingface.co/TheBloke/llama-deus-7b-v3-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0 | GPTeacher, Roleplay V2 Instruct, GPT4-LLM Uncensored + Unnatural Instructions, WizardLM Uncensored, CamelAI's 20k Bio Physics Chemistry Math, CodeAlpaca |  |  |  | 2023-06-05 |
| TheBloke | [llama-deus-7b-v3-GPTQ](https://huggingface.co/TheBloke/llama-deus-7b-v3-GPTQ) | llama | 7b | 4bit GPTQ | GPTeacher, Roleplay V2 Instruct, GPT4-LLM Uncensored + Unnatural Instructions, WizardLM Uncensored, CamelAI's 20k Bio Physics Chemistry Math, CodeAlpaca |  |  |  | 2023-06-05 |
| togethercomputer | [RedPajama-INCITE-7B-Chat](https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Chat) | redpajama | 7b | none | [base](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T) + [oasst2](https://huggingface.co/datasets/OpenAssistant/oasst1),  [Dolly2](https://huggingface.co/datasets/databricks/databricks-dolly-15k) |  |  |  | 2023-06-05 |
| togethercomputer | [RedPajama-INCITE-7B-Instruct](https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct) | redpajama | 7b | none | [base](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T) + [RedPajama-Data-Instruct](https://huggingface.co/togethercomputer/RedPajama-INCITE-7B-Instruct) |  |  |  | 2023-06-05 |
| jondurbin | [airoboros-13b-gpt4](https://huggingface.co/jondurbin/airoboros-13b-gpt4) | llama | 13b | none | airoboros-13b + [airoboros-gpt4](https://huggingface.co/datasets/jondurbin/airoboros-gpt4) for trivia, reasoning, coding, multipe-choice, context-obedient info retrieval and Q&A | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-04 |
| TheBloke | [airoboros-13b-gpt4-GGML](https://huggingface.co/TheBloke/airoboros-13b-gpt4-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0 | airoboros-13b + [airoboros-gpt4](https://huggingface.co/datasets/jondurbin/airoboros-gpt4) for trivia, reasoning, coding, multipe-choice, context-obedient info retrieval and Q&A | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-04 |
| TheBloke | [airoboros-13b-gpt4-GPTQ](https://huggingface.co/TheBloke/airoboros-13b-gpt4-GPTQ) | llama | 13b | 4bit GPTQ | airoboros-13b + [airoboros-gpt4](https://huggingface.co/datasets/jondurbin/airoboros-gpt4) for trivia, reasoning, coding, multipe-choice, context-obedient info retrieval and Q&A | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-06-04 |
| TheBloke | [based-13b-GGML](https://huggingface.co/TheBloke/based-13b-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0 | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-04 |
| TheBloke | [based-13b-GPTQ](https://huggingface.co/TheBloke/based-13b-GPTQ) | llama | 13b | 4bit GPTQ | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-04 |
| TheBloke | [based-30B-GGML](https://huggingface.co/TheBloke/based-30B-GGML) | llama | 30b | q4_0, q4_1, q5_0, q5_1, q8_0 | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-04 |
| TheBloke | [based-30B-GPTQ](https://huggingface.co/TheBloke/based-30B-GPTQ) | llama | 30b | 4bit GPTQ | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-04 |
| TheBloke | [based-7B-GGML](https://huggingface.co/TheBloke/based-7B-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0 | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-04 |
| TheBloke | [based-7B-GPTQ](https://huggingface.co/TheBloke/based-7B-GPTQ) | llama | 7b | 4bit GPTQ | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-04 |
| bavest | [fin-llama-33b-merged](https://huggingface.co/bavest/fin-llama-33b-merged) | llama | 33b | none | [fin-llama](https://huggingface.co/datasets/bavest/fin-llama-dataset) finance dataset |  |  |  | 2023-06-04 |
| ehartford | [based-13b](https://huggingface.co/ehartford/based-13b) | llama | 13b | none | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-03 |
| ehartford | [based-30b](https://huggingface.co/ehartford/based-30b) | llama | 30b | none | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-03 |
| ehartford | [based-7b](https://huggingface.co/ehartford/based-7b) | llama | 7b | none | [based](https://huggingface.co/datasets/ehartford/based) |  |  |  | 2023-06-03 |
| nmitchko | [medguanaco-lora-33b-8bit](https://huggingface.co/nmitchko/medguanaco-lora-33b-8bit) | llama | 33b | none | [medalpaca](https://huggingface.co/medalpaca/medalpaca-lora-13b-8bit) |  |  | yes | 2023-06-03 |
| nmitchko | [medguanaco-lora-65b-GPTQ](https://huggingface.co/nmitchko/medguanaco-lora-65b-GPTQ) | llama | 65b | 4bit GPTQ | [medalpaca](https://huggingface.co/medalpaca/medalpaca-lora-13b-8bit) |  |  | yes | 2023-06-03 |
| TheBloke | [Nous-Hermes-13B-GPTQ](https://huggingface.co/TheBloke/Nous-Hermes-13B-GPTQ) | llama | 13b | 4bit GPTQ | GPTeacher, the general, roleplay v1&2, code instruct datasets, Nous Instruct & PDACTL, CodeAlpaca, Evol_Instruct Uncensored, GPT4-LLM, Unnatural Instructions |  |  |  | 2023-06-03 |
| ehartford | [WizardLM-Uncensored-Falcon-40b](https://huggingface.co/ehartford/WizardLM-Uncensored-Falcon-40b) | falcon | 40b | none | WizardLM Uncensored |  |  |  | 2023-06-03 |
| TheBloke | [WizardLM-Uncensored-Falcon-40B-GPTQ](https://huggingface.co/TheBloke/WizardLM-Uncensored-Falcon-40B-GPTQ) | falcon | 40b | 4bit GPTQ | WizardLM Uncensored |  |  |  | 2023-06-03 |
| mindrage | [Manticore-13B-Chat-Pyg-Guanaco-GGML-q4_0](https://huggingface.co/mindrage/Manticore-13B-Chat-Pyg-Guanaco-GGML-q4_0) | llama | 13b | q4_0 | manticore base + Guanaco qLoRa |  |  |  | 2023-06-02 |
| h2oai | [h2ogpt-gm-oasst1-en-2048-falcon-7b-v2](https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2) | falcon | 7b | none | falcon-7b + oasst1 |  |  |  | 2023-06-01 |
| ehartford | [WizardLM-Uncensored-Falcon-7b](https://huggingface.co/ehartford/WizardLM-Uncensored-Falcon-7b) | falcon | 7b | none | WizardLM Uncensored |  |  |  | 2023-06-01 |
| TheBloke | [WizardLM-Uncensored-Falcon-7B-GPTQ](https://huggingface.co/TheBloke/WizardLM-Uncensored-Falcon-7B-GPTQ) | falcon | 7b | 4bit GPTQ | WizardLM Uncensored |  |  |  | 2023-06-01 |
| TheBloke | [WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGML](https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGML) | llama | 30b | q4_0, q4_1, q5_0, q5_1, q8_0 | WizardLM Uncensored, CoT, Storytelling |  |  |  | 2023-06-01 |
| TheBloke | [WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ](https://huggingface.co/TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GPTQ) | llama | 30b | 4bit GPTQ | WizardLM Uncensored, CoT, Storytelling |  |  |  | 2023-06-01 |
| TheBloke | [hippogriff-30b-chat-GGML](https://huggingface.co/TheBloke/hippogriff-30b-chat-GGML) | llama | 30b | q4_0, q4_1, q5_0, q5_1, q8_0 | oasst1, synthetic jokes, synthetic prose, Q&A, logic_inference_oa, de-duped pygmalion, riddle_sense, hellaswag, gsm8k, code-alpaca-instruct-unfiltered, alpaca-CoT for roleplay, GPTeacher-General-Instruct, ARC-Easy, ARC-Challenge, scienceQA_text_only, summarize_from_feedback | chat |  |  | 2023-05-31 |
| TheBloke | [hippogriff-30b-chat-GPTQ](https://huggingface.co/TheBloke/hippogriff-30b-chat-GPTQ) | llama | 30b | 4bit GPTQ | oasst1, synthetic jokes, synthetic prose, Q&A, logic_inference_oa, de-duped pygmalion, riddle_sense, hellaswag, gsm8k, code-alpaca-instruct-unfiltered, alpaca-CoT for roleplay, GPTeacher-General-Instruct, ARC-Easy, ARC-Challenge, scienceQA_text_only, summarize_from_feedback | chat |  |  | 2023-05-31 |
| VMware | [open-llama-0.7T-7B-open-instruct-v1.1](https://huggingface.co/VMware/open-llama-0.7T-7B-open-instruct-v1.1) | open-llama | 7b | none | open_llama_7b_700bt_preview + [open-instruct-v1.1-oasst-dolly-hhrlhf](https://huggingface.co/datasets/VMware/open-instruct-v1.1-oasst-dolly-hhrlhf) | instruct |  |  | 2023-05-31 |
| dfurman | [falcon-40b-chat-oasst1](https://huggingface.co/dfurman/falcon-40b-chat-oasst1) | falcon | 40b | none | falcon-40b + oasst1 | chat |  | yes | 2023-05-30 |
| mindrage | [Manticore-13B-Chat-Pyg-Guanaco-GPTQ-4bit-128g.no-act-order.safetensors](https://huggingface.co/mindrage/Manticore-13B-Chat-Pyg-Guanaco-GPTQ-4bit-128g.no-act-order.safetensors) | llama | 13b | 4bit GPTQ | manticore base + Guanaco qLoRa |  |  |  | 2023-05-30 |
| ehartford | [samantha-falcon-7b](https://huggingface.co/ehartford/samantha-falcon-7b) | falcon | 7b | none | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-30 |
| TheBloke | [samantha-falcon-7B-GPTQ](https://huggingface.co/TheBloke/samantha-falcon-7B-GPTQ) | falcon | 7b | 4bit GPTQ | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-30 |
| ehartford | [Wizard-Vicuna-30B-Uncensored](https://huggingface.co/ehartford/Wizard-Vicuna-30B-Uncensored) | vicuna | 30b | none | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-30 |
| TheBloke | [Wizard-Vicuna-30B-Uncensored-GGML](https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GGML) | vicuna | 30b | q4_0, q4_1, q5_0, q5_1, q8_0 | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-30 |
| TheBloke | [Wizard-Vicuna-30B-Uncensored-GPTQ](https://huggingface.co/TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ) | vicuna | 30b | 4bit GPTQ | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-30 |
| ehartford | [samantha-33b](https://huggingface.co/ehartford/samantha-33b) | llama | 33b | none | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-29 |
| TheBloke | [samantha-33B-GGML](https://huggingface.co/TheBloke/samantha-33B-GGML) | llama | 33b | q4_0, q4_1, q5_0, q5_1, q8_0 | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-29 |
| TheBloke | [samantha-33B-GPTQ](https://huggingface.co/TheBloke/samantha-33B-GPTQ) | llama | 33b | 4bit GPTQ | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-29 |
| TheBloke | [VicUnlocked-alpaca-65B-QLoRA-GGML](https://huggingface.co/TheBloke/VicUnlocked-alpaca-65B-QLoRA-GGML) | alpaca | 65b | q4_0, q4_1, q5_0, q5_1, q8_0 | [shareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/Aeala/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-05-29 |
| TheBloke | [gorilla-7B-fp16](https://huggingface.co/TheBloke/gorilla-7B-fp16) | llama | 7b | none | 1640+ [API documentations](https://github.com/ShishirPatil/gorilla/tree/main/data/api) |  |  |  | 2023-05-28 |
| TheBloke | [gorilla-7B-GGML](https://huggingface.co/TheBloke/gorilla-7B-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0 | 1640+ [API documentations](https://github.com/ShishirPatil/gorilla/tree/main/data/api) |  |  |  | 2023-05-28 |
| TheBloke | [gorilla-7B-GPTQ](https://huggingface.co/TheBloke/gorilla-7B-GPTQ) | llama | 7b | 4bit GPTQ | 1640+ [API documentations](https://github.com/ShishirPatil/gorilla/tree/main/data/api) |  |  |  | 2023-05-28 |
| ehartford | [samantha-13b](https://huggingface.co/ehartford/samantha-13b) | llama | 13b | none | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-28 |
| TheBloke | [samantha-13B-GGML](https://huggingface.co/TheBloke/samantha-13B-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0 | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-28 |
| TheBloke | [samantha-13B-GPTQ](https://huggingface.co/TheBloke/samantha-13B-GPTQ) | llama | 13b | 4bit GPTQ | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-28 |
| ehartford | [samantha-7b](https://huggingface.co/ehartford/samantha-7b) | llama | 7b | none | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-28 |
| TheBloke | [Samantha-7B-GGML](https://huggingface.co/TheBloke/Samantha-7B-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0 | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-28 |
| TheBloke | [Samantha-7B-GPTQ](https://huggingface.co/TheBloke/Samantha-7B-GPTQ) | llama | 7b | 4bit GPTQ | 6,000 curated conversations in ShareGPT/Vicuna format |  |  |  | 2023-05-28 |
| Aeala | [VicUnlocked-alpaca-65b-4bit](https://huggingface.co/Aeala/VicUnlocked-alpaca-65b-4bit) | alpaca | 65b | 4bit GPTQ | [shareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/Aeala/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-05-28 |
| TheBloke | [falcon-40b-instruct-GPTQ](https://huggingface.co/TheBloke/falcon-40b-instruct-GPTQ) | falcon | 40b | 4bit GPTQ | base trained on [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), finetuned on a mixture of [Baize](https://github.com/project-baize/baize-chatbot) | instruct |  |  | 2023-05-27 |
| TheBloke | [falcon-7b-instruct-GPTQ](https://huggingface.co/TheBloke/falcon-7b-instruct-GPTQ) | falcon | 7b | 4bit GPTQ | base trained on [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), finetuned on a mixture of [Baize](https://github.com/project-baize/baize-chatbot) | instruct |  |  | 2023-05-27 |
| Aeala | [VicUnlocked-alpaca-65b-QLoRA](https://huggingface.co/Aeala/VicUnlocked-alpaca-65b-QLoRA) | alpaca | 65b | none | [shareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/Aeala/ShareGPT_Vicuna_unfiltered) |  |  | yes | 2023-05-27 |
| TheBloke | [wizardLM-13B-1.0-fp16](https://huggingface.co/TheBloke/wizardLM-13B-1.0-fp16) | llama | 13b | none | 250k evolved instructions (ShareGPT) |  |  |  | 2023-05-27 |
| TheBloke | [wizardLM-13B-1.0-GGML](https://huggingface.co/TheBloke/wizardLM-13B-1.0-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0 | 250k evolved instructions (ShareGPT) |  |  |  | 2023-05-27 |
| TheBloke | [wizardLM-13B-1.0-GPTQ](https://huggingface.co/TheBloke/wizardLM-13B-1.0-GPTQ) | llama | 13b | 4bit GPTQ | 250k evolved instructions (ShareGPT) |  |  |  | 2023-05-27 |
| tiiuae | [falcon-40b](https://huggingface.co/tiiuae/falcon-40b) | falcon | 40b | none | base trained on [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb) |  |  |  | 2023-05-25 |
| tiiuae | [falcon-40b-instruct](https://huggingface.co/tiiuae/falcon-40b-instruct) | falcon | 40b | none | base trained on [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), finetuned on a mixture of [Baize](https://github.com/project-baize/baize-chatbot) | instruct |  |  | 2023-05-25 |
| tiiuae | [falcon-7b](https://huggingface.co/tiiuae/falcon-7b) | falcon | 7b | none | base trained on [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb) |  |  |  | 2023-05-25 |
| tiiuae | [falcon-7b-instruct](https://huggingface.co/tiiuae/falcon-7b-instruct) | falcon | 7b | none | base trained on [RefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), finetuned on a mixture of [Baize](https://github.com/project-baize/baize-chatbot) | instruct |  |  | 2023-05-25 |
| TheBloke | [guanaco-13B-GGML](https://huggingface.co/TheBloke/guanaco-13B-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0 | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| TheBloke | [guanaco-13B-GPTQ](https://huggingface.co/TheBloke/guanaco-13B-GPTQ) | llama | 13b | 4bit GPTQ | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| TheBloke | [guanaco-33B-GGML](https://huggingface.co/TheBloke/guanaco-33B-GGML) | llama | 33b | q4_0, q4_1, q5_0, q5_1, q8_0 | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| TheBloke | [guanaco-33B-GPTQ](https://huggingface.co/TheBloke/guanaco-33B-GPTQ) | llama | 33b | 4bit GPTQ | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| TheBloke | [guanaco-65B-GGML](https://huggingface.co/TheBloke/guanaco-65B-GGML) | llama | 65b | q4_0, q4_1, q5_0, q5_1, q8_0 | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| TheBloke | [guanaco-65B-GPTQ](https://huggingface.co/TheBloke/guanaco-65B-GPTQ) | llama | 65b | 4bit GPTQ | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| TheBloke | [guanaco-7B-GGML](https://huggingface.co/TheBloke/guanaco-7B-GGML) | llama | 7b | q4_0, q4_1, q5_0, q5_1, q8_0 | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| TheBloke | [guanaco-7B-GPTQ](https://huggingface.co/TheBloke/guanaco-7B-GPTQ) | llama | 7b | 4bit GPTQ | [Guanaco dataset](https://huggingface.co/datasets/JosephusCheung/GuanacoDataset) |  |  |  | 2023-05-25 |
| jondurbin | [airoboros-13b](https://huggingface.co/jondurbin/airoboros-13b) | llama | 13b | none | [synthetic airoboros-uncensored](https://huggingface.co/datasets/jondurbin/airoboros-uncensored) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-22 |
| cmh | [airoboros-13b-4bit-128g-triton](https://huggingface.co/cmh/airoboros-13b-4bit-128g-triton) | llama | 13b | safetensors triton | [synthetic airoboros-uncensored](https://huggingface.co/datasets/jondurbin/airoboros-uncensored) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-22 |
| latimar | [airoboros-13b-ggml](https://huggingface.co/latimar/airoboros-13b-ggml) | llama | 13b | q4_1, q5_1, q8_0 | [synthetic airoboros-uncensored](https://huggingface.co/datasets/jondurbin/airoboros-uncensored) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-22 |
| ehartford | [WizardLM-30B-Uncensored](https://huggingface.co/ehartford/WizardLM-30B-Uncensored) | llama | 30b | none | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-22 |
| TheBloke | [WizardLM-30B-Uncensored-GGML](https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GGML) | llama | 30b | q4_0, q4_1, q5_0, q5_1, q8_0, q2_K, q3_K_S, q3_K_M, q3_K_L, q4_K_S, q4_K_M, q5_K_S, q6_K | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-22 |
| TheBloke | [gpt4-alpaca-lora-30B-4bit-GGML](https://huggingface.co/TheBloke/gpt4-alpaca-lora-30B-4bit-GGML) | alpaca | 30b | q4_0, q4_1, q5_0, q5_1 | chansung's dataset alpaca_data_gpt4.json |  |  |  | 2023-05-20 |
| NeoDim | [starchat-alpha-GGML](https://huggingface.co/NeoDim/starchat-alpha-GGML) | starcoder | 16b | q4_0, q4_1, q5_0, q5_1, q8_0 | [dolly](https://huggingface.co/datasets/databricks/databricks-dolly-15k), [oasst](https://huggingface.co/datasets/OpenAssistant/oasst1) | chat |  |  | 2023-05-20 |
| openaccess-ai-collective | [manticore-13b](https://huggingface.co/openaccess-ai-collective/manticore-13b) | llama | 13b | none | [ShareGPT](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered), [WizardLM](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered), [Wizard-Vicuna](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered), [Alpaca-CoT subset](https://huggingface.co/QingyiSi/Alpaca-CoT), [GPT4-LLM-Cleaned](https://huggingface.co/datasets/teknium/GPT4-LLM-Cleaned), [GPTeacher-General-Instruct](https://huggingface.co/datasets/teknium/GPTeacher-General-Instruct), ARC-Easy & ARC-Challenge, mmlu subset, [hellaswag subset](https://huggingface.co/datasets/hellaswag), [ScienceQA_text_only](https://huggingface.co/datasets/metaeval/ScienceQA_text_only), [summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback) | chat + instruct | [manticore-chat + manticore-instruct](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-19 |
| TheBloke | [Manticore-13B-GGML](https://huggingface.co/TheBloke/Manticore-13B-GGML) | llama | 13b | q4_0, q5_0, q5_1, q8_0 | [ShareGPT](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered), [WizardLM](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered), [Wizard-Vicuna](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered), [Alpaca-CoT subset](https://huggingface.co/QingyiSi/Alpaca-CoT), [GPT4-LLM-Cleaned](https://huggingface.co/datasets/teknium/GPT4-LLM-Cleaned), [GPTeacher-General-Instruct](https://huggingface.co/datasets/teknium/GPTeacher-General-Instruct), ARC-Easy & ARC-Challenge, mmlu subset, [hellaswag subset](https://huggingface.co/datasets/hellaswag), [ScienceQA_text_only](https://huggingface.co/datasets/metaeval/ScienceQA_text_only), [summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback) | chat + instruct | [manticore-chat + manticore-instruct](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-19 |
| TheBloke | [Manticore-13B-GPTQ](https://huggingface.co/TheBloke/Manticore-13B-GPTQ) | llama | 13b | 4bit GPTQ | [ShareGPT](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered), [WizardLM](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered), [Wizard-Vicuna](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered), [Alpaca-CoT subset](https://huggingface.co/QingyiSi/Alpaca-CoT), [GPT4-LLM-Cleaned](https://huggingface.co/datasets/teknium/GPT4-LLM-Cleaned), [GPTeacher-General-Instruct](https://huggingface.co/datasets/teknium/GPTeacher-General-Instruct), ARC-Easy & ARC-Challenge, mmlu subset, [hellaswag subset](https://huggingface.co/datasets/hellaswag), [ScienceQA_text_only](https://huggingface.co/datasets/metaeval/ScienceQA_text_only), [summarize_from_feedback](https://huggingface.co/datasets/openai/summarize_from_feedback) | chat + instruct | [manticore-chat + manticore-instruct](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-19 |
| PygmalionAI | [metharme-13b](https://huggingface.co/PygmalionAI/metharme-13b) | llama | 13b | none | instruction, roleplay, fictional stories, conversations, synthetic instructions |  |  |  | 2023-05-19 |
| TehVenom | [Metharme-13b-8bit-GPTQ](https://huggingface.co/TehVenom/Metharme-13b-8bit-GPTQ) | llama | 13b | 8bit GPTQ | instruction, roleplay, fictional stories, conversations, synthetic instructions |  |  |  | 2023-05-19 |
| TehVenom | [Metharme-13b-GGML](https://huggingface.co/TehVenom/Metharme-13b-GGML) | llama | 13b | q4_1, q5_1, q8_0 | instruction, roleplay, fictional stories, conversations, synthetic instructions |  |  |  | 2023-05-19 |
| TehVenom | [Metharme-13b-Merged](https://huggingface.co/TehVenom/Metharme-13b-Merged) | llama | 13b | none | instruction, roleplay, fictional stories, conversations, synthetic instructions |  |  |  | 2023-05-19 |
| PygmalionAI | [pygmalion-13b](https://huggingface.co/PygmalionAI/pygmalion-13b) | llama | 13b | none | subset of Pygmalion-6B-v8-pt4 |  |  |  | 2023-05-19 |
| notstoic | [pygmalion-13b-4bit-128g](https://huggingface.co/notstoic/pygmalion-13b-4bit-128g) | llama | 13b | 4bit GPTQ | subset of Pygmalion-6B-v8-pt4 |  |  |  | 2023-05-19 |
| notstoic | [pygmalion-13b-ggml](https://huggingface.co/notstoic/pygmalion-13b-ggml) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0 | subset of Pygmalion-6B-v8-pt4 |  |  |  | 2023-05-19 |
| TehVenom | [Pygmalion-13b-GGML](https://huggingface.co/TehVenom/Pygmalion-13b-GGML) | llama | 13b | q4_1, q5_1, q8_0 | subset of Pygmalion-6B-v8-pt4 |  |  |  | 2023-05-19 |
| TehVenom | [Pygmalion-13b-Merged](https://huggingface.co/TehVenom/Pygmalion-13b-Merged) | llama | 13b | none | subset of Pygmalion-6B-v8-pt4 |  |  |  | 2023-05-19 |
| ehartford | [Wizard-Vicuna-7B-Uncensored](https://huggingface.co/ehartford/Wizard-Vicuna-7B-Uncensored) | vicuna | 7b | none | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-18 |
| TheBloke | [Wizard-Vicuna-7B-Uncensored-GGML](https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML) | vicuna | 7b | q4_0, q4_1, q5_0, q5_1, q8_0 | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-18 |
| TheBloke | [Wizard-Vicuna-7B-Uncensored-GPTQ](https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ) | vicuna | 7b | 4bit GPTQ | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-18 |
| askmyteapot | [GPT4-X-Alpasta-30b-4bit](https://huggingface.co/askmyteapot/GPT4-X-Alpasta-30b-4bit) | alpaca | 30b | 4bit GPTQ | merge of [Chansung GPT4-Alpaca Lora](https://huggingface.co/chansung/gpt4-alpaca-lora-30b) and [oasst native fine-tune](https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor) |  |  |  | 2023-05-17 |
| teknium | [llama-deus-7b-v3-lora-merged](https://huggingface.co/teknium/llama-deus-7b-v3-lora-merged) | llama | 7b | none | GPTeacher, Roleplay V2 Instruct, GPT4-LLM Uncensored + Unnatural Instructions, WizardLM Uncensored, CamelAI's 20k Bio Physics Chemistry Math, CodeAlpaca |  |  |  | 2023-05-17 |
| bigcode | [starcoderplus](https://huggingface.co/bigcode/starcoderplus) | starcoder | 15.5b | none | StarCoderBase + [RedefinedWeb](https://huggingface.co/datasets/tiiuae/falcon-refinedweb), [StarCoderData](https://huggingface.co/datasets/bigcode/starcoderdata) (The Stack (v1.2)), a Wikipedia dataset | fill in the middle |  |  | 2023-05-17 |
| Neko-Institute-of-Science | [VicUnLocked-30b-LoRA](https://huggingface.co/Neko-Institute-of-Science/VicUnLocked-30b-LoRA) | vicuna | 30b | none |  |  |  | yes | 2023-05-17 |
| TheBloke | [VicUnlocked-30B-LoRA-GGML](https://huggingface.co/TheBloke/VicUnlocked-30B-LoRA-GGML) | vicuna | 30b | q4_0, q4_1, q5_0, q5_1, q8_0 |  |  |  |  | 2023-05-17 |
| TheBloke | [VicUnlocked-30B-LoRA-GPTQ](https://huggingface.co/TheBloke/VicUnlocked-30B-LoRA-GPTQ) | vicuna | 30b | 4bit GPTQ |  |  |  |  | 2023-05-17 |
| TheBloke | [VicUnlocked-30B-LoRA-HF](https://huggingface.co/TheBloke/VicUnlocked-30B-LoRA-HF) | vicuna | 30b | none |  |  |  |  | 2023-05-17 |
| TheBloke | [Wizard-Vicuna-13B-Uncensored-GGML](https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GGML) | vicuna | 13b | q4_0, q5_0, q5_1, q8_0 | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-17 |
| TheBloke | [Wizard-Vicuna-13B-Uncensored-GPTQ](https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ) | vicuna | 13b | 4bit GPTQ | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-17 |
| NeoDim | [starcoder-GGML](https://huggingface.co/NeoDim/starcoder-GGML) | starcoder | 15.5b | q4_0, q4_1, q5_0, q5_1, q8_0 | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack) |  |  |  | 2023-05-16 |
| NeoDim | [starcoderbase-GGML](https://huggingface.co/NeoDim/starcoderbase-GGML) | starcoder | 15.5b | q4_0, q4_1, q5_0, q5_1, q8_0 | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack), additional 35B Python tokens | text completion |  |  | 2023-05-16 |
| openaccess-ai-collective | [wizard-mega-13b](https://huggingface.co/openaccess-ai-collective/wizard-mega-13b) | llama | 13b | none | [ShareGPT](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered), [WizardLM](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered), [Wizard-Vicuna](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered) |  |  |  | 2023-05-15 |
| TheBloke | [wizard-mega-13B-GGML](https://huggingface.co/TheBloke/wizard-mega-13B-GGML) | llama | 13b | q4_0, q5_0, q5_1, q8_0 | [ShareGPT](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered), [WizardLM](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered), [Wizard-Vicuna](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered) |  |  |  | 2023-05-15 |
| TheBloke | [wizard-mega-13B-GPTQ](https://huggingface.co/TheBloke/wizard-mega-13B-GPTQ) | llama | 13b | 4bit GPTQ | [ShareGPT](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered), [WizardLM](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered), [Wizard-Vicuna](https://huggingface.co/datasets/ehartford/wizard_vicuna_70k_unfiltered) |  |  |  | 2023-05-15 |
| TheBloke | [WizardLM-13B-Uncensored-GGML](https://huggingface.co/TheBloke/WizardLM-13B-Uncensored-GGML) | llama | 13b | q4_0, q4_1, q5_0, q5_1, q8_0 | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-15 |
| mongolian-basket-weaving | [wizardlm-13b-uncensored-ggml-f16](https://huggingface.co/mongolian-basket-weaving/wizardlm-13b-uncensored-ggml-f16) | llama | 13b | none | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-13 |
| TheBloke | [dromedary-65B-lora-GPTQ](https://huggingface.co/TheBloke/dromedary-65B-lora-GPTQ) | llama | 65b | 4bit GPTQ |  |  |  |  | 2023-05-12 |
| eachadea | [ggml-gpt4-x-vicuna-13b](https://huggingface.co/eachadea/ggml-gpt4-x-vicuna-13b) | vicuna-v1.1 | 13b | q4_0, q5_0, q5_1 | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct |  |  |  | 2023-05-12 |
| TheBloke | [gpt4-x-vicuna-13B-GGML](https://huggingface.co/TheBloke/gpt4-x-vicuna-13B-GGML) | vicuna-v1.1 | 13b | q4_0, q5_0, q5_1 | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct |  |  |  | 2023-05-12 |
| TheBloke | [GPT4All-13B-snoozy-GGML](https://huggingface.co/TheBloke/GPT4All-13B-snoozy-GGML) | llama | 13b | q4_0, q5_0, q5_1 | [gpt4all-j-prompt-generations](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations) |  |  |  | 2023-05-12 |
| VMware | [open-llama-0.3T-7B-open-instruct-v1.1](https://huggingface.co/VMware/open-llama-0.3T-7B-open-instruct-v1.1) | open-llama | 7b | none | oasst, dolly, hhrlhf | instruct |  |  | 2023-05-12 |
| TheBloke | [OpenAssistant-SFT-7-Llama-30B-GGML](https://huggingface.co/TheBloke/OpenAssistant-SFT-7-Llama-30B-GGML) | llama | 30b | q4_0, q5_0, q5_1 | Open-Assistant |  |  |  | 2023-05-12 |
| TheBloke | [stable-vicuna-13B-GGML](https://huggingface.co/TheBloke/stable-vicuna-13B-GGML) | vicuna | 13b | q4_0, q5_0, q5_1, q8_0 | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-05-12 |
| TheBloke | [WizardLM-7B-uncensored-GGML](https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GGML) | llama | 7b | q4_0, q5_0, q5_1 | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-12 |
| TheBloke | [dromedary-65B-lora-GGML](https://huggingface.co/TheBloke/dromedary-65B-lora-GGML) | llama | 65b | q4_0, q4_2, q5_0, q5_1 |  |  |  |  | 2023-05-11 |
| TheBloke | [dromedary-65b-lora-HF](https://huggingface.co/TheBloke/dromedary-65b-lora-HF) | llama | 65b | none |  |  |  |  | 2023-05-11 |
| TheBloke | [h2ogpt-oasst1-512-30B-GPTQ](https://huggingface.co/TheBloke/h2ogpt-oasst1-512-30B-GPTQ) | llama | 30b | 4bit GPTQ | [h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2) |  |  |  | 2023-05-11 |
| openaccess-ai-collective | [mpt-7b-wizardlm](https://huggingface.co/openaccess-ai-collective/mpt-7b-wizardlm) | llama | 7b | none | base WizardLM finetuned on MPT datasets: [bigcode/the-stack](https://huggingface.co/datasets/bigcode/the-stack), [mc4](https://huggingface.co/datasets/mc4), [c4](https://huggingface.co/datasets/c4) |  |  |  | 2023-05-11 |
| 4bit | [WizardLM-13B-Uncensored-4bit-128g](https://huggingface.co/4bit/WizardLM-13B-Uncensored-4bit-128g) | llama | 13b | 4bit GPTQ | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-11 |
| VMware | [open-llama-0.3T-7B-instruct-dolly-hhrlhf](https://huggingface.co/VMware/open-llama-0.3T-7B-instruct-dolly-hhrlhf) | open-llama | 7b | none | [mosaicml/dolly_hhrlhf](https://huggingface.co/datasets/mosaicml/dolly_hhrlhf) | instruct |  |  | 2023-05-10 |
| HuggingFaceH4 | [starchat-alpha](https://huggingface.co/HuggingFaceH4/starchat-alpha) | starcoder | 16b | none | [dolly](https://huggingface.co/datasets/databricks/databricks-dolly-15k), [oasst](https://huggingface.co/datasets/OpenAssistant/oasst1) | chat |  |  | 2023-05-09 |
| LLMs | [Vicuna-LoRA-EvolInstruct-StarCoder](https://huggingface.co/LLMs/Vicuna-LoRA-EvolInstruct-StarCoder) | vicuna | ? | none | EvolInstruct, [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack) |  |  | yes | 2023-05-09 |
| ehartford | [Wizard-Vicuna-13b-Uncensored](https://huggingface.co/ehartford/Wizard-Vicuna-13b-Uncensored) | vicuna | 13b | none | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-09 |
| ehartford | [WizardLM-13B-Uncensored](https://huggingface.co/ehartford/WizardLM-13B-Uncensored) | llama | 13b | none | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-09 |
| h2oai | [h2ogpt-research-oig-oasst1-512-30b](https://huggingface.co/h2oai/h2ogpt-research-oig-oasst1-512-30b) | llama | 30b | none | [h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v2) |  |  |  | 2023-05-07 |
| NousResearch | [GPT4-x-Vicuna-13b-4bit](https://huggingface.co/NousResearch/GPT4-x-Vicuna-13b-4bit) | vicuna-v1.1 | 13b | 4bit GPTQ | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct |  |  |  | 2023-05-06 |
| NousResearch | [gpt4-x-vicuna-13b](https://huggingface.co/NousResearch/gpt4-x-vicuna-13b) | vicuna-v1.1 | 13b | none | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct |  |  |  | 2023-05-05 |
| TheBloke | [gpt4-x-vicuna-13B-GPTQ](https://huggingface.co/TheBloke/gpt4-x-vicuna-13B-GPTQ) | vicuna-v1.1 | 13b | 4bit GPTQ | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct |  |  |  | 2023-05-05 |
| TheBloke | [gpt4-x-vicuna-13B-HF](https://huggingface.co/TheBloke/gpt4-x-vicuna-13B-HF) | vicuna-v1.1 | 13b | 16bit | Teknium/GPTeacher, Roleplay v2 (unreleased), GPT-4-LLM, NousResearch/Instruct |  |  |  | 2023-05-05 |
| mosaicml | [mpt-7b](https://huggingface.co/mosaicml/mpt-7b) | mpt | 7b | none | [bigcode/the-stack](https://huggingface.co/datasets/bigcode/the-stack), [mc4](https://huggingface.co/datasets/mc4), [c4](https://huggingface.co/datasets/c4) |  |  |  | 2023-05-05 |
| mosaicml | [mpt-7b-chat](https://huggingface.co/mosaicml/mpt-7b-chat) | mpt | 7b | none | [ShareGPT-Vicuna](https://huggingface.co/datasets/jeffwan/sharegpt_vicuna), [HC3](https://huggingface.co/datasets/Hello-SimpleAI/HC3), [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca), [HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [EvolInstruct](https://huggingface.co/datasets/victor123/evol_instruct_70k) | chat |  |  | 2023-05-05 |
| mosaicml | [mpt-7b-instruct](https://huggingface.co/mosaicml/mpt-7b-instruct) | mpt | 7b | none | [mosaicml/dolly-hhrlhf](https://huggingface.co/datasets/sam-mosaic/dolly_hhrlhf) | instruct |  |  | 2023-05-05 |
| mosaicml | [mpt-7b-storywriter](https://huggingface.co/mosaicml/mpt-7b-storywriter) | mpt | 7b | none | [books3](https://huggingface.co/datasets/the_pile_books3) |  |  |  | 2023-05-05 |
| togethercomputer | [RedPajama-INCITE-Chat-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1) | redpajama | 3b | none | oasst1, dolly2 |  |  |  | 2023-05-05 |
| togethercomputer | [RedPajama-INCITE-Instruct-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1) | redpajama | 3b | none | base: [RedPajama-Data-T1](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T), instruct: dataset of [GPT-JT](https://huggingface.co/togethercomputer/GPT-JT-6B-v1) for few-shot |  |  |  | 2023-05-05 |
| GeorgiaTechResearchInstitute | [starcoder-gpteacher-code-instruct](https://huggingface.co/GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct) | starcoder | 15.5b | none | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack), [GPTeacher](https://github.com/teknium1/GPTeacher) | instruct |  |  | 2023-05-05 |
| TheBloke | [WizardLM-7B-uncensored-GPTQ](https://huggingface.co/TheBloke/WizardLM-7B-uncensored-GPTQ) | llama | 7b | 4bit GPTQ | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-05 |
| openlm-research | [open_llama_7b_preview_300bt](https://huggingface.co/openlm-research/open_llama_7b_preview_300bt) | open-llama | 7b | none | [RedPajama](https://www.together.xyz/blog/redpajama) |  |  |  | 2023-05-04 |
| togethercomputer | [RedPajama-INCITE-Base-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1) | redpajama | 3b | none | [RedPajama-Data-T1](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T) |  |  |  | 2023-05-04 |
| bigcode | [starcoder](https://huggingface.co/bigcode/starcoder) | starcoder | 15.5b | none | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack) |  |  |  | 2023-05-04 |
| bigcode | [starcoderbase](https://huggingface.co/bigcode/starcoderbase) | starcoder | 15.5b | none | [The Stack v1.2](https://huggingface.co/datasets/bigcode/the-stack), additional 35B Python tokens | text completion |  |  | 2023-05-04 |
| amesianx | [wizard-vicuna-13b-ggml](https://huggingface.co/amesianx/wizard-vicuna-13b-ggml) | llama | 13b | q4_0, q4_1, q4_2, q5_0, q5_1, q8_0 | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-04 |
| TheBloke | [wizard-vicuna-13B-GGML](https://huggingface.co/TheBloke/wizard-vicuna-13B-GGML) | llama | 13b | q4_0, q4_2, q5_0, q5_1 | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-04 |
| ehartford | [WizardLM-7B-Uncensored](https://huggingface.co/ehartford/WizardLM-7B-Uncensored) | llama | 7b | none | uncensored WizardLM dataset [ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered](https://huggingface.co/datasets/ehartford/WizardLM_alpaca_evol_instruct_70k_unfiltered) |  |  |  | 2023-05-04 |
| reeducator | [vicuna-13b-cocktail](https://huggingface.co/reeducator/vicuna-13b-cocktail) | vicuna-1.1 | 13b | q5_0, 4bit GPTQ | [GPTeacher-Vicuna](https://huggingface.co/datasets/gozfarb/GPTeacher-Vicuna), [gozfarb/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/gozfarb/ShareGPT_Vicuna_unfiltered), [anon8231489123/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-05-03 |
| reeducator | [vicuna-13b-free](https://huggingface.co/reeducator/vicuna-13b-free) | vicuna-1.1 | 13b | q5_0, 4bit GPTQ | [gozfarb/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/gozfarb/ShareGPT_Vicuna_unfiltered), [anon8231489123/ShareGPT_Vicuna_unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-05-03 |
| junelee | [wizard-vicuna-13b](https://huggingface.co/junelee/wizard-vicuna-13b) | llama | 13b | none | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k) | instruct | [vicuna-v1.1](https://docs.google.com/spreadsheets/d/1PtrPwDV8Wcdhzh-N_Siaofc2R6TImebnFvv0GuCCzdo/edit#gid=1982365152) |  | 2023-05-03 |
| execveat | [wizardLM-13b-ggml-4bit](https://huggingface.co/execveat/wizardLM-13b-ggml-4bit) | llama | 13b | q4_0, q4_1, q5_0, q5_1 | [WizardVicuna 70k conversations](https://huggingface.co/datasets/junelee/wizard_vicuna_70k) |  |  |  | 2023-05-03 |
| winglian | [llama-adapter-13b](https://huggingface.co/winglian/llama-adapter-13b) | llama | 13b | none | [alpaca_data_gpt4.json](https://github.com/tloen/alpaca-lora/blob/main/alpaca_data_gpt4.json) |  |  |  | 2023-05-02 |
| TehVenom | [Metharme-7b-4bit-Q4_1-GGML](https://huggingface.co/TehVenom/Metharme-7b-4bit-Q4_1-GGML) | llama | 7b | q4_1 | instruction, roleplay, fictional stories, conversations, synthetic instructions |  |  |  | 2023-05-02 |
| openlm-research | [open_llama_7b_preview_200bt](https://huggingface.co/openlm-research/open_llama_7b_preview_200bt) | llama | 7b | none | [Redpajama](https://www.together.xyz/blog/redpajama) |  |  |  | 2023-05-02 |
| winddude | [wizardLM-LlaMA-LoRA-13](https://huggingface.co/winddude/wizardLM-LlaMA-LoRA-13) | llama | 13b | none | modified [evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) |  |  | yes | 2023-05-02 |
| PygmalionAI | [pygmalion-7b](https://huggingface.co/PygmalionAI/pygmalion-7b) | llama | 7b | none | subset of Pygmalion-6B-v8-pt4 |  |  |  | 2023-05-01 |
| unamedkr | [stable-vicuna-13b](https://huggingface.co/unamedkr/stable-vicuna-13b) | vicuna | 13b | none | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-05-01 |
| Neko-Institute-of-Science | [metharme-7b](https://huggingface.co/Neko-Institute-of-Science/metharme-7b) | llama | 7b | none | instruction, roleplay, fictional stories, conversations, synthetic instructions |  |  |  | 2023-04-30 |
| Neko-Institute-of-Science | [pygmalion-7b](https://huggingface.co/Neko-Institute-of-Science/pygmalion-7b) | llama | 7b | none | subset of Pygmalion-6B-v8-pt4 |  |  |  | 2023-04-30 |
| tsumeone | [stable-vicuna-13B-4bit-128g-cuda](https://huggingface.co/tsumeone/stable-vicuna-13B-4bit-128g-cuda) | vicuna | 13b | 4bit GPTQ | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-04-30 |
| 4bit | [stable-vicuna-13B-GPTQ](https://huggingface.co/4bit/stable-vicuna-13B-GPTQ) | vicuna | 4b | 4bit GPTQ | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-04-30 |
| LLMs | [Alpaca-LoRA-65B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-65B-elina) | alpaca | 65b | none | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored |  |  | yes | 2023-04-29 |
| MetaIX | [GPT4-X-Alpasta-30b-4bit](https://huggingface.co/MetaIX/GPT4-X-Alpasta-30b-4bit) | alpaca | 30b | 4bit GPTQ / GGML | merge of [Chansung GPT4-Alpaca Lora](https://huggingface.co/chansung/gpt4-alpaca-lora-30b) and [oasst native fine-tune](https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor) |  |  |  | 2023-04-29 |
| digitous | [ChanSung_Elina_33b-4bit](https://huggingface.co/digitous/ChanSung_Elina_33b-4bit) | llama | 33b | 4bit GPTQ | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored |  |  |  | 2023-04-28 |
| TheBloke | [gpt4-alpaca-lora-13B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/gpt4-alpaca-lora-13B-GPTQ-4bit-128g) | alpaca | 13b | 4bit GPTQ | chansung's dataset alpaca_data_gpt4.json |  |  |  | 2023-04-28 |
| OpenAssistant | [oasst-sft-7-llama-30b-xor](https://huggingface.co/OpenAssistant/oasst-sft-7-llama-30b-xor) | llama | 30b | none | Open-Assistant |  |  |  | 2023-04-28 |
| CarperAI | [stable-vicuna-13b-delta](https://huggingface.co/CarperAI/stable-vicuna-13b-delta) | vicuna | 13b | none | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-04-28 |
| TheBloke | [stable-vicuna-13B-GPTQ](https://huggingface.co/TheBloke/stable-vicuna-13B-GPTQ) | vicuna | 13b | 4bit GPTQ | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-04-28 |
| TheBloke | [stable-vicuna-13B-HF](https://huggingface.co/TheBloke/stable-vicuna-13B-HF) | vicuna | 13b | none | [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [GPT4All](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human PReferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-04-28 |
| Pi3141 | [alpaca-7b-native-enhanced](https://huggingface.co/Pi3141/alpaca-7b-native-enhanced) | alpaca | 7b | q4_0, q4_1, q4_2, q4_3, q5_0, q5_1 | [larger dataset?](https://huggingface.co/Pi3141/alpaca-7b-native-enhanced/discussions/2) |  |  |  | 2023-04-27 |
| GeoV | [GeoV-9b](https://huggingface.co/GeoV/GeoV-9b) | GeoV | 9b | none |  |  |  |  | 2023-04-27 |
| CRD716 | [ggml-LLaMa-65B-quantized](https://huggingface.co/CRD716/ggml-LLaMa-65B-quantized) | llama | 65b | q4_0, q5_0, q5_1 |  |  |  |  | 2023-04-27 |
| LLMs | [Alpaca-LoRA-30B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-30B-elina) | alpaca | 30b | none | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored |  |  |  | 2023-04-26 |
| ArmelR | [BigCodeAlpaca2048](https://huggingface.co/ArmelR/BigCodeAlpaca2048) | alpaca? | ? | none | BigCode? |  |  |  | 2023-04-26 |
| Fsoft-AIC | [CodeCapybara](https://huggingface.co/Fsoft-AIC/CodeCapybara) | llama | 7b | none | [CodeCapybara](https://github.com/FSoft-AI4Code/CodeCapybara) |  |  |  | 2023-04-26 |
| catalpa | [codecapybara-4bit-128g-gptq](https://huggingface.co/catalpa/codecapybara-4bit-128g-gptq) | llama | 7b | 4bit GPTQ | [CodeCapybara](https://github.com/FSoft-AI4Code/CodeCapybara) |  |  |  | 2023-04-26 |
| mhhmm | [codegen-6B-lora](https://huggingface.co/mhhmm/codegen-6B-lora) | codegen | 6b | none | Peft/lora finetune with [Leetcode](https://huggingface.co/datasets/mhhmm/leetcode-solutions-python) and [Google Deepmind Code contests](https://huggingface.co/datasets/deepmind/code_contests) |  |  | yes | 2023-04-26 |
| camelids | [llama-65b-ggml-q4_2](https://huggingface.co/camelids/llama-65b-ggml-q4_2) | llama | 65b | q4_2 |  |  |  |  | 2023-04-26 |
| wordcab | [llama-natural-instructions-13b](https://huggingface.co/wordcab/llama-natural-instructions-13b) | llama | 13b | none | [LoRA of Natural Instructions by AllenAI](https://huggingface.co/datasets/Muennighoff/natural-instructions) | instruct |  |  | 2023-04-26 |
| wordcab | [llama-natural-instructions-7b](https://huggingface.co/wordcab/llama-natural-instructions-7b) | llama | 7b | none | [LoRA of Natural Instructions by AllenAI](https://huggingface.co/datasets/Muennighoff/natural-instructions) | instruct |  |  | 2023-04-26 |
| oeathus | [stablelm-7b-sft-v7-epoch-3-ggml-q4](https://huggingface.co/oeathus/stablelm-7b-sft-v7-epoch-3-ggml-q4) | stablelm | 7b | q4_0, q4_1, q4_2, q4_3 | oasst, vicuna, dolly15k, grade_school_math_instructions, code_alpaca |  |  |  | 2023-04-26 |
| oeathus | [stablelm-base-alpha-7b-ggml-q4](https://huggingface.co/oeathus/stablelm-base-alpha-7b-ggml-q4) | stablelm | 7b | q4_0, q4_1, q4_2, q4_3 | [The New Pile](https://pile.eleuther.ai/) |  |  |  | 2023-04-26 |
| oeathus | [stablelm-tuned-alpha-7b-ggml-q4](https://huggingface.co/oeathus/stablelm-tuned-alpha-7b-ggml-q4) | stablelm | 7b | q4_0, q4_1, q4_2, q4_3 | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH |  |  |  | 2023-04-26 |
| TheBloke | [wizardLM-7B-GGML](https://huggingface.co/TheBloke/wizardLM-7B-GGML) | llama | 7b | q4_0, q4_2, q4_3, q5_0, q5_1 | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) |  |  |  | 2023-04-26 |
| TheBloke | [wizardLM-7B-GPTQ](https://huggingface.co/TheBloke/wizardLM-7B-GPTQ) | llama | 7b | 4bit GPTQ | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) |  |  |  | 2023-04-26 |
| TheBloke | [wizardLM-7B-HF](https://huggingface.co/TheBloke/wizardLM-7B-HF) | llama | 7b | none | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) |  |  |  | 2023-04-26 |
| winddude | [wizardLM-LlaMA-LoRA-7B](https://huggingface.co/winddude/wizardLM-LlaMA-LoRA-7B) | llama | 7b | none | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) |  |  | yes | 2023-04-26 |
| kajdun | [llama-30b-4bit-128g](https://huggingface.co/kajdun/llama-30b-4bit-128g) | llama | 30b | 4bit GPTQ | none |  |  | yes | 2023-04-25 |
| victor123 | [WizardLM](https://huggingface.co/victor123/WizardLM) | llama | 7b | none | [alpaca_evol_instruct_70k](https://huggingface.co/datasets/victor123/evol_instruct_70k) |  |  |  | 2023-04-25 |
| LLMs | [Alpaca-LoRA-13B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-13B-elina) | alpaca | 13b | none | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored |  |  | yes | 2023-04-24 |
| MildlyAggressiveGoose1 | [ggml-oasst-sft-6-llama-30B-q4_0](https://huggingface.co/MildlyAggressiveGoose1/ggml-oasst-sft-6-llama-30B-q4_0) | llama | 30b | q4_0 | Open-Assistant |  |  |  | 2023-04-24 |
| MildlyAggressiveGoose1 | [ggml-oasst-sft-6-llama-30B-q4_2](https://huggingface.co/MildlyAggressiveGoose1/ggml-oasst-sft-6-llama-30B-q4_2) | llama | 30b | q4_2 | Open-Assistant |  |  |  | 2023-04-24 |
| nomic-ai | [gpt4all-13b-snoozy](https://huggingface.co/nomic-ai/gpt4all-13b-snoozy) | llama | 13b | none | [gpt4all-j-prompt-generations](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations) |  |  |  | 2023-04-24 |
| LLMs | [Alpaca-LoRA-7B-elina](https://huggingface.co/LLMs/Alpaca-LoRA-7B-elina) | alpaca | 7b | none | [AlpacaDataCleaned](https://github.com/gururise/AlpacaDataCleaned) uncensored |  |  | yes | 2023-04-23 |
| ravenscroftj | [CodeGen-2B-multi-ggml-quant](https://huggingface.co/ravenscroftj/CodeGen-2B-multi-ggml-quant) | codegen | 2b | 4bit ? | none |  |  |  | 2023-04-23 |
| ravenscroftj | [CodeGen-6B-multi-ggml-quant](https://huggingface.co/ravenscroftj/CodeGen-6B-multi-ggml-quant) | codegen | 6b | 4bit ? | none |  |  |  | 2023-04-23 |
| stevengrove | [gpt4tools-vicuna-13b-lora](https://huggingface.co/stevengrove/gpt4tools-vicuna-13b-lora) | vicuna | 13b | none | [gpt4tools_71k.json](https://github.com/StevenGrove/GPT4Tools#Dataset) which is a mix of [alpaca_gpt4_data](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data.json) and synthetic GPT3.5 instructions |  |  | yes | 2023-04-23 |
| h2oai | [h2ogpt-oasst1-512-20b](https://huggingface.co/h2oai/h2ogpt-oasst1-512-20b) | gpt-neox | 20b | none | [openassistant_oasst1](https://huggingface.co/datasets/h2oai/openassistant_oasst1) |  |  |  | 2023-04-23 |
| TheYuriLover | [llama-13b-SuperCOT-4bit-TRITON](https://huggingface.co/TheYuriLover/llama-13b-SuperCOT-4bit-TRITON) | llama | 13b | 4bit GPTQ | [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [neulab/conala](https://huggingface.co/datasets/neulab/conala), [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned) |  |  |  | 2023-04-23 |
| camenduru | [MiniGPT4-7B](https://huggingface.co/camenduru/MiniGPT4-7B) | vicuna | 7b | none | minigpt-4 |  |  |  | 2023-04-23 |
| MetaIX | [OpenAssistant-Llama-30b-4bit](https://huggingface.co/MetaIX/OpenAssistant-Llama-30b-4bit) | llama | 30b | 4bit GPTQ | Open-Assistant |  |  |  | 2023-04-23 |
| OpenAssistant | [stablelm-7b-sft-v7-epoch-3](https://huggingface.co/OpenAssistant/stablelm-7b-sft-v7-epoch-3) | stablelm | 7b | none | oasst, vicuna, dolly15k, grade_school_math_instructions, code_alpaca |  |  |  | 2023-04-23 |
| TheBloke | [alpaca-lora-65B-GGML](https://huggingface.co/TheBloke/alpaca-lora-65B-GGML) | alpaca | 65b | 4bit/2bit | Alpaca LoRa |  |  |  | 2023-04-22 |
| ethzanalytics | [dolly-v2-12b-sharded](https://huggingface.co/ethzanalytics/dolly-v2-12b-sharded) | dolly | 12b | none | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data) |  |  |  | 2023-04-22 |
| ethzanalytics | [dolly-v2-7b-sharded](https://huggingface.co/ethzanalytics/dolly-v2-7b-sharded) | dolly | 7b | none | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data) |  |  |  | 2023-04-22 |
| eachadea | [ggml-vicuna-13b-1.1](https://huggingface.co/eachadea/ggml-vicuna-13b-1.1) | vicuna-v1.1 | 13b | q4_0, q4_1, q4_2, q4_3, q5_0, q5_1 | vicuna 1.1 censored, vicuna 1.0 uncensored |  |  |  | 2023-04-22 |
| teknium | [GPT4-x-Alpaca13b-RolePlayLora-4bit-v2](https://huggingface.co/teknium/GPT4-x-Alpaca13b-RolePlayLora-4bit-v2) | llama | 13b | 4bit GPTQ | gpt4-x-alpaca finetune, [roleplay instruct](https://github.com/teknium1/GPTeacher/tree/main/Roleplay) |  |  |  | 2023-04-22 |
| h2oai | [h2ogpt-oig-oasst1-512-6.9b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-512-6.9b) | pythia | 6.9b | none | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt) |  |  |  | 2023-04-22 |
| luodian | [llama-13b-hf](https://huggingface.co/luodian/llama-13b-hf) | llama | 13b | none | LLaMA |  |  |  | 2023-04-22 |
| ausboss | [llama-13b-supercot-4bit-128g](https://huggingface.co/ausboss/llama-13b-supercot-4bit-128g) | llama | 13b | 4bit GPTQ | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-13b) |  |  |  | 2023-04-22 |
| elinas | [llama-30b-hf-transformers-4.29](https://huggingface.co/elinas/llama-30b-hf-transformers-4.29) | llama | 30b | none | LLaMA |  |  |  | 2023-04-22 |
| tsumeone | [llama-30b-supercot-4bit-128g-cuda](https://huggingface.co/tsumeone/llama-30b-supercot-4bit-128g-cuda) | llama | 30b | 4bit GPTQ | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-30b) |  |  |  | 2023-04-22 |
| elinas | [llama-65b-hf-transformers-4.29](https://huggingface.co/elinas/llama-65b-hf-transformers-4.29) | llama | 65b | none | llama |  |  |  | 2023-04-22 |
| luodian | [llama-7b-hf](https://huggingface.co/luodian/llama-7b-hf) | llama | 7b | none | LLaMA |  |  |  | 2023-04-22 |
| fragro | [llama-7b-hf](https://huggingface.co/fragro/llama-7b-hf) | llama | 7b | none | LLaMA |  |  |  | 2023-04-22 |
| elinas | [llama-7b-hf-transformers-4.29](https://huggingface.co/elinas/llama-7b-hf-transformers-4.29) | llama | 7b | none | llama |  |  |  | 2023-04-22 |
| prodm93 | [llama_30b_corr](https://huggingface.co/prodm93/llama_30b_corr) | llama | 30b | none |  |  |  |  | 2023-04-22 |
| TheBloke | [medalpaca-13B-GPTQ-4bit](https://huggingface.co/TheBloke/medalpaca-13B-GPTQ-4bit) | alpaca | 13b | 4bit GPTQ | [ChatDoctor](https://github.com/Kent0n-Li/ChatDoctor), [Wikidoc](https://www.wikidoc.org/index.php/Main_Page), Stackexchange academia bio fitness health bioinformatics, Anki flashcards |  |  |  | 2023-04-22 |
| wangrongsheng | [MiniGPT-4-LLaMA-7B](https://huggingface.co/wangrongsheng/MiniGPT-4-LLaMA-7B) | vicuna | 7b | none | minigpt-4 |  |  |  | 2023-04-22 |
| OpenAssistant | [oasst-sft-6-llama-30b-xor](https://huggingface.co/OpenAssistant/oasst-sft-6-llama-30b-xor) | llama | 30b | none | Open-Assistant |  |  |  | 2023-04-22 |
| ethzanalytics | [stablelm-base-alpha-7b-sharded](https://huggingface.co/ethzanalytics/stablelm-base-alpha-7b-sharded) | stablelm | 7b | none | [The New Pile](https://pile.eleuther.ai/) |  |  |  | 2023-04-22 |
| ethzanalytics | [stablelm-tuned-alpha-3b-sharded](https://huggingface.co/ethzanalytics/stablelm-tuned-alpha-3b-sharded) | stablelm | 3b | none | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH |  |  |  | 2023-04-22 |
| ethzanalytics | [stablelm-tuned-alpha-7b-sharded](https://huggingface.co/ethzanalytics/stablelm-tuned-alpha-7b-sharded) | stablelm | 7b | none | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH |  |  |  | 2023-04-22 |
| kaiokendev | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA) | llama | 7b/13b/30b | 4bit GPTQ | [Alpaca-CoT](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT), [neulab/conala](https://huggingface.co/datasets/neulab/conala), [alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned) |  |  | yes | 2023-04-22 |
| ausboss | [llama-13b-supercot](https://huggingface.co/ausboss/llama-13b-supercot) | llama | 13b | none | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-13b) |  |  |  | 2023-04-21 |
| ausboss | [llama-30b-supercot](https://huggingface.co/ausboss/llama-30b-supercot) | llama | 30b | none | [SuperCOT-LoRA](https://huggingface.co/kaiokendev/SuperCOT-LoRA), [huggy LLaMA](https://huggingface.co/huggyllama/llama-30b) |  |  |  | 2023-04-21 |
| wojtab | [llava-13b-v0-4bit-128g](https://huggingface.co/wojtab/llava-13b-v0-4bit-128g) | llava | 13b | 4bit | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) |  |  |  | 2023-04-21 |
| mongolian-basket-weaving | [oasst-stablelm-7b-sft-v7-epoch-3-ggml-f16](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-f16) | stablelm | 7b | 16bit | Open-Assistant |  |  |  | 2023-04-21 |
| mongolian-basket-weaving | [oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_2](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_2) | stablelm | 7b | 4bit | Open-Assistant |  |  |  | 2023-04-21 |
| mongolian-basket-weaving | [oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_3](https://huggingface.co/mongolian-basket-weaving/oasst-stablelm-7b-sft-v7-epoch-3-ggml-q4_3) | stablelm | 7b | 4bit | Open-Assistant |  |  |  | 2023-04-21 |
| BlinkDL | [rwkv-4-raven](https://huggingface.co/BlinkDL/rwkv-4-raven) | rwkv | 3b/7b/14b | none | The Pile, Alpaca, CodeAlpaca, Guanaco, GPT4All, ShareGPT |  |  |  | 2023-04-21 |
| TheBloke | [alpaca-lora-65B-GGML](https://huggingface.co/TheBloke/alpaca-lora-65B-GGML) | alpaca | 65b | q2_0, q4_0, q4_2, q4_3 | GPT 3.5 Alpaca dataset? |  |  |  | 2023-04-20 |
| TheBloke | [alpaca-lora-65B-GPTQ-4bit](https://huggingface.co/TheBloke/alpaca-lora-65B-GPTQ-4bit) | alpaca | 65b | 4bit GPTQ | Alpaca LoRa |  |  | ? | 2023-04-20 |
| TheBloke | [alpaca-lora-65B-GPTQ-4bit](https://huggingface.co/TheBloke/alpaca-lora-65B-GPTQ-4bit) | alpaca | 65b | 4bit GPTQ | GPT 3.5 Alpaca dataset? |  |  |  | 2023-04-20 |
| Peeepy | [llama-30b-oasst](https://huggingface.co/Peeepy/llama-30b-oasst) | llama | 30b | none | oasst-lora |  |  |  | 2023-04-20 |
| Peeepy | [llama-30b-oasst-4bit](https://huggingface.co/Peeepy/llama-30b-oasst-4bit) | llama | 30b | 4bit | oasst-lora |  |  |  | 2023-04-20 |
| Peeepy | [llama-30b-oasst-4bit-128g](https://huggingface.co/Peeepy/llama-30b-oasst-4bit-128g) | llama | 30b | 4bit | oasst-lora |  |  |  | 2023-04-20 |
| prodm93 | [llama_65b_corr](https://huggingface.co/prodm93/llama_65b_corr) | llama | 65b | none |  |  |  |  | 2023-04-20 |
| prodm93 | [llama_7b_corr](https://huggingface.co/prodm93/llama_7b_corr) | llama | 7b | none |  |  |  |  | 2023-04-20 |
| mongolian-basket-weaving | [llava-13b-fp16](https://huggingface.co/mongolian-basket-weaving/llava-13b-fp16) | llava | 13b | 16bit | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) |  |  |  | 2023-04-20 |
| mongolian-basket-weaving | [llava-13b-fp16-safetensors](https://huggingface.co/mongolian-basket-weaving/llava-13b-fp16-safetensors) | llava | 13b | 16bit | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) |  |  |  | 2023-04-20 |
| wangrongsheng | [MiniGPT-4-LLaMA](https://huggingface.co/wangrongsheng/MiniGPT-4-LLaMA) | vicuna | 13b | none | minigpt-4 |  |  |  | 2023-04-20 |
| vvsotnikov | [stablelm-tuned-alpha-3b-16bit](https://huggingface.co/vvsotnikov/stablelm-tuned-alpha-3b-16bit) | stablelm | 3b | 16bit | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH |  |  |  | 2023-04-20 |
| vvsotnikov | [stablelm-tuned-alpha-7b-16bit](https://huggingface.co/vvsotnikov/stablelm-tuned-alpha-7b-16bit) | stablelm | 7b | 16bit | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH |  |  |  | 2023-04-20 |
| eachadea | [ggml-vicuna-7b-1.1](https://huggingface.co/eachadea/ggml-vicuna-7b-1.1) | vicuna-v1.1 | 7b | 4bit | vicuna censored |  |  |  | 2023-04-19 |
| h2oai | [h2ogpt-oig-oasst1-256-20b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-20b) | gpt-neox | 20b | none | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt) |  |  |  | 2023-04-19 |
| Vision-CAIR | [MiniGPT-4](https://huggingface.co/Vision-CAIR/MiniGPT-4) | vicuna | 7b | none | minigpt-4 |  |  |  | 2023-04-19 |
| stabilityai | [stablelm-tuned-alpha-3b/](https://huggingface.co/stabilityai/stablelm-tuned-alpha-3b/) | stablelm | 3b | none | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH |  |  |  | 2023-04-19 |
| stabilityai | [stablelm-tuned-alpha-7b/](https://huggingface.co/stabilityai/stablelm-tuned-alpha-7b/) | stablelm | 7b | none | [The New Pile](https://pile.eleuther.ai/), Stanford's Alpaca, Nomic-AI's gpt4all, RyokoAI's ShareGPT52K, Databricks Dolly, Anthropic's HH |  |  |  | 2023-04-19 |
| 4bit | [vicuna-13b-GPTQ-4bit-128g](https://huggingface.co/4bit/vicuna-13b-GPTQ-4bit-128g) | vicuna | 13b | 4bit GPTQ | Vicuna |  |  |  | 2023-04-19 |
| Melbourne | [Alpacino-30b-ggml](https://huggingface.co/Melbourne/Alpacino-30b-ggml) | alpaca | 30b | q4_0 | CoT + Storytelling |  |  |  | 2023-04-17 |
| h2oai | [h2ogpt-oasst1-512-12b](https://huggingface.co/h2oai/h2ogpt-oasst1-512-12b) | pythia | 12b | none | [openassistant_oasst1](https://huggingface.co/datasets/h2oai/openassistant_oasst1) |  |  |  | 2023-04-17 |
| h2oai | [h2ogpt-oig-oasst1-256-12b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-12b) | gpt-neox | 12b | none | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt) |  |  |  | 2023-04-17 |
| h2oai | [h2ogpt-oig-oasst1-256-12b](https://huggingface.co/h2oai/h2ogpt-oig-oasst1-256-12b) | pythia | 12b | none | [h2ogpt-oig-oasst1-instruct-cleaned-v1](https://huggingface.co/datasets/h2oai/h2ogpt-oig-oasst1-instruct-cleaned-v1), [openassistant_oasst1_h2ogpt](https://huggingface.co/datasets/h2oai/openassistant_oasst1_h2ogpt) |  |  |  | 2023-04-17 |
| liuhaotian | [LLaVA-13b-delta-v0](https://huggingface.co/liuhaotian/LLaVA-13b-delta-v0) | llava | 13b | 16bit | [LLaVA Instruct](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K) |  |  |  | 2023-04-17 |
| stabilityai | [stablelm-base-alpha-3b/](https://huggingface.co/stabilityai/stablelm-base-alpha-3b/) | stablelm | 3b | none | [The New Pile](https://pile.eleuther.ai/) |  |  |  | 2023-04-17 |
| gozfarb | [alpacino-13b-4bit-128g](https://huggingface.co/gozfarb/alpacino-13b-4bit-128g) | alpaca | 13b | 4bit | CoT + Storytelling |  |  |  | 2023-04-15 |
| verymuchawful | [Alpacino-13b-ggml](https://huggingface.co/verymuchawful/Alpacino-13b-ggml) | alpaca | 13b | 16bit | CoT + Storytelling |  |  |  | 2023-04-15 |
| MetaIX | [GPT4-X-Alpaca-30B-4bit](https://huggingface.co/MetaIX/GPT4-X-Alpaca-30B-4bit) | alpaca | 30b | 4bit GPTQ | [GPTeacher](https://github.com/teknium1/GPTeacher) |  |  |  | 2023-04-15 |
| helloollel | [vicuna-13b](https://huggingface.co/helloollel/vicuna-13b) | vicuna | 13b | 16bit | Vicuna |  |  |  | 2023-04-15 |
| TheBloke | [vicuna-13B-1.1-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g) | vicuna-v1.1 | 13b | 4bit GPTQ | vicuna censored |  |  |  | 2023-04-15 |
| TheBloke | [vicuna-13B-1.1-HF](https://huggingface.co/TheBloke/vicuna-13B-1.1-HF) | vicuna-v1.1 | 13b | 16bit | vicuna censored |  |  |  | 2023-04-15 |
| winglian | [vicuna-13b-1_1-hf](https://huggingface.co/winglian/vicuna-13b-1_1-hf) | vicuna-v1.1 | 13b | none | vicuna censored |  |  |  | 2023-04-15 |
| helloollel | [vicuna-7b](https://huggingface.co/helloollel/vicuna-7b) | vicuna | 7b | 16bit | Vicuna |  |  |  | 2023-04-15 |
| Sosaka | [Vicuna-7B-4bit-ggml](https://huggingface.co/Sosaka/Vicuna-7B-4bit-ggml) | vicuna | 7b | q4_0 | Vicuna |  |  |  | 2023-04-15 |
| Thireus | [Vicuna13B-v1.1-8bit-128g](https://huggingface.co/Thireus/Vicuna13B-v1.1-8bit-128g) | vicuna-v1.1 | 13b | 8bit GPTQ | Vicuna |  |  |  | 2023-04-15 |
| digitous | [Alpacino30b](https://huggingface.co/digitous/Alpacino30b) | alpaca | 30b | 16bit | CoT + Storytelling |  |  |  | 2023-04-14 |
| TheBloke | [gpt4-alpaca-lora-30B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/gpt4-alpaca-lora-30B-GPTQ-4bit-128g) | alpaca | 30b | 4bit GPTQ | chansung's dataset alpaca_data_gpt4.json |  |  |  | 2023-04-14 |
| TheBloke | [gpt4-alpaca-lora-30b-HF](https://huggingface.co/TheBloke/gpt4-alpaca-lora-30b-HF) | alpaca | 30b | none | chansung's dataset alpaca_data_gpt4.json |  |  |  | 2023-04-14 |
| digitous | [Alpacino13b](https://huggingface.co/digitous/Alpacino13b) | alpaca | 13b | 16bit | CoT + Storytelling |  |  |  | 2023-04-13 |
| databricks | [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b) | dolly | 3b | none | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data) |  |  |  | 2023-04-13 |
| databricks | [dolly-v2-7b](https://huggingface.co/databricks/dolly-v2-7b) | dolly | 7b | none | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data) |  |  |  | 2023-04-13 |
| CRD716 | [ggml-vicuna-1.1-q4_0](https://huggingface.co/CRD716/ggml-vicuna-1.1-q4_0) | vicuna-v1.1 | 7b | q4_0, f16 | vicuna censored |  |  |  | 2023-04-13 |
| CRD716 | [ggml-vicuna-1.1-q4_0](https://huggingface.co/CRD716/ggml-vicuna-1.1-q4_0) | vicuna-v1.1 | 13b | q4_0, q5_0, f16 | vicuna censored |  |  |  | 2023-04-13 |
| winglian | [llama-adapter-7b](https://huggingface.co/winglian/llama-adapter-7b) | llama | 7b | none | [alpaca_data_gpt4.json](https://github.com/tloen/alpaca-lora/blob/main/alpaca_data_gpt4.json) |  |  | yes | 2023-04-13 |
| eachadea | [vicuna-13b-1.1](https://huggingface.co/eachadea/vicuna-13b-1.1) | vicuna | 13b | none | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) [llama](https://huggingface.co/datasets/viewv/LLaMA-13B) [shareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-04-13 |
| teknium | [Base-GPT4-x-Alpaca-Roleplay-Lora](https://huggingface.co/teknium/Base-GPT4-x-Alpaca-Roleplay-Lora) | llama | 13b | none | gpt4-x-alpaca finetune, [roleplay instruct](https://github.com/teknium1/GPTeacher/tree/main/Roleplay) |  |  |  | 2023-04-12 |
| databricks | [dolly-v2-12b](https://huggingface.co/databricks/dolly-v2-12b) | dolly | 12b | none | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data) |  |  |  | 2023-04-12 |
| mzedp | [dolly-v2-12b-GPTQ-4bit-128g](https://huggingface.co/mzedp/dolly-v2-12b-GPTQ-4bit-128g) | dolly | 12b | 4bit | [databricks-dolly-15k](https://github.com/databrickslabs/dolly/tree/master/data) |  |  |  | 2023-04-12 |
| Selyam | [gpt4-x-alpaca-13b-native-4bit-128g](https://huggingface.co/Selyam/gpt4-x-alpaca-13b-native-4bit-128g) | alpaca | 13b | 4bit GPTQ | [GPTeacher](https://github.com/teknium1/GPTeacher) |  |  |  | 2023-04-12 |
| TheBloke | [vicuna-13B-1.1-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/vicuna-13B-1.1-GPTQ-4bit-128g-GGML) | vicuna-v1.1 | 13b | 4bit GPTQ | vicuna censored |  |  |  | 2023-04-12 |
| TheBloke | [vicuna-7B-1.1-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-7B-1.1-GPTQ-4bit-128g) | vicuna-v1.1 | 7b | 4bit GPTQ | vicuna censored |  |  |  | 2023-04-12 |
| TheBloke | [vicuna-7B-1.1-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/vicuna-7B-1.1-GPTQ-4bit-128g-GGML) | vicuna-v1.1 | 7b | 4bit GPTQ | vicuna censored |  |  |  | 2023-04-12 |
| TheBloke | [vicuna-7B-1.1-HF](https://huggingface.co/TheBloke/vicuna-7B-1.1-HF) | vicuna-v1.1 | 7b | 16bit | vicuna censored |  |  |  | 2023-04-12 |
| nomic-ai | [gpt4all-j](https://huggingface.co/nomic-ai/gpt4all-j) | gpt-j | 6b | 16bit | [gpt4all-j-prompt-generations](https://huggingface.co/datasets/nomic-ai/gpt4all-j-prompt-generations) |  |  |  | 2023-04-11 |
| verymuchawful | [llama-13b-pretrained-dropout-hf-int4-128g](https://huggingface.co/verymuchawful/llama-13b-pretrained-dropout-hf-int4-128g) | llama | 13b | 4bit GPTQ | Open-Assistant? |  |  |  | 2023-04-11 |
| stabilityai | [stablelm-base-alpha-7b/](https://huggingface.co/stabilityai/stablelm-base-alpha-7b/) | stablelm | 7b | none | [The New Pile](https://pile.eleuther.ai/) |  |  |  | 2023-04-11 |
| gozfarb | [vicuba-7b-int4-128g](https://huggingface.co/gozfarb/vicuba-7b-int4-128g) | vicuna | 7b | 4bit GPTQ | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-04-11 |
| gozfarb | [instruct-13b-4bit-128g](https://huggingface.co/gozfarb/instruct-13b-4bit-128g) | llama | 13b | 4bit GPTQ? | instruct-13b weights | instruct |  |  | 2023-04-10 |
| llama-anon | [instruct-13b-4bit-ggml](https://huggingface.co/llama-anon/instruct-13b-4bit-ggml) | llama | 13b | q4_0 | instruct-13b weights | instruct |  |  | 2023-04-10 |
| TheBloke | [vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/vicuna-AlekseyKorshuk-7B-GPTQ-4bit-128g) | vicuna | 7b | 4bit GPTQ | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-04-10 |
| TheBloke | [koala-13B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g) | llama | 13b | 4bit GPTQ | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization |  |  |  | 2023-04-09 |
| TheBloke | [koala-13B-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/koala-13B-GPTQ-4bit-128g-GGML) | llama | 13b | 4bit GPTQ | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization |  |  |  | 2023-04-09 |
| TheBloke | [koala-7B-GPTQ-4bit-128g](https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g) | llama | 7b | 4bit GPTQ | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization |  |  |  | 2023-04-09 |
| TheBloke | [koala-7B-GPTQ-4bit-128g-GGML](https://huggingface.co/TheBloke/koala-7B-GPTQ-4bit-128g-GGML) | llama | 7b | 4bit GPTQ | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization |  |  |  | 2023-04-09 |
| 4bit | [llama-13b-4bit-gr128](https://huggingface.co/4bit/llama-13b-4bit-gr128) | llama | 13b | 4bit GPTQ | none |  |  |  | 2023-04-09 |
| andreaskoepf | [pythia-6.9b-gpt4all-pretrain](https://huggingface.co/andreaskoepf/pythia-6.9b-gpt4all-pretrain) | pythia | 6.9b | 16bit | Open-Assistant? gpt4all? |  |  |  | 2023-04-09 |
| tsumeone | [gpt4-x-alpaca-13b-native-4bit-128g-cuda](https://huggingface.co/tsumeone/gpt4-x-alpaca-13b-native-4bit-128g-cuda) | alpaca | 13b | 4bit | [GPTeacher](https://github.com/teknium1/GPTeacher) |  |  |  | 2023-04-08 |
| Black-Engineer | [oasst-llama30b-ggml-q4](https://huggingface.co/Black-Engineer/oasst-llama30b-ggml-q4) | llama | 30b | q4_0 | Open-Assistant, Alpaca |  |  |  | 2023-04-08 |
| LLukas22 | [alpaca-native-7B-4bit-ggjt](https://huggingface.co/LLukas22/alpaca-native-7B-4bit-ggjt) | alpaca | 7b | 4bit GPTQ? |  |  |  |  | 2023-04-07 |
| TheBloke | [koala-13B-HF](https://huggingface.co/TheBloke/koala-13B-HF) | llama | 13b | 16bit | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization |  |  |  | 2023-04-07 |
| TheBloke | [koala-7B-HF](https://huggingface.co/TheBloke/koala-7B-HF) | llama | 7b | 16bit | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization |  |  |  | 2023-04-07 |
| Black-Engineer | [llama-13b-pretrained-sft-do2-ggml-q4](https://huggingface.co/Black-Engineer/llama-13b-pretrained-sft-do2-ggml-q4) | llama | 13b | q4_0 | ? |  |  |  | 2023-04-07 |
| Black-Engineer | [oasst-llama13b-ggml](https://huggingface.co/Black-Engineer/oasst-llama13b-ggml) | llama | 13b | 16bit | Open-Assistant |  |  |  | 2023-04-07 |
| MetaIX | [Alpaca-30B-Int4-128G-Safetensors](https://huggingface.co/MetaIX/Alpaca-30B-Int4-128G-Safetensors) | alpaca | 30b | 4bit | Clean Alpaca dataset of 2023-04-06 using Chansung ALpaca Lora |  |  |  | 2023-04-06 |
| eachadea | [ggml-gpt4-x-alpaca-13b-native-4bit](https://huggingface.co/eachadea/ggml-gpt4-x-alpaca-13b-native-4bit) | alpaca | 13b | 4bit | Alpaca |  |  |  | 2023-04-06 |
| jordiclive | [gpt4all-alpaca-oa-codealpaca-lora-13b](https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-13b) | alpaca | 13b | ? | Nebulous/gpt4all_pruned, sahil2801/CodeAlpaca-20k, yahma/alpaca-cleaned, part of OpenAssistant |  |  | yes | 2023-04-06 |
| TheBloke | [koala-7b-ggml-unquantized](https://huggingface.co/TheBloke/koala-7b-ggml-unquantized) | llama | 7b | 16bit | Llama, ShareGPT, HC3 English, LAION OIC, Alpaca, ANthropic HH, WebGPT, Summarization |  |  |  | 2023-04-06 |
| dvruette | [llama-13b-pretrained-sft-do2](https://huggingface.co/dvruette/llama-13b-pretrained-sft-do2) | llama | 13b | 16bit | ? |  |  |  | 2023-04-06 |
| Black-Engineer | [oasst-llama13b-ggml-q4](https://huggingface.co/Black-Engineer/oasst-llama13b-ggml-q4) | llama | 13b | q4_0 | Open-Assistant, Alpaca |  |  |  | 2023-04-06 |
| jeffwan | [vicuna-13b/tree/main](https://huggingface.co/jeffwan/vicuna-13b/tree/main) | vicuna | 13b | ? | Vicuna |  |  |  | 2023-04-06 |
| chansung | [alpaca-lora-13b](https://huggingface.co/chansung/alpaca-lora-13b) | alpaca | 13b | 8bit | [cleaned-up aplaca dataset](https://github.com/gururise/AlpacaDataCleaned) |  |  | yes | 2023-04-05 |
| eachadea | [ggml-vicuna-13b-4bit](https://huggingface.co/eachadea/ggml-vicuna-13b-4bit) | vicuna | 13b | 4bit GPTQ? | Vicuna |  |  |  | 2023-04-05 |
| eachadea | [ggml-vicuna-7b-4bit](https://huggingface.co/eachadea/ggml-vicuna-7b-4bit) | vicuna | 7b | 4bit | Vicuna |  |  |  | 2023-04-05 |
| dvruette | [llama-13b-pretrained-dropout](https://huggingface.co/dvruette/llama-13b-pretrained-dropout) | llama | 13b | 16bit | Open-Assistant? |  |  |  | 2023-04-05 |
| magicgh | [llama30b-lora-cot](https://huggingface.co/magicgh/llama30b-lora-cot) | llama | 30b | ? | Alpaca-CoT |  |  | yes | 2023-04-05 |
| titan087 | [Vicuna-13b](https://huggingface.co/titan087/Vicuna-13b) | vicuna | 13b | 16bit |  |  |  |  | 2023-04-05 |
| AlekseyKorshuk | [vicuna-7b](https://huggingface.co/AlekseyKorshuk/vicuna-7b) | vicuna | 7b | none | [ShareGPT Unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-04-05 |
| jordiclive | [gpt4all-alpaca-oa-codealpaca-lora-7b](https://huggingface.co/jordiclive/gpt4all-alpaca-oa-codealpaca-lora-7b) | alpaca | 7b | ? | [gpt4all_pruned](https://huggingface.co/datasets/Nebulous/gpt4all_pruned)<br />[CodeAlpaca-20k](https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k)<br />[alpaca-cleaned](https://huggingface.co/datasets/yahma/alpaca-cleaned) |  |  | yes | 2023-04-04 |
| ShreyasBrill | [Vicuna-13B](https://huggingface.co/ShreyasBrill/Vicuna-13B) | vicuna | 13b | q4_0 | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca) [llama](https://huggingface.co/datasets/viewv/LLaMA-13B) [shareGPT unfiltered](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |  |  |  | 2023-04-04 |
| elinas | [vicuna-13b-4bit](https://huggingface.co/elinas/vicuna-13b-4bit) | vicuna | 13b | 4bit GPTQ |  |  |  |  | 2023-04-04 |
| samwit | [vicuna-13b-8bit](https://huggingface.co/samwit/vicuna-13b-8bit) | vicuna | 13b | 8bit |  |  |  |  | 2023-04-04 |
| chansung | [alpaca-lora-65b](https://huggingface.co/chansung/alpaca-lora-65b) | alpaca | 65b | 16bit | GPT 3.5 Alpaca dataset? |  |  | yes | 2023-04-03 |
| dvruette | [oasst-pythia-12b-pretrained](https://huggingface.co/dvruette/oasst-pythia-12b-pretrained) | pythia | 12b | 16bit | Open-Assistant? |  |  |  | 2023-04-03 |
| dvruette | [oasst-pythia-12b-reference](https://huggingface.co/dvruette/oasst-pythia-12b-reference) | pythia | 12b | 16bit | ? |  |  |  | 2023-04-03 |
| andreaskoepf | [pythia-12b-pre-2000](https://huggingface.co/andreaskoepf/pythia-12b-pre-2000) | pythia | 12b | 16bit | joke, webgpt, gpt4all, alpaca, code_alpaca, minimath, codegen, testgen, grade school math, recipes, cmu wiki, oa wiki, prosocial dialogue, explain prosocial |  |  |  | 2023-04-03 |
| eachadea | [vicuna-13b](https://huggingface.co/eachadea/vicuna-13b) | vicuna | 13b | 16bit | Vicuna |  |  |  | 2023-04-03 |
| lmsys | [vicuna-13b-delta-v0](https://huggingface.co/lmsys/vicuna-13b-delta-v0) | vicuna | 13b | 16bit |  |  |  |  | 2023-04-03 |
| anon8231489123 | [vicuna-13b-GPTQ-4bit-128g](https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g) | vicuna | 13b | 4bit GPTQ | Vicuna |  |  |  | 2023-04-03 |
| Pi3141 | [alpaca-13B-ggml](https://huggingface.co/Pi3141/alpaca-13B-ggml) | alpaca | 13b | 4bit GPTQ |  |  |  | yes | 2023-04-02 |
| Pi3141 | [alpaca-30B-ggml](https://huggingface.co/Pi3141/alpaca-30B-ggml) | alpaca | 30b | 4bit GPTQ |  |  |  |  | 2023-04-01 |
| anon8231489123 | [gpt4-x-alpaca-13b-native-4bit-128g](https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g) | alpaca | 13b | 4bit GPTQ | [GPTeacher](https://github.com/teknium1/GPTeacher) |  |  |  | 2023-04-01 |
| andreaskoepf | [pythia-12b-pre-3500](https://huggingface.co/andreaskoepf/pythia-12b-pre-3500) | pythia | 12b | 16bit | joke, webgpt, gpt4all, alpaca, code_alpaca, minimath, codegen, testgen, grade school math, recipes, cmu wiki, oa wiki, prosocial dialogue, explain prosocial |  |  |  | 2023-04-01 |
| chavinlo | [gpt4-x-alpaca](https://huggingface.co/chavinlo/gpt4-x-alpaca) | alpaca | 13b | 16bit | [GPTeacher](https://github.com/teknium1/GPTeacher) |  |  |  | 2023-03-31 |
| elinas | [alpaca-30b-lora-int4](https://huggingface.co/elinas/alpaca-30b-lora-int4) | alpaca | 30b | 4bit GPTQ | Alpaca |  |  |  | 2023-03-30 |
| tloen | [alpaca-lora-7b/](https://huggingface.co/tloen/alpaca-lora-7b/) | alpaca | 7b | 4bit GPTQ |  |  |  | yes | 2023-03-29 |
| 8bit-coder | [alpaca-7b-nativeEnhanced](https://huggingface.co/8bit-coder/alpaca-7b-nativeEnhanced) | alpaca | 7b | 16bit |  |  |  |  | 2023-03-28 |
| nomic-ai | [gpt4all-lora](https://huggingface.co/nomic-ai/gpt4all-lora) | llama | 7b | ? | [gpt4all prompt generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations) |  |  | yes | 2023-03-28 |
| elinas | [alpaca-13b-lora-int4](https://huggingface.co/elinas/alpaca-13b-lora-int4) | alpaca | 7b | 4bit GPTQ |  |  |  | yes | 2023-03-27 |
| Pi3141 | [alpaca-7B-ggml](https://huggingface.co/Pi3141/alpaca-7B-ggml) | alpaca | 7b | 4bit GPTQ |  |  |  | yes | 2023-03-25 |
| Sosaka | [Alpaca-native-4bit-ggml](https://huggingface.co/Sosaka/Alpaca-native-4bit-ggml) | alpaca | 7b | 4bit GPTQ |  |  |  |  | 2023-03-21 |
| ozcur | [alpaca-native-4bit](https://huggingface.co/ozcur/alpaca-native-4bit) | alpaca | 7b | 4bit GPTQ |  |  |  |  | 2023-03-20 |
| baseten | [alpaca-30b](https://huggingface.co/baseten/alpaca-30b) | alpaca | 30b | 16bit |  |  |  | yes | 2023-03-19 |
| Dogge | [alpaca-13b](https://huggingface.co/Dogge/alpaca-13b) | alpaca | 13b | 4bit GPTQ |  |  |  |  | 2023-03-18 |
| baruga | [alpaca-lora-13b](https://huggingface.co/baruga/alpaca-lora-13b) | alpaca | 13b | 8bit |  |  |  | yes | 2023-03-18 |
| chavinlo | [alpaca-native](https://huggingface.co/chavinlo/alpaca-native) | alpaca | 7b | 16bit |  |  |  |  | 2023-03-18 |
| TianXxx | [llama-30b-int4](https://huggingface.co/TianXxx/llama-30b-int4) | llama | 13b | 4bit GPTQ | none |  |  |  | 2023-03-18 |
| kuleshov | [llama-30b-4bit](https://huggingface.co/kuleshov/llama-30b-4bit) | llama | 13b | 4bit GPTQ | none |  |  |  | 2023-03-17 |
| Draff | [llama-alpaca-stuff/tree/main/Alpaca-Loras](https://huggingface.co/Draff/llama-alpaca-stuff/tree/main/Alpaca-Loras) | alpaca | 13b | 8bit |  |  |  | yes | 2023-03-17 |
| gozfarb | [oasst-llama13b-4bit-128g](https://huggingface.co/gozfarb/oasst-llama13b-4bit-128g) | llama | 13b | 4bit | Open-Assistant |  |  |  | 2023-03-17 |
| elinas | [llama-30b-int4](https://huggingface.co/elinas/llama-30b-int4) | llama | 13b | 4bit GPTQ | none |  |  |  | 2023-03-16 |
| samwit | [alpaca13B-lora](https://huggingface.co/samwit/alpaca13B-lora) | alpaca | 13b | 8bit |  |  |  | yes | 2023-03-15 |
| decapoda-research | [llama-7b-hf](https://huggingface.co/decapoda-research/llama-7b-hf) | llama | 7b | 16bit | none |  |  |  | 2023-03-08 |
| CarperAI | [vicuna-13b-fine-tuned-rlhf](https://huggingface.co/CarperAI/vicuna-13b-fine-tuned-rlhf) | vicuna | 13b | 16bit | [alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca), [gpt4all_prompt_generations](https://huggingface.co/datasets/nomic-ai/gpt4all_prompt_generations), [oasst1](https://huggingface.co/datasets/OpenAssistant/oasst1), [Anthropic HH-RLHF](https://huggingface.co/datasets/Anthropic/hh-rlhf), [Stanford Human Preferences Dataset](https://huggingface.co/datasets/stanfordnlp/SHP) |  |  |  | 2023-03-01 |



## Other SOTA Open Source models
- [Cerebras GPT-13b](https://huggingface.co/cerebras) ([release notes](https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/))
- [LAION OpenFlamingo | Multi Modal Model and training architecture](https://github.com/mlfoundations/open_flamingo)
- [TheBloke/galpaca-30b-gptq-4bit-128g](https://huggingface.co/TheBloke/galpaca-30B-GPTQ-4bit-128g), GALACTICA 30B fine tuned with Alpaca 
- [GeorgiaTechResearchInstitute/galpaca-6.7b](https://huggingface.co/GeorgiaTechResearchInstitute/galpaca-6.7b) GALACTICA 6.7B fine tuned with Alpaca
- [GeoV/GeoV-9b](https://huggingface.co/GeoV/GeoV-9b) - 9B parameter, in-progress training to 300B tokens (33:1)
- [RWKV: Parallelizable RNN with Transformer-level LLM Performance](https://github.com/BlinkDL/RWKV-LM)
- [CodeGeeX 13B | Multi Language Code Generation Model](https://huggingface.co/spaces/THUDM/CodeGeeX)
- [BigCode | Open Scientific collaboration to train a coding LLM](https://huggingface.co/bigcode)
- [MOSS by Fudan University](https://github.com/OpenLMLab/MOSS) a 16b Chinese/English custom foundational model with additional models fine tuned on sft and plugin usage
- [mPLUG-Owl](https://github.com/X-PLUG/mPLUG-Owl) Multimodal finetuned model for visual/language tasks
- [Multimodal-GPT](https://github.com/open-mmlab/Multimodal-GPT) multi-modal visual/language chatbot, using llama with custom LoRA weights and openflamingo-9B.
- [Visual-med-alpaca](https://github.com/cambridgeltl/visual-med-alpaca) fine-tuning llama-7b on self instruct for the biomedical domain. Models locked behind a request form.
- [replit-code-v1-3b](https://huggingface.co/replit/replit-code-v1-3b) focused on Code Completion. The model has been trained on a subset of the [Stack Dedup v1.2](https://arxiv.org/abs/2211.15533) dataset.
- [VPGTrans](https://vpgtrans.github.io/) Transfer Visual Prompt Generator across LLMs and the VL-Vicuna model is a novel VL-LLM. [Paper](https://arxiv.org/abs/2305.01278), [code](https://github.com/VPGTrans/VPGTrans)
- [salesforce/CodeT5](https://github.com/salesforce/codet5) code assistant, has released their [codet5+ 16b](https://huggingface.co/Salesforce/codet5p-16b) and other model sizes
- [baichuan-7b](https://github.com/baichuan-inc/baichuan-7B) Baichuan Intelligent Technology developed baichuan-7B, an open-source language model with 7 billion parameters trained on 1.2 trillion tokens. Supporting Chinese and English, it achieves top performance on authoritative benchmarks (C-EVAL, MMLU)

